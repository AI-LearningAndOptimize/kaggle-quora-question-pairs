{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 'lystdo-fasttext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep\n",
    "submissions_data_folder = os.path.join(data_folder, 'submissions') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirror the dataset question-wise and append it to the original one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1_new = np.vstack([X_train_q1, X_train_q2])\n",
    "X_train_q2_new = np.vstack([X_train_q2, X_train_q1])\n",
    "\n",
    "X_train_q1 = X_train_q1_new\n",
    "X_train_q2 = X_train_q2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.concatenate([y_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train_q1:', X_train_q1.shape)\n",
    "print('X_train_q2:', X_train_q2.shape)\n",
    "print('y_train   :', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    embedding_layer = Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    )\n",
    "    lstm_layer = LSTM(\n",
    "        params['num_lstm'],\n",
    "        dropout=params['lstm_dropout_rate'],\n",
    "        recurrent_dropout=params['lstm_dropout_rate'],\n",
    "    )\n",
    "\n",
    "    sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "    x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "    sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "    y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "    merged = concatenate([x1, y1])\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    merged = Dense(params['num_dense'], activation='relu')(merged)\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[sequence_1_input, sequence_2_input],\n",
    "        outputs=output\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer='nadam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_fingerprint(params):\n",
    "    return EXPERIMENT_ID + '-lstm-{}-dense-{}-droplstm-{:.3f}-dropdense-{:.3f}'.format(\n",
    "        params['num_lstm'],\n",
    "        params['num_dense'],\n",
    "        params['lstm_dropout_rate'],\n",
    "        params['dense_dropout_rate'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a K-Fold Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = [\n",
    "    (\n",
    "        (X_train_q1[ix_fold_train], X_train_q2[ix_fold_train], y_train[ix_fold_train]),\n",
    "        (X_train_q1[ix_fold_val], X_train_q2[ix_fold_val], y_train[ix_fold_val]),        \n",
    "    )\n",
    "    for (ix_fold_train, ix_fold_val) in kfold.split(X_train_q1, y_train)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Search Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_random_search_iterations = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_grid = [\n",
    "    {\n",
    "        'num_lstm': np.random.randint(128, 512),\n",
    "        'num_dense': np.random.randint(50, 250),\n",
    "        'lstm_dropout_rate': np.random.random_sample() / 2,\n",
    "        'dense_dropout_rate': np.random.random_sample() / 2,\n",
    "    }\n",
    "    for i in range(num_random_search_iterations)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + EXPERIMENT_ID + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histories = []\n",
    "best_score = 1e9\n",
    "best_params = None\n",
    "\n",
    "# Begin Random Search.\n",
    "for search_iter, current_params in enumerate(search_grid):\n",
    "    \n",
    "    print()\n",
    "    print('-' * 30, f'Iteration {search_iter + 1} / {num_random_search_iterations}', '-' * 30)\n",
    "    print(f'Trying parameter combination:')\n",
    "    pprint.pprint(current_params)\n",
    "    \n",
    "    current_iter_val_scores = []\n",
    "\n",
    "    # Begin K-Fold.\n",
    "    for fold_num, fold in enumerate(folds):\n",
    "        X_fold_train_q1, X_fold_train_q2, y_fold_train = fold[0]\n",
    "        X_fold_val_q1, X_fold_val_q2, y_fold_val = fold[1]\n",
    "\n",
    "        print()\n",
    "        print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "        print()\n",
    "\n",
    "        model = create_model(current_params)\n",
    "        history = model.fit(\n",
    "            [X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "            validation_data=([X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "\n",
    "            batch_size=2048,\n",
    "            epochs=200,\n",
    "            verbose=0,\n",
    "            \n",
    "            callbacks=[\n",
    "                EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    min_delta=0.001,\n",
    "                    patience=3,\n",
    "                    verbose=1,\n",
    "                    mode='auto',\n",
    "                ),\n",
    "                ModelCheckpoint(\n",
    "                    model_checkpoint_path,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True,\n",
    "                    verbose=2,\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        best_val_score = min(history.history['val_loss'])\n",
    "        print(f'Validation score: {best_val_score}')        \n",
    "\n",
    "        current_iter_val_scores.append(best_val_score)\n",
    "        histories.append((current_params, best_val_score, history.history))\n",
    "\n",
    "    # End K-Fold.\n",
    "    # Save the trained model with the current parameter combination.\n",
    "    current_iter_avg_score = np.mean(current_iter_val_scores)\n",
    "    model_save_filename = '{}-random-search-{:.4f}-{}.keras'.format(\n",
    "        EXPERIMENT_ID,\n",
    "        current_iter_avg_score,\n",
    "        get_model_fingerprint(current_params)\n",
    "    )\n",
    "    \n",
    "    if current_iter_avg_score < best_score:\n",
    "        best_score = current_iter_avg_score\n",
    "        best_params = current_params\n",
    "    \n",
    "    print()\n",
    "    print('CV score  :', current_iter_avg_score)\n",
    "    print('Saving as :', model_save_filename)\n",
    "    model.save(aux_data_folder + model_save_filename)\n",
    "\n",
    "# End Random Search.\n",
    "# Print best params and save history.\n",
    "print()\n",
    "print('=' * 70)\n",
    "print('Best CV score:', best_score)\n",
    "print('Best params:')\n",
    "pprint.pprint(best_params)\n",
    "\n",
    "save(histories, aux_data_folder + f'{EXPERIMENT_ID}-random-search-history.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
