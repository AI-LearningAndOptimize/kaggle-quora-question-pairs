{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_lystdo_bi_lstm_magic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "magic_feature_lists = [\n",
    "    'magic_jturkewitz',\n",
    "    'magic_stas_svd_150',\n",
    "    'magic_stas_avito',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic, X_test_magic, _ = load_feature_lists(magic_feature_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic = X_train_magic.values\n",
    "X_test_magic = X_test_magic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack([X_train_magic, X_test_magic]))\n",
    "X_train_magic = scaler.transform(X_train_magic)\n",
    "X_test_magic = scaler.transform(X_test_magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_question_branch():\n",
    "    input_q = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    \n",
    "    embedding_q = Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    )(input_q)\n",
    "\n",
    "    timedist_q = TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu',\n",
    "    ))(embedding_q)\n",
    "\n",
    "    lambda_q = Lambda(\n",
    "        lambda x: K.max(x, axis=1),\n",
    "        output_shape=(EMBEDDING_DIM, )\n",
    "    )(timedist_q)\n",
    "    \n",
    "    output_q = lambda_q\n",
    "    return input_q, output_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(params):    \n",
    "    embedding_layer = Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    )\n",
    "    lstm_layer = Bidirectional(LSTM(\n",
    "        params['num_lstm'],\n",
    "        dropout=params['lstm_dropout_rate'],\n",
    "        recurrent_dropout=params['lstm_dropout_rate'],\n",
    "    ))\n",
    "\n",
    "    sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "    x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "    sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "    y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "    magic_input = Input(shape=(X_train_magic.shape[-1], ))\n",
    "    \n",
    "    merged = concatenate([x1, y1, magic_input])\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    merged = Dense(params['num_dense'], activation='relu')(merged)\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[sequence_1_input, sequence_2_input, magic_input],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'dense_dropout_rate': 0.07512852175097123,\n",
    "    'lstm_dropout_rate': 0.3320541002991107,\n",
    "    'num_dense': 130,\n",
    "    'num_lstm': 333\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X_q1, X_q2, X_magic):\n",
    "    y1 = model.predict(\n",
    "        [X_q1, X_q2, X_magic],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    y2 = model.predict(\n",
    "        [X_q2, X_q1, X_magic],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    return (y1 + y2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8256Epoch 00000: val_loss improved from inf to 0.33177, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 203s - loss: 0.3850 - acc: 0.8256 - val_loss: 0.3318 - val_acc: 0.8563\n",
      "Epoch 2/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.8554Epoch 00001: val_loss improved from 0.33177 to 0.30224, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 205s - loss: 0.3210 - acc: 0.8554 - val_loss: 0.3022 - val_acc: 0.8661\n",
      "Epoch 3/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.8671Epoch 00002: val_loss improved from 0.30224 to 0.29431, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 204s - loss: 0.2952 - acc: 0.8671 - val_loss: 0.2943 - val_acc: 0.8671\n",
      "Epoch 4/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2779 - acc: 0.8751Epoch 00003: val_loss improved from 0.29431 to 0.27635, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 203s - loss: 0.2779 - acc: 0.8752 - val_loss: 0.2763 - val_acc: 0.8766\n",
      "Epoch 5/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2636 - acc: 0.8816Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 203s - loss: 0.2636 - acc: 0.8816 - val_loss: 0.2799 - val_acc: 0.8732\n",
      "Epoch 6/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2510 - acc: 0.8875Epoch 00005: val_loss improved from 0.27635 to 0.27098, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 204s - loss: 0.2510 - acc: 0.8875 - val_loss: 0.2710 - val_acc: 0.8808\n",
      "Epoch 7/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.8931Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 204s - loss: 0.2401 - acc: 0.8931 - val_loss: 0.2905 - val_acc: 0.8691\n",
      "Epoch 8/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.8984Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 204s - loss: 0.2300 - acc: 0.8984 - val_loss: 0.2776 - val_acc: 0.8749\n",
      "Epoch 9/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2211 - acc: 0.9023Epoch 00008: val_loss did not improve\n",
      "646862/646862 [==============================] - 204s - loss: 0.2211 - acc: 0.9023 - val_loss: 0.2849 - val_acc: 0.8745\n",
      "Epoch 10/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9059Epoch 00009: val_loss did not improve\n",
      "646862/646862 [==============================] - 204s - loss: 0.2138 - acc: 0.9059 - val_loss: 0.2770 - val_acc: 0.8793\n",
      "Epoch 00009: early stopping\n",
      "80859/80859 [==============================] - 9s     \n",
      "80859/80859 [==============================] - 9s     \n",
      "2345796/2345796 [==============================] - 261s   \n",
      "2345796/2345796 [==============================] - 262s   \n",
      "\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8274Epoch 00000: val_loss improved from inf to 0.33918, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 203s - loss: 0.3829 - acc: 0.8274 - val_loss: 0.3392 - val_acc: 0.8460\n",
      "Epoch 2/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.8560Epoch 00001: val_loss improved from 0.33918 to 0.31118, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 201s - loss: 0.3190 - acc: 0.8561 - val_loss: 0.3112 - val_acc: 0.8588\n",
      "Epoch 3/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2946 - acc: 0.8673Epoch 00002: val_loss improved from 0.31118 to 0.29343, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 201s - loss: 0.2946 - acc: 0.8673 - val_loss: 0.2934 - val_acc: 0.8689\n",
      "Epoch 4/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2769 - acc: 0.8757Epoch 00003: val_loss improved from 0.29343 to 0.28514, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 200s - loss: 0.2769 - acc: 0.8757 - val_loss: 0.2851 - val_acc: 0.8727\n",
      "Epoch 5/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.8825Epoch 00004: val_loss improved from 0.28514 to 0.27790, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646862/646862 [==============================] - 200s - loss: 0.2628 - acc: 0.8825 - val_loss: 0.2779 - val_acc: 0.8763\n",
      "Epoch 6/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2508 - acc: 0.8881Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 201s - loss: 0.2507 - acc: 0.8881 - val_loss: 0.2897 - val_acc: 0.8685\n",
      "Epoch 7/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.8933Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 201s - loss: 0.2398 - acc: 0.8933 - val_loss: 0.2818 - val_acc: 0.8755\n",
      "Epoch 8/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.8978Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 201s - loss: 0.2303 - acc: 0.8978 - val_loss: 0.2884 - val_acc: 0.8740\n",
      "Epoch 9/200\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9024Epoch 00008: val_loss did not improve\n",
      "646862/646862 [==============================] - 200s - loss: 0.2214 - acc: 0.9024 - val_loss: 0.2801 - val_acc: 0.8780\n",
      "Epoch 00008: early stopping\n",
      "80859/80859 [==============================] - 9s     \n",
      "80859/80859 [==============================] - 8s     \n",
      "2345796/2345796 [==============================] - 259s   \n",
      "2345796/2345796 [==============================] - 259s   \n",
      "\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 646864 samples, validate on 161716 samples\n",
      "Epoch 1/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.3841 - acc: 0.8260Epoch 00000: val_loss improved from inf to 0.34420, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646864/646864 [==============================] - 202s - loss: 0.3840 - acc: 0.8260 - val_loss: 0.3442 - val_acc: 0.8445\n",
      "Epoch 2/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.8565Epoch 00001: val_loss improved from 0.34420 to 0.29290, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646864/646864 [==============================] - 200s - loss: 0.3191 - acc: 0.8565 - val_loss: 0.2929 - val_acc: 0.8684\n",
      "Epoch 3/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.8686Epoch 00002: val_loss did not improve\n",
      "646864/646864 [==============================] - 200s - loss: 0.2933 - acc: 0.8686 - val_loss: 0.3114 - val_acc: 0.8539\n",
      "Epoch 4/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2760 - acc: 0.8761Epoch 00003: val_loss improved from 0.29290 to 0.28442, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646864/646864 [==============================] - 200s - loss: 0.2760 - acc: 0.8761 - val_loss: 0.2844 - val_acc: 0.8704\n",
      "Epoch 5/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.8833Epoch 00004: val_loss improved from 0.28442 to 0.28192, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646864/646864 [==============================] - 201s - loss: 0.2613 - acc: 0.8833 - val_loss: 0.2819 - val_acc: 0.8719\n",
      "Epoch 6/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2486 - acc: 0.8887Epoch 00005: val_loss improved from 0.28192 to 0.27693, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646864/646864 [==============================] - 206s - loss: 0.2486 - acc: 0.8888 - val_loss: 0.2769 - val_acc: 0.8746\n",
      "Epoch 7/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.8943Epoch 00006: val_loss improved from 0.27693 to 0.27487, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646864/646864 [==============================] - 207s - loss: 0.2383 - acc: 0.8942 - val_loss: 0.2749 - val_acc: 0.8774\n",
      "Epoch 8/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.8987Epoch 00007: val_loss did not improve\n",
      "646864/646864 [==============================] - 207s - loss: 0.2277 - acc: 0.8988 - val_loss: 0.2936 - val_acc: 0.8684\n",
      "Epoch 9/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9029Epoch 00008: val_loss did not improve\n",
      "646864/646864 [==============================] - 207s - loss: 0.2195 - acc: 0.9029 - val_loss: 0.2847 - val_acc: 0.8716\n",
      "Epoch 10/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9070Epoch 00009: val_loss did not improve\n",
      "646864/646864 [==============================] - 205s - loss: 0.2115 - acc: 0.9070 - val_loss: 0.2830 - val_acc: 0.8743\n",
      "Epoch 11/200\n",
      "646144/646864 [============================>.] - ETA: 0s - loss: 0.2047 - acc: 0.9104Epoch 00010: val_loss did not improve\n",
      "646864/646864 [==============================] - 209s - loss: 0.2047 - acc: 0.9104 - val_loss: 0.2809 - val_acc: 0.8784\n",
      "Epoch 00010: early stopping\n",
      "80858/80858 [==============================] - 9s     \n",
      "80858/80858 [==============================] - 8s     \n",
      "2345796/2345796 [==============================] - 268s   \n",
      "2345796/2345796 [==============================] - 264s   \n",
      "\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8255Epoch 00000: val_loss improved from inf to 0.33810, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 203s - loss: 0.3862 - acc: 0.8256 - val_loss: 0.3381 - val_acc: 0.8538\n",
      "Epoch 2/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.3202 - acc: 0.8557Epoch 00001: val_loss improved from 0.33810 to 0.30502, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 202s - loss: 0.3202 - acc: 0.8557 - val_loss: 0.3050 - val_acc: 0.8615\n",
      "Epoch 3/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2941 - acc: 0.8674Epoch 00002: val_loss did not improve\n",
      "646866/646866 [==============================] - 202s - loss: 0.2941 - acc: 0.8674 - val_loss: 0.3057 - val_acc: 0.8579\n",
      "Epoch 4/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2768 - acc: 0.8756Epoch 00003: val_loss improved from 0.30502 to 0.28975, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 202s - loss: 0.2768 - acc: 0.8755 - val_loss: 0.2897 - val_acc: 0.8695\n",
      "Epoch 5/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.8824Epoch 00004: val_loss improved from 0.28975 to 0.28373, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 201s - loss: 0.2628 - acc: 0.8824 - val_loss: 0.2837 - val_acc: 0.8711\n",
      "Epoch 6/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2508 - acc: 0.8875Epoch 00005: val_loss improved from 0.28373 to 0.28367, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 202s - loss: 0.2508 - acc: 0.8875 - val_loss: 0.2837 - val_acc: 0.8707\n",
      "Epoch 7/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.8931Epoch 00006: val_loss improved from 0.28367 to 0.28027, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 202s - loss: 0.2401 - acc: 0.8931 - val_loss: 0.2803 - val_acc: 0.8741\n",
      "Epoch 8/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2307 - acc: 0.8978Epoch 00007: val_loss improved from 0.28027 to 0.27800, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 210s - loss: 0.2307 - acc: 0.8978 - val_loss: 0.2780 - val_acc: 0.8767\n",
      "Epoch 9/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9017Epoch 00008: val_loss improved from 0.27800 to 0.27384, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 212s - loss: 0.2220 - acc: 0.9017 - val_loss: 0.2738 - val_acc: 0.8807\n",
      "Epoch 10/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9058Epoch 00009: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2133 - acc: 0.9058 - val_loss: 0.2821 - val_acc: 0.8762\n",
      "Epoch 11/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9095Epoch 00010: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2065 - acc: 0.9095 - val_loss: 0.2891 - val_acc: 0.8734\n",
      "Epoch 12/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9122Epoch 00011: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2007 - acc: 0.9122 - val_loss: 0.3009 - val_acc: 0.8677\n",
      "Epoch 13/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9151Epoch 00012: val_loss did not improve\n",
      "646866/646866 [==============================] - 211s - loss: 0.1944 - acc: 0.9151 - val_loss: 0.2846 - val_acc: 0.8787\n",
      "Epoch 00012: early stopping\n",
      "80857/80857 [==============================] - 9s     \n",
      "80857/80857 [==============================] - 9s     \n",
      "2345796/2345796 [==============================] - 266s   \n",
      "2345796/2345796 [==============================] - 266s   \n",
      "\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8254Epoch 00000: val_loss improved from inf to 0.33122, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 212s - loss: 0.3860 - acc: 0.8253 - val_loss: 0.3312 - val_acc: 0.8589\n",
      "Epoch 2/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.3206 - acc: 0.8550Epoch 00001: val_loss improved from 0.33122 to 0.30883, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646866/646866 [==============================] - 212s - loss: 0.3206 - acc: 0.8550 - val_loss: 0.3088 - val_acc: 0.8606\n",
      "Epoch 3/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2955 - acc: 0.8673Epoch 00002: val_loss improved from 0.30883 to 0.29736, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 212s - loss: 0.2955 - acc: 0.8673 - val_loss: 0.2974 - val_acc: 0.8660\n",
      "Epoch 4/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2782 - acc: 0.8750Epoch 00003: val_loss improved from 0.29736 to 0.27888, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 212s - loss: 0.2782 - acc: 0.8751 - val_loss: 0.2789 - val_acc: 0.8756\n",
      "Epoch 5/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2637 - acc: 0.8819Epoch 00004: val_loss improved from 0.27888 to 0.27626, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 212s - loss: 0.2637 - acc: 0.8818 - val_loss: 0.2763 - val_acc: 0.8768\n",
      "Epoch 6/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2503 - acc: 0.8882Epoch 00005: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2504 - acc: 0.8882 - val_loss: 0.2768 - val_acc: 0.8761\n",
      "Epoch 7/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2400 - acc: 0.8932Epoch 00006: val_loss improved from 0.27626 to 0.27147, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm_magic.h5\n",
      "646866/646866 [==============================] - 212s - loss: 0.2399 - acc: 0.8932 - val_loss: 0.2715 - val_acc: 0.8804\n",
      "Epoch 8/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.8982Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2294 - acc: 0.8982 - val_loss: 0.2965 - val_acc: 0.8687\n",
      "Epoch 9/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9024Epoch 00008: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2212 - acc: 0.9024 - val_loss: 0.2876 - val_acc: 0.8745\n",
      "Epoch 10/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9066Epoch 00009: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2126 - acc: 0.9065 - val_loss: 0.2818 - val_acc: 0.8766\n",
      "Epoch 11/200\n",
      "646144/646866 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9101Epoch 00010: val_loss did not improve\n",
      "646866/646866 [==============================] - 212s - loss: 0.2054 - acc: 0.9100 - val_loss: 0.2819 - val_acc: 0.8779\n",
      "Epoch 00010: early stopping\n",
      "80857/80857 [==============================] - 9s     \n",
      "80857/80857 [==============================] - 9s     \n",
      "2345796/2345796 [==============================] - 266s   \n",
      "2345796/2345796 [==============================] - 259s   \n",
      "CPU times: user 3h 22min 55s, sys: 43min 27s, total: 4h 6min 23s\n",
      "Wall time: 3h 51min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "    X_fold_train_magic = np.vstack([X_train_magic[ix_train], X_train_magic[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "    X_fold_val_magic = np.vstack([X_train_magic[ix_val], X_train_magic[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model(model_params)\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2, X_fold_train_magic], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2, X_fold_val_magic], y_fold_val),\n",
    "\n",
    "        batch_size=1024,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "        \n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_train_oofp[ix_val] = predict(model, X_train_q1[ix_val], X_train_q2[ix_val], X_train_magic[ix_val])\n",
    "    y_test_oofp[:, fold_num] = predict(model, X_test_q1, X_test_q2, X_test_magic)\n",
    "    \n",
    "    # Clear GPU memory.\n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_train_magic\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del X_fold_val_magic\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.271096058182\n"
     ]
    }
   ],
   "source": [
    "cv_score = log_loss(y_train, y_train_oofp)\n",
    "print('CV score:', cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_lystdo_bi_lstm_magic',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp_mean = np.mean(y_test_oofp, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp_mean, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
