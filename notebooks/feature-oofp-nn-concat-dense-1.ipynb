{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_nn_concat_dense_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep\n",
    "submissions_data_folder = os.path.join(data_folder, 'submissions') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.stack((X_train_q1, X_train_q2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0] - 1\n",
    "MAX_SEQUENCE_LENGTH = X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101441 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model_q1 = Sequential()\n",
    "\n",
    "    model_q1.add(Embedding(\n",
    "        VOCAB_LENGTH + 1,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    ))\n",
    "\n",
    "    model_q1.add(TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu',\n",
    "    )))\n",
    "\n",
    "    model_q1.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "    model_q2 = Sequential()\n",
    "\n",
    "    model_q2.add(Embedding(\n",
    "        VOCAB_LENGTH + 1,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    ))\n",
    "\n",
    "    model_q2.add(TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu'\n",
    "    )))\n",
    "\n",
    "    model_q2.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([model_q1, model_q2], mode='concat'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323431 samples, validate on 80859 samples\n",
      "Epoch 1/200\n",
      "323264/323431 [============================>.] - ETA: 0s - loss: 0.6532 - acc: 0.7352Epoch 00000: val_loss improved from inf to 0.47442, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 36s - loss: 0.6532 - acc: 0.7353 - val_loss: 0.4744 - val_acc: 0.7638\n",
      "Epoch 2/200\n",
      "323008/323431 [============================>.] - ETA: 0s - loss: 0.5645 - acc: 0.7788Epoch 00001: val_loss improved from 0.47442 to 0.45677, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 35s - loss: 0.5645 - acc: 0.7788 - val_loss: 0.4568 - val_acc: 0.7735\n",
      "Epoch 3/200\n",
      "323008/323431 [============================>.] - ETA: 0s - loss: 0.5076 - acc: 0.8045Epoch 00002: val_loss improved from 0.45677 to 0.41687, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 35s - loss: 0.5076 - acc: 0.8045 - val_loss: 0.4169 - val_acc: 0.7971\n",
      "Epoch 4/200\n",
      "323136/323431 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.8249Epoch 00003: val_loss improved from 0.41687 to 0.41669, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 35s - loss: 0.4631 - acc: 0.8249 - val_loss: 0.4167 - val_acc: 0.7982\n",
      "Epoch 5/200\n",
      "323264/323431 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8411Epoch 00004: val_loss improved from 0.41669 to 0.40721, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 35s - loss: 0.4261 - acc: 0.8411 - val_loss: 0.4072 - val_acc: 0.8119\n",
      "Epoch 6/200\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3923 - acc: 0.8559Epoch 00005: val_loss did not improve\n",
      "323431/323431 [==============================] - 35s - loss: 0.3923 - acc: 0.8559 - val_loss: 0.4165 - val_acc: 0.8079\n",
      "Epoch 7/200\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8674Epoch 00006: val_loss did not improve\n",
      "323431/323431 [==============================] - 36s - loss: 0.3640 - acc: 0.8674 - val_loss: 0.4098 - val_acc: 0.8157\n",
      "Epoch 8/200\n",
      "322944/323431 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.8788Epoch 00007: val_loss improved from 0.40721 to 0.40020, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 33s - loss: 0.3397 - acc: 0.8787 - val_loss: 0.4002 - val_acc: 0.8203\n",
      "Epoch 9/200\n",
      "323136/323431 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8870Epoch 00008: val_loss did not improve\n",
      "323431/323431 [==============================] - 31s - loss: 0.3174 - acc: 0.8870 - val_loss: 0.4332 - val_acc: 0.8178\n",
      "Epoch 10/200\n",
      "323264/323431 [============================>.] - ETA: 0s - loss: 0.2968 - acc: 0.8957Epoch 00009: val_loss did not improve\n",
      "323431/323431 [==============================] - 34s - loss: 0.2969 - acc: 0.8957 - val_loss: 0.4422 - val_acc: 0.8194\n",
      "Epoch 11/200\n",
      "323008/323431 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.9023Epoch 00010: val_loss did not improve\n",
      "323431/323431 [==============================] - 34s - loss: 0.2792 - acc: 0.9023 - val_loss: 0.4404 - val_acc: 0.8267\n",
      "Epoch 12/200\n",
      "322880/323431 [============================>.] - ETA: 0s - loss: 0.2640 - acc: 0.9089Epoch 00011: val_loss did not improve\n",
      "323431/323431 [==============================] - 32s - loss: 0.2639 - acc: 0.9089 - val_loss: 0.4430 - val_acc: 0.8264\n",
      "Epoch 00011: early stopping\n",
      "79616/80859 [============================>.] - ETA: 0s\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 323431 samples, validate on 80859 samples\n",
      "Epoch 1/200\n",
      "323008/323431 [============================>.] - ETA: 0s - loss: 0.6554 - acc: 0.7324Epoch 00000: val_loss improved from inf to 0.47807, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 35s - loss: 0.6554 - acc: 0.7324 - val_loss: 0.4781 - val_acc: 0.7617\n",
      "Epoch 2/200\n",
      "323264/323431 [============================>.] - ETA: 0s - loss: 0.5623 - acc: 0.7793Epoch 00001: val_loss improved from 0.47807 to 0.44889, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 36s - loss: 0.5624 - acc: 0.7793 - val_loss: 0.4489 - val_acc: 0.7819\n",
      "Epoch 3/200\n",
      "323392/323431 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.8057Epoch 00002: val_loss improved from 0.44889 to 0.42090, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 31s - loss: 0.5070 - acc: 0.8057 - val_loss: 0.4209 - val_acc: 0.7976\n",
      "Epoch 4/200\n",
      "323264/323431 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8250Epoch 00003: val_loss improved from 0.42090 to 0.39662, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323431/323431 [==============================] - 31s - loss: 0.4631 - acc: 0.8249 - val_loss: 0.3966 - val_acc: 0.8115\n",
      "Epoch 5/200\n",
      "322880/323431 [============================>.] - ETA: 0s - loss: 0.4270 - acc: 0.8415Epoch 00004: val_loss did not improve\n",
      "323431/323431 [==============================] - 32s - loss: 0.4270 - acc: 0.8415 - val_loss: 0.4130 - val_acc: 0.8070\n",
      "Epoch 6/200\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3949 - acc: 0.8554Epoch 00005: val_loss did not improve\n",
      "323431/323431 [==============================] - 32s - loss: 0.3949 - acc: 0.8554 - val_loss: 0.4063 - val_acc: 0.8138\n",
      "Epoch 7/200\n",
      "322880/323431 [============================>.] - ETA: 0s - loss: 0.3657 - acc: 0.8674Epoch 00006: val_loss did not improve\n",
      "323431/323431 [==============================] - 31s - loss: 0.3658 - acc: 0.8673 - val_loss: 0.4208 - val_acc: 0.8087\n",
      "Epoch 8/200\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3395 - acc: 0.8782Epoch 00007: val_loss did not improve\n",
      "323431/323431 [==============================] - 31s - loss: 0.3395 - acc: 0.8782 - val_loss: 0.4229 - val_acc: 0.8161\n",
      "Epoch 00007: early stopping\n",
      "80224/80859 [============================>.] - ETA: 0s\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 323432 samples, validate on 80858 samples\n",
      "Epoch 1/200\n",
      "323200/323432 [============================>.] - ETA: 0s - loss: 0.6556 - acc: 0.7330Epoch 00000: val_loss improved from inf to 0.48025, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323432/323432 [==============================] - 32s - loss: 0.6555 - acc: 0.7331 - val_loss: 0.4803 - val_acc: 0.7577\n",
      "Epoch 2/200\n",
      "323392/323432 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.7797Epoch 00001: val_loss improved from 0.48025 to 0.43406, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323432/323432 [==============================] - 32s - loss: 0.5621 - acc: 0.7797 - val_loss: 0.4341 - val_acc: 0.7874\n",
      "Epoch 3/200\n",
      "323200/323432 [============================>.] - ETA: 0s - loss: 0.5062 - acc: 0.8053Epoch 00002: val_loss improved from 0.43406 to 0.41357, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323432/323432 [==============================] - 32s - loss: 0.5062 - acc: 0.8054 - val_loss: 0.4136 - val_acc: 0.8035\n",
      "Epoch 4/200\n",
      "323008/323432 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.8266Epoch 00003: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323432/323432 [==============================] - 31s - loss: 0.4617 - acc: 0.8266 - val_loss: 0.4157 - val_acc: 0.7969\n",
      "Epoch 5/200\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.4242 - acc: 0.8419Epoch 00004: val_loss improved from 0.41357 to 0.40583, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323432/323432 [==============================] - 33s - loss: 0.4242 - acc: 0.8419 - val_loss: 0.4058 - val_acc: 0.8080\n",
      "Epoch 6/200\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8567Epoch 00005: val_loss improved from 0.40583 to 0.40139, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323432/323432 [==============================] - 32s - loss: 0.3918 - acc: 0.8567 - val_loss: 0.4014 - val_acc: 0.8131\n",
      "Epoch 7/200\n",
      "323264/323432 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.8684Epoch 00006: val_loss improved from 0.40139 to 0.40101, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323432/323432 [==============================] - 32s - loss: 0.3636 - acc: 0.8683 - val_loss: 0.4010 - val_acc: 0.8136\n",
      "Epoch 8/200\n",
      "323264/323432 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8786Epoch 00007: val_loss did not improve\n",
      "323432/323432 [==============================] - 31s - loss: 0.3381 - acc: 0.8786 - val_loss: 0.4154 - val_acc: 0.8188\n",
      "Epoch 9/200\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8877Epoch 00008: val_loss did not improve\n",
      "323432/323432 [==============================] - 31s - loss: 0.3157 - acc: 0.8877 - val_loss: 0.4218 - val_acc: 0.8186\n",
      "Epoch 00008: early stopping\n",
      "80256/80858 [============================>.] - ETA: 0s\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 323433 samples, validate on 80857 samples\n",
      "Epoch 1/200\n",
      "322944/323433 [============================>.] - ETA: 0s - loss: 0.6558 - acc: 0.7321Epoch 00000: val_loss improved from inf to 0.47494, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 35s - loss: 0.6556 - acc: 0.7321 - val_loss: 0.4749 - val_acc: 0.7631\n",
      "Epoch 2/200\n",
      "323264/323433 [============================>.] - ETA: 0s - loss: 0.5611 - acc: 0.7796Epoch 00001: val_loss improved from 0.47494 to 0.44205, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 34s - loss: 0.5611 - acc: 0.7796 - val_loss: 0.4421 - val_acc: 0.7910\n",
      "Epoch 3/200\n",
      "323008/323433 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.8077Epoch 00002: val_loss improved from 0.44205 to 0.41089, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 33s - loss: 0.5048 - acc: 0.8077 - val_loss: 0.4109 - val_acc: 0.8040\n",
      "Epoch 4/200\n",
      "323392/323433 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8268Epoch 00003: val_loss did not improve\n",
      "323433/323433 [==============================] - 32s - loss: 0.4599 - acc: 0.8268 - val_loss: 0.4131 - val_acc: 0.8045\n",
      "Epoch 5/200\n",
      "323264/323433 [============================>.] - ETA: 0s - loss: 0.4234 - acc: 0.8421Epoch 00004: val_loss improved from 0.41089 to 0.40900, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 33s - loss: 0.4234 - acc: 0.8421 - val_loss: 0.4090 - val_acc: 0.8119\n",
      "Epoch 6/200\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.3910 - acc: 0.8564Epoch 00005: val_loss improved from 0.40900 to 0.40397, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 32s - loss: 0.3910 - acc: 0.8565 - val_loss: 0.4040 - val_acc: 0.8166\n",
      "Epoch 7/200\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8679Epoch 00006: val_loss improved from 0.40397 to 0.40081, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 35s - loss: 0.3635 - acc: 0.8679 - val_loss: 0.4008 - val_acc: 0.8207\n",
      "Epoch 8/200\n",
      "323008/323433 [============================>.] - ETA: 0s - loss: 0.3388 - acc: 0.8781Epoch 00007: val_loss did not improve\n",
      "323433/323433 [==============================] - 31s - loss: 0.3388 - acc: 0.8781 - val_loss: 0.4066 - val_acc: 0.8216\n",
      "Epoch 9/200\n",
      "322944/323433 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.8872Epoch 00008: val_loss did not improve\n",
      "323433/323433 [==============================] - 32s - loss: 0.3177 - acc: 0.8871 - val_loss: 0.4111 - val_acc: 0.8146\n",
      "Epoch 10/200\n",
      "322880/323433 [============================>.] - ETA: 0s - loss: 0.2979 - acc: 0.8942Epoch 00009: val_loss did not improve\n",
      "323433/323433 [==============================] - 32s - loss: 0.2979 - acc: 0.8942 - val_loss: 0.4406 - val_acc: 0.8185\n",
      "Epoch 00009: early stopping\n",
      "79776/80857 [============================>.] - ETA: 0s\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 323433 samples, validate on 80857 samples\n",
      "Epoch 1/200\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.6559 - acc: 0.7324Epoch 00000: val_loss improved from inf to 0.48162, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 37s - loss: 0.6560 - acc: 0.7324 - val_loss: 0.4816 - val_acc: 0.7591\n",
      "Epoch 2/200\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.5623 - acc: 0.7783Epoch 00001: val_loss improved from 0.48162 to 0.42963, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 35s - loss: 0.5622 - acc: 0.7783 - val_loss: 0.4296 - val_acc: 0.7910\n",
      "Epoch 3/200\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.5037 - acc: 0.8063Epoch 00002: val_loss improved from 0.42963 to 0.41191, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 33s - loss: 0.5037 - acc: 0.8063 - val_loss: 0.4119 - val_acc: 0.8016\n",
      "Epoch 4/200\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8264Epoch 00003: val_loss improved from 0.41191 to 0.41164, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 32s - loss: 0.4594 - acc: 0.8264 - val_loss: 0.4116 - val_acc: 0.8038\n",
      "Epoch 5/200\n",
      "322880/323433 [============================>.] - ETA: 0s - loss: 0.4234 - acc: 0.8418Epoch 00004: val_loss did not improve\n",
      "323433/323433 [==============================] - 32s - loss: 0.4235 - acc: 0.8418 - val_loss: 0.4121 - val_acc: 0.8054\n",
      "Epoch 6/200\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.3914 - acc: 0.8561Epoch 00005: val_loss improved from 0.41164 to 0.39682, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "323433/323433 [==============================] - 33s - loss: 0.3914 - acc: 0.8561 - val_loss: 0.3968 - val_acc: 0.8185\n",
      "Epoch 7/200\n",
      "323136/323433 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8680Epoch 00006: val_loss did not improve\n",
      "323433/323433 [==============================] - 35s - loss: 0.3638 - acc: 0.8680 - val_loss: 0.4050 - val_acc: 0.8170\n",
      "Epoch 8/200\n",
      "323392/323433 [============================>.] - ETA: 0s - loss: 0.3365 - acc: 0.8793Epoch 00007: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323433/323433 [==============================] - 38s - loss: 0.3365 - acc: 0.8794 - val_loss: 0.4272 - val_acc: 0.8122\n",
      "Epoch 9/200\n",
      "323136/323433 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.8884Epoch 00008: val_loss did not improve\n",
      "323433/323433 [==============================] - 37s - loss: 0.3145 - acc: 0.8884 - val_loss: 0.4021 - val_acc: 0.8238\n",
      "Epoch 10/200\n",
      "323264/323433 [============================>.] - ETA: 0s - loss: 0.2951 - acc: 0.8962Epoch 00009: val_loss did not improve\n",
      "323433/323433 [==============================] - 35s - loss: 0.2951 - acc: 0.8961 - val_loss: 0.4210 - val_acc: 0.8244\n",
      "Epoch 00009: early stopping\n",
      "80192/80857 [============================>.] - ETA: 0sCPU times: user 38min 27s, sys: 2min 15s, total: 40min 43s\n",
      "Wall time: 28min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_fold_train, ix_fold_val) in enumerate(kfold.split(X_train, y_train)):\n",
    "    X_fold_train = X_train[ix_fold_train]\n",
    "    y_fold_train = y_train[ix_fold_train]\n",
    "    \n",
    "    X_fold_val = X_train[ix_fold_val]\n",
    "    y_fold_val = y_train[ix_fold_val]\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        [X_fold_train[:, 0], X_fold_train[:, 1]], y_fold_train,\n",
    "        batch_size=64,\n",
    "        epochs=200,\n",
    "        validation_data=([X_fold_val[:, 0], X_fold_val[:, 1]], y_fold_val),\n",
    "        class_weight=keras_get_class_weights(y_fold_train),\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.005,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    y_pred_oofp = model.predict_proba([X_fold_val[:, 0], X_fold_val[:, 1]])[:, -1]\n",
    "    \n",
    "    # Remember them.\n",
    "    y_train_oofp[ix_fold_val] = y_pred_oofp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344832/2345796 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# It would be better to fit the model on the whole training set\n",
    "# but the validation set for early stopping would be an issue.\n",
    "y_test_oofp = model.predict_proba([X_test_q1, X_test_q2])[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = y_test_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
