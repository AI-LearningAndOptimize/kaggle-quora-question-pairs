{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_bradleypallen_mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    model_q1 = Sequential()\n",
    "\n",
    "    model_q1.add(Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    ))\n",
    "\n",
    "    model_q1.add(TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu',\n",
    "    )))\n",
    "\n",
    "    model_q1.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "    model_q2 = Sequential()\n",
    "\n",
    "    model_q2.add(Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    ))\n",
    "\n",
    "    model_q2.add(TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu'\n",
    "    )))\n",
    "\n",
    "    model_q2.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([model_q1, model_q2], mode='concat'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(params['num_dense_1']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(params['num_dense_2']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(params['num_dense_3']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(params['num_dense_4']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'num_dense_1': 500,\n",
    "    'num_dense_2': 225,\n",
    "    'num_dense_3': 500,\n",
    "    'num_dense_4': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X_q1, X_q2):\n",
    "    y1 = model.predict(\n",
    "        [X_q1, X_q2],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    y2 = model.predict(\n",
    "        [X_q2, X_q1],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    return (y1 + y2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646464/646862 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.7728Epoch 00000: val_loss improved from inf to 0.41351, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 76s - loss: 0.4630 - acc: 0.7728 - val_loss: 0.4135 - val_acc: 0.8014\n",
      "Epoch 2/200\n",
      "646464/646862 [============================>.] - ETA: 0s - loss: 0.3846 - acc: 0.8196Epoch 00001: val_loss improved from 0.41351 to 0.38431, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 77s - loss: 0.3846 - acc: 0.8196 - val_loss: 0.3843 - val_acc: 0.8191\n",
      "Epoch 3/200\n",
      "646528/646862 [============================>.] - ETA: 0s - loss: 0.3414 - acc: 0.8440Epoch 00002: val_loss improved from 0.38431 to 0.37390, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 77s - loss: 0.3414 - acc: 0.8440 - val_loss: 0.3739 - val_acc: 0.8273\n",
      "Epoch 4/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.8629Epoch 00003: val_loss improved from 0.37390 to 0.36512, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 76s - loss: 0.3074 - acc: 0.8629 - val_loss: 0.3651 - val_acc: 0.8333\n",
      "Epoch 5/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2799 - acc: 0.8772Epoch 00004: val_loss improved from 0.36512 to 0.36448, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 77s - loss: 0.2799 - acc: 0.8772 - val_loss: 0.3645 - val_acc: 0.8373\n",
      "Epoch 6/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.8896Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 77s - loss: 0.2552 - acc: 0.8896 - val_loss: 0.3709 - val_acc: 0.8399\n",
      "Epoch 7/200\n",
      "646464/646862 [============================>.] - ETA: 0s - loss: 0.2347 - acc: 0.8992Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 76s - loss: 0.2347 - acc: 0.8992 - val_loss: 0.3729 - val_acc: 0.8389\n",
      "Epoch 8/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9086Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 77s - loss: 0.2156 - acc: 0.9086 - val_loss: 0.3898 - val_acc: 0.8405\n",
      "Epoch 00007: early stopping\n",
      "2344960/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.4625 - acc: 0.7730Epoch 00000: val_loss improved from inf to 0.41581, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 78s - loss: 0.4625 - acc: 0.7730 - val_loss: 0.4158 - val_acc: 0.7994\n",
      "Epoch 2/200\n",
      "646528/646862 [============================>.] - ETA: 0s - loss: 0.3852 - acc: 0.8194Epoch 00001: val_loss improved from 0.41581 to 0.38401, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 76s - loss: 0.3852 - acc: 0.8194 - val_loss: 0.3840 - val_acc: 0.8202\n",
      "Epoch 3/200\n",
      "646400/646862 [============================>.] - ETA: 0s - loss: 0.3413 - acc: 0.8444Epoch 00002: val_loss improved from 0.38401 to 0.37214, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 77s - loss: 0.3413 - acc: 0.8443 - val_loss: 0.3721 - val_acc: 0.8283\n",
      "Epoch 4/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.8622Epoch 00003: val_loss improved from 0.37214 to 0.36676, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646862/646862 [==============================] - 77s - loss: 0.3082 - acc: 0.8622 - val_loss: 0.3668 - val_acc: 0.8318\n",
      "Epoch 5/200\n",
      "646592/646862 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.8763Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 77s - loss: 0.2801 - acc: 0.8763 - val_loss: 0.3695 - val_acc: 0.8369\n",
      "Epoch 6/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2565 - acc: 0.8881Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 76s - loss: 0.2564 - acc: 0.8881 - val_loss: 0.3686 - val_acc: 0.8401\n",
      "Epoch 7/200\n",
      "646400/646862 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.8983Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 77s - loss: 0.2354 - acc: 0.8983 - val_loss: 0.3815 - val_acc: 0.8404\n",
      "Epoch 8/200\n",
      "646464/646862 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9070Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 77s - loss: 0.2169 - acc: 0.9070 - val_loss: 0.3977 - val_acc: 0.8408\n",
      "Epoch 00007: early stopping\n",
      "2343936/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 646864 samples, validate on 161716 samples\n",
      "Epoch 1/200\n",
      "646464/646864 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.7723Epoch 00000: val_loss improved from inf to 0.41691, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646864/646864 [==============================] - 76s - loss: 0.4630 - acc: 0.7723 - val_loss: 0.4169 - val_acc: 0.7991\n",
      "Epoch 2/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.3849 - acc: 0.8193Epoch 00001: val_loss improved from 0.41691 to 0.38580, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646864/646864 [==============================] - 77s - loss: 0.3849 - acc: 0.8193 - val_loss: 0.3858 - val_acc: 0.8187\n",
      "Epoch 3/200\n",
      "646400/646864 [============================>.] - ETA: 0s - loss: 0.3411 - acc: 0.8441Epoch 00002: val_loss improved from 0.38580 to 0.37416, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646864/646864 [==============================] - 77s - loss: 0.3411 - acc: 0.8441 - val_loss: 0.3742 - val_acc: 0.8260\n",
      "Epoch 4/200\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.8621Epoch 00003: val_loss improved from 0.37416 to 0.36723, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646864/646864 [==============================] - 76s - loss: 0.3078 - acc: 0.8621 - val_loss: 0.3672 - val_acc: 0.8330\n",
      "Epoch 5/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.2797 - acc: 0.8767Epoch 00004: val_loss improved from 0.36723 to 0.36290, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646864/646864 [==============================] - 77s - loss: 0.2797 - acc: 0.8767 - val_loss: 0.3629 - val_acc: 0.8378\n",
      "Epoch 6/200\n",
      "646528/646864 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.8888Epoch 00005: val_loss did not improve\n",
      "646864/646864 [==============================] - 77s - loss: 0.2560 - acc: 0.8888 - val_loss: 0.3731 - val_acc: 0.8373\n",
      "Epoch 7/200\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.8990Epoch 00006: val_loss did not improve\n",
      "646864/646864 [==============================] - 76s - loss: 0.2346 - acc: 0.8990 - val_loss: 0.3855 - val_acc: 0.8410\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646464/646864 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9075Epoch 00007: val_loss did not improve\n",
      "646864/646864 [==============================] - 76s - loss: 0.2165 - acc: 0.9074 - val_loss: 0.3992 - val_acc: 0.8392\n",
      "Epoch 9/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9156Epoch 00008: val_loss did not improve\n",
      "646864/646864 [==============================] - 77s - loss: 0.2001 - acc: 0.9156 - val_loss: 0.4033 - val_acc: 0.8435\n",
      "Epoch 00008: early stopping\n",
      "2343936/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.7737Epoch 00000: val_loss improved from inf to 0.40862, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646866/646866 [==============================] - 77s - loss: 0.4617 - acc: 0.7737 - val_loss: 0.4086 - val_acc: 0.8033\n",
      "Epoch 2/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3838 - acc: 0.8202Epoch 00001: val_loss improved from 0.40862 to 0.37984, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646866/646866 [==============================] - 76s - loss: 0.3838 - acc: 0.8202 - val_loss: 0.3798 - val_acc: 0.8204\n",
      "Epoch 3/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8446Epoch 00002: val_loss improved from 0.37984 to 0.36461, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646866/646866 [==============================] - 77s - loss: 0.3412 - acc: 0.8446 - val_loss: 0.3646 - val_acc: 0.8319\n",
      "Epoch 4/200\n",
      "646464/646866 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.8625Epoch 00003: val_loss improved from 0.36461 to 0.36277, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646866/646866 [==============================] - 77s - loss: 0.3074 - acc: 0.8625 - val_loss: 0.3628 - val_acc: 0.8331\n",
      "Epoch 5/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2796 - acc: 0.8771Epoch 00004: val_loss did not improve\n",
      "646866/646866 [==============================] - 76s - loss: 0.2796 - acc: 0.8771 - val_loss: 0.3638 - val_acc: 0.8386\n",
      "Epoch 6/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.8896Epoch 00005: val_loss did not improve\n",
      "646866/646866 [==============================] - 77s - loss: 0.2547 - acc: 0.8896 - val_loss: 0.3710 - val_acc: 0.8417\n",
      "Epoch 7/200\n",
      "646528/646866 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.8992Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 77s - loss: 0.2342 - acc: 0.8992 - val_loss: 0.3760 - val_acc: 0.8392\n",
      "Epoch 8/200\n",
      "646592/646866 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9079Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 76s - loss: 0.2161 - acc: 0.9079 - val_loss: 0.3890 - val_acc: 0.8411\n",
      "Epoch 00007: early stopping\n",
      "2341888/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.4638 - acc: 0.7724Epoch 00000: val_loss improved from inf to 0.41362, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646866/646866 [==============================] - 78s - loss: 0.4638 - acc: 0.7724 - val_loss: 0.4136 - val_acc: 0.8017\n",
      "Epoch 2/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8190Epoch 00001: val_loss improved from 0.41362 to 0.38261, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646866/646866 [==============================] - 78s - loss: 0.3850 - acc: 0.8190 - val_loss: 0.3826 - val_acc: 0.8213\n",
      "Epoch 3/200\n",
      "646528/646866 [============================>.] - ETA: 0s - loss: 0.3419 - acc: 0.8439Epoch 00002: val_loss improved from 0.38261 to 0.36444, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp.h5\n",
      "646866/646866 [==============================] - 78s - loss: 0.3418 - acc: 0.8439 - val_loss: 0.3644 - val_acc: 0.8313\n",
      "Epoch 4/200\n",
      "646400/646866 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.8617Epoch 00003: val_loss did not improve\n",
      "646866/646866 [==============================] - 77s - loss: 0.3088 - acc: 0.8617 - val_loss: 0.3699 - val_acc: 0.8353\n",
      "Epoch 5/200\n",
      "646400/646866 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.8762Epoch 00004: val_loss did not improve\n",
      "646866/646866 [==============================] - 77s - loss: 0.2806 - acc: 0.8762 - val_loss: 0.3663 - val_acc: 0.8392\n",
      "Epoch 6/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.8883Epoch 00005: val_loss did not improve\n",
      "646866/646866 [==============================] - 77s - loss: 0.2561 - acc: 0.8883 - val_loss: 0.3726 - val_acc: 0.8384\n",
      "Epoch 7/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.8988Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 77s - loss: 0.2352 - acc: 0.8988 - val_loss: 0.3813 - val_acc: 0.8406\n",
      "Epoch 00006: early stopping\n",
      "2342912/2345796 [============================>.] - ETA: 0sCPU times: user 1h 13min 24s, sys: 4min 11s, total: 1h 17min 35s\n",
      "Wall time: 54min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model(model_params)\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "#         class_weight=keras_get_class_weights(y_fold_val),\n",
    "\n",
    "        batch_size=64,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "        \n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_train_oofp[ix_val] = predict(model, X_train_q1[ix_val], X_train_q2[ix_val])\n",
    "    y_test_oofp[:, fold_num] = predict(model, X_test_q1, X_test_q2)\n",
    "    \n",
    "    # Clear GPU memory.\n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_bradleypallen_mlp',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp_mean = np.mean(y_test_oofp, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp_mean, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
