{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_bradleypallen_mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    model_q1 = Sequential()\n",
    "\n",
    "    model_q1.add(Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    ))\n",
    "\n",
    "    model_q1.add(TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu',\n",
    "    )))\n",
    "\n",
    "    model_q1.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "    model_q2 = Sequential()\n",
    "\n",
    "    model_q2.add(Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    ))\n",
    "\n",
    "    model_q2.add(TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu'\n",
    "    )))\n",
    "\n",
    "    model_q2.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([model_q1, model_q2], mode='concat'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(params['num_dense_1']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(params['num_dense_2']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(params['num_dense_3']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(params['num_dense_4']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'num_dense_1': 500,\n",
    "    'num_dense_2': 225,\n",
    "    'num_dense_3': 500,\n",
    "    'num_dense_4': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X_q1, X_q2):\n",
    "    y1 = model.predict(\n",
    "        [X_q1, X_q2],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    y2 = model.predict(\n",
    "        [X_q2, X_q1],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    return (y1 + y2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646400/646862 [============================>.] - ETA: 0s - loss: 0.6082 - acc: 0.7572Epoch 00000: val_loss improved from inf to 0.43875, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 73s - loss: 0.6082 - acc: 0.7572 - val_loss: 0.4387 - val_acc: 0.7857\n",
      "Epoch 2/200\n",
      "646528/646862 [============================>.] - ETA: 0s - loss: 0.5027 - acc: 0.8079Epoch 00001: val_loss improved from 0.43875 to 0.40932, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 72s - loss: 0.5027 - acc: 0.8079 - val_loss: 0.4093 - val_acc: 0.8039\n",
      "Epoch 3/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.4449 - acc: 0.8337Epoch 00002: val_loss improved from 0.40932 to 0.39576, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 73s - loss: 0.4449 - acc: 0.8337 - val_loss: 0.3958 - val_acc: 0.8167\n",
      "Epoch 4/200\n",
      "646592/646862 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8530Epoch 00003: val_loss did not improve\n",
      "646862/646862 [==============================] - 73s - loss: 0.4015 - acc: 0.8530 - val_loss: 0.3966 - val_acc: 0.8185\n",
      "Epoch 5/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.3649 - acc: 0.8676Epoch 00004: val_loss improved from 0.39576 to 0.38146, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 73s - loss: 0.3649 - acc: 0.8676 - val_loss: 0.3815 - val_acc: 0.8282\n",
      "Epoch 6/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3336 - acc: 0.8810Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 72s - loss: 0.3336 - acc: 0.8810 - val_loss: 0.3867 - val_acc: 0.8310\n",
      "Epoch 7/200\n",
      "646400/646862 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.8910Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 73s - loss: 0.3069 - acc: 0.8910 - val_loss: 0.3880 - val_acc: 0.8333\n",
      "Epoch 8/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2827 - acc: 0.9006Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 73s - loss: 0.2827 - acc: 0.9006 - val_loss: 0.4128 - val_acc: 0.8349\n",
      "Epoch 9/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2626 - acc: 0.9085Epoch 00008: val_loss did not improve\n",
      "646862/646862 [==============================] - 72s - loss: 0.2626 - acc: 0.9085 - val_loss: 0.4198 - val_acc: 0.8337\n",
      "Epoch 00008: early stopping\n",
      "2340864/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.7573Epoch 00000: val_loss improved from inf to 0.43028, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 74s - loss: 0.6085 - acc: 0.7573 - val_loss: 0.4303 - val_acc: 0.7924\n",
      "Epoch 2/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.5032 - acc: 0.8079Epoch 00001: val_loss improved from 0.43028 to 0.41546, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 73s - loss: 0.5031 - acc: 0.8079 - val_loss: 0.4155 - val_acc: 0.8029\n",
      "Epoch 3/200\n",
      "646400/646862 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8346Epoch 00002: val_loss improved from 0.41546 to 0.38744, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 73s - loss: 0.4444 - acc: 0.8346 - val_loss: 0.3874 - val_acc: 0.8181\n",
      "Epoch 4/200\n",
      "646528/646862 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8528Epoch 00003: val_loss improved from 0.38744 to 0.38365, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646862/646862 [==============================] - 74s - loss: 0.4011 - acc: 0.8528 - val_loss: 0.3837 - val_acc: 0.8244\n",
      "Epoch 5/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3664 - acc: 0.8677Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 73s - loss: 0.3664 - acc: 0.8677 - val_loss: 0.3870 - val_acc: 0.8248\n",
      "Epoch 6/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.3346 - acc: 0.8801Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 73s - loss: 0.3346 - acc: 0.8801 - val_loss: 0.3970 - val_acc: 0.8257\n",
      "Epoch 7/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.8908Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 73s - loss: 0.3078 - acc: 0.8908 - val_loss: 0.4017 - val_acc: 0.8301\n",
      "Epoch 8/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2853 - acc: 0.8998Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 73s - loss: 0.2853 - acc: 0.8998 - val_loss: 0.4035 - val_acc: 0.8335\n",
      "Epoch 00007: early stopping\n",
      "2338816/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 646864 samples, validate on 161716 samples\n",
      "Epoch 1/200\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.7568Epoch 00000: val_loss improved from inf to 0.43735, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646864/646864 [==============================] - 73s - loss: 0.6097 - acc: 0.7568 - val_loss: 0.4374 - val_acc: 0.7881\n",
      "Epoch 2/200\n",
      "646528/646864 [============================>.] - ETA: 0s - loss: 0.5030 - acc: 0.8072Epoch 00001: val_loss improved from 0.43735 to 0.41151, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646864/646864 [==============================] - 73s - loss: 0.5031 - acc: 0.8072 - val_loss: 0.4115 - val_acc: 0.8022\n",
      "Epoch 3/200\n",
      "646464/646864 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8328Epoch 00002: val_loss improved from 0.41151 to 0.39239, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646864/646864 [==============================] - 73s - loss: 0.4451 - acc: 0.8328 - val_loss: 0.3924 - val_acc: 0.8148\n",
      "Epoch 4/200\n",
      "646528/646864 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8534Epoch 00003: val_loss did not improve\n",
      "646864/646864 [==============================] - 72s - loss: 0.4003 - acc: 0.8534 - val_loss: 0.3978 - val_acc: 0.8172\n",
      "Epoch 5/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8680Epoch 00004: val_loss did not improve\n",
      "646864/646864 [==============================] - 72s - loss: 0.3638 - acc: 0.8680 - val_loss: 0.3927 - val_acc: 0.8242\n",
      "Epoch 6/200\n",
      "646528/646864 [============================>.] - ETA: 0s - loss: 0.3333 - acc: 0.8803Epoch 00005: val_loss improved from 0.39239 to 0.38729, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646864/646864 [==============================] - 73s - loss: 0.3334 - acc: 0.8803 - val_loss: 0.3873 - val_acc: 0.8312\n",
      "Epoch 7/200\n",
      "646464/646864 [============================>.] - ETA: 0s - loss: 0.3060 - acc: 0.8916Epoch 00006: val_loss did not improve\n",
      "646864/646864 [==============================] - 72s - loss: 0.3061 - acc: 0.8916 - val_loss: 0.4010 - val_acc: 0.8316\n",
      "Epoch 8/200\n",
      "646400/646864 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.9010Epoch 00007: val_loss did not improve\n",
      "646864/646864 [==============================] - 72s - loss: 0.2832 - acc: 0.9010 - val_loss: 0.3975 - val_acc: 0.8333\n",
      "Epoch 9/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.2618 - acc: 0.9091Epoch 00008: val_loss did not improve\n",
      "646864/646864 [==============================] - 72s - loss: 0.2618 - acc: 0.9091 - val_loss: 0.4182 - val_acc: 0.8342\n",
      "Epoch 10/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9157Epoch 00009: val_loss did not improve\n",
      "646864/646864 [==============================] - 72s - loss: 0.2445 - acc: 0.9157 - val_loss: 0.4425 - val_acc: 0.8354\n",
      "Epoch 00009: early stopping\n",
      "2342912/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.7556Epoch 00000: val_loss improved from inf to 0.42751, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646866/646866 [==============================] - 73s - loss: 0.6113 - acc: 0.7556 - val_loss: 0.4275 - val_acc: 0.7894\n",
      "Epoch 2/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.8061Epoch 00001: val_loss improved from 0.42751 to 0.41072, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646866/646866 [==============================] - 73s - loss: 0.5059 - acc: 0.8061 - val_loss: 0.4107 - val_acc: 0.8062\n",
      "Epoch 3/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8336Epoch 00002: val_loss improved from 0.41072 to 0.38797, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646866/646866 [==============================] - 80s - loss: 0.4471 - acc: 0.8336 - val_loss: 0.3880 - val_acc: 0.8198\n",
      "Epoch 4/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.4035 - acc: 0.8523Epoch 00003: val_loss improved from 0.38797 to 0.37624, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646866/646866 [==============================] - 115s - loss: 0.4035 - acc: 0.8522 - val_loss: 0.3762 - val_acc: 0.8285\n",
      "Epoch 5/200\n",
      "646464/646866 [============================>.] - ETA: 0s - loss: 0.3666 - acc: 0.8675Epoch 00004: val_loss did not improve\n",
      "646866/646866 [==============================] - 72s - loss: 0.3666 - acc: 0.8675 - val_loss: 0.3843 - val_acc: 0.8269\n",
      "Epoch 6/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8800Epoch 00005: val_loss did not improve\n",
      "646866/646866 [==============================] - 73s - loss: 0.3344 - acc: 0.8800 - val_loss: 0.3907 - val_acc: 0.8292\n",
      "Epoch 7/200\n",
      "646400/646866 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.8907Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 72s - loss: 0.3078 - acc: 0.8907 - val_loss: 0.4071 - val_acc: 0.8314\n",
      "Epoch 8/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9000Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 72s - loss: 0.2842 - acc: 0.9000 - val_loss: 0.4049 - val_acc: 0.8333\n",
      "Epoch 00007: early stopping\n",
      "2342912/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.6112 - acc: 0.7551Epoch 00000: val_loss improved from inf to 0.44115, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646866/646866 [==============================] - 97s - loss: 0.6112 - acc: 0.7551 - val_loss: 0.4411 - val_acc: 0.7845\n",
      "Epoch 2/200\n",
      "646592/646866 [============================>.] - ETA: 0s - loss: 0.5050 - acc: 0.8071Epoch 00001: val_loss improved from 0.44115 to 0.40073, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646866/646866 [==============================] - 104s - loss: 0.5050 - acc: 0.8071 - val_loss: 0.4007 - val_acc: 0.8076\n",
      "Epoch 3/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.4469 - acc: 0.8329Epoch 00002: val_loss improved from 0.40073 to 0.38485, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_nn_concat_dense_1.h5\n",
      "646866/646866 [==============================] - 132s - loss: 0.4468 - acc: 0.8330 - val_loss: 0.3848 - val_acc: 0.8207\n",
      "Epoch 4/200\n",
      "646528/646866 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8523Epoch 00003: val_loss did not improve\n",
      "646866/646866 [==============================] - 72s - loss: 0.4028 - acc: 0.8523 - val_loss: 0.3863 - val_acc: 0.8255\n",
      "Epoch 5/200\n",
      "646464/646866 [============================>.] - ETA: 0s - loss: 0.3655 - acc: 0.8678Epoch 00004: val_loss did not improve\n",
      "646866/646866 [==============================] - 72s - loss: 0.3655 - acc: 0.8678 - val_loss: 0.3920 - val_acc: 0.8283\n",
      "Epoch 6/200\n",
      "646528/646866 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.8802Epoch 00005: val_loss did not improve\n",
      "646866/646866 [==============================] - 71s - loss: 0.3348 - acc: 0.8802 - val_loss: 0.3918 - val_acc: 0.8280\n",
      "Epoch 7/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.8908Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 74s - loss: 0.3075 - acc: 0.8908 - val_loss: 0.4015 - val_acc: 0.8321\n",
      "Epoch 00006: early stopping\n",
      "2340864/2345796 [============================>.] - ETA: 0sCPU times: user 1h 13min 48s, sys: 11min 51s, total: 1h 25min 40s\n",
      "Wall time: 1h 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model(model_params)\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "        class_weight=keras_get_class_weights(y_fold_val),\n",
    "\n",
    "        batch_size=64,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "        \n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_train_oofp[ix_val] = predict(model, X_train_q1[ix_val], X_train_q2[ix_val])\n",
    "    y_test_oofp[:, fold_num] = predict(model, X_test_q1, X_test_q2)\n",
    "    \n",
    "    # Clear GPU memory.\n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_bradleypallen_mlp',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp_mean = np.mean(y_test_oofp, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp_mean, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
