{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_bradleypallen_mlp_magic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "magic_feature_lists = [\n",
    "    'magic_jturkewitz',\n",
    "    'magic_stas_svd_150',\n",
    "    'magic_stas_avito',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic, X_test_magic, _ = load_feature_lists(magic_feature_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic = X_train_magic.values\n",
    "X_test_magic = X_test_magic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack([X_train_magic, X_test_magic]))\n",
    "X_train_magic = scaler.transform(X_train_magic)\n",
    "X_test_magic = scaler.transform(X_test_magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_question_branch():\n",
    "    input_q = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    \n",
    "    embedding_q = Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    )(input_q)\n",
    "\n",
    "    timedist_q = TimeDistributed(Dense(\n",
    "        EMBEDDING_DIM,\n",
    "        activation='relu',\n",
    "    ))(embedding_q)\n",
    "\n",
    "    lambda_q = Lambda(\n",
    "        lambda x: K.max(x, axis=1),\n",
    "        output_shape=(EMBEDDING_DIM, )\n",
    "    )(timedist_q)\n",
    "    \n",
    "    output_q = lambda_q\n",
    "    return input_q, output_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    q1_input, q1_output = create_model_question_branch()\n",
    "    q2_input, q2_output = create_model_question_branch()\n",
    "    magic_input = Input(shape=(X_train_magic.shape[-1], ))\n",
    "    \n",
    "    merged_inputs = concatenate([q1_output, q2_output, magic_input])\n",
    "\n",
    "    dense_1 = Dense(params['num_dense_1'])(merged_inputs)\n",
    "    bn_1 = BatchNormalization()(dense_1)\n",
    "    relu_1 = Activation('relu')(bn_1)\n",
    "\n",
    "    dense_2 = Dense(params['num_dense_2'])(relu_1)\n",
    "    bn_2 = BatchNormalization()(dense_2)\n",
    "    relu_2 = Activation('relu')(bn_2)\n",
    "\n",
    "    dense_3 = Dense(params['num_dense_3'])(relu_2)\n",
    "    bn_3 = BatchNormalization()(dense_3)\n",
    "    relu_3 = Activation('relu')(bn_3)\n",
    "\n",
    "    dense_4 = Dense(params['num_dense_4'])(relu_3)\n",
    "    bn_4 = BatchNormalization()(dense_4)\n",
    "    relu_4 = Activation('relu')(bn_4)\n",
    "\n",
    "    bn_final = BatchNormalization()(relu_4)\n",
    "    output = Dense(1, activation='sigmoid')(bn_final)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[q1_input, q2_input, magic_input],\n",
    "        outputs=output,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'num_dense_1': 400,\n",
    "    'num_dense_2': 200,\n",
    "    'num_dense_3': 400,\n",
    "    'num_dense_4': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X_q1, X_q2, X_magic):\n",
    "    y1 = model.predict(\n",
    "        [X_q1, X_q2, X_magic],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    y2 = model.predict(\n",
    "        [X_q2, X_q1, X_magic],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    return (y1 + y2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646464/646862 [============================>.] - ETA: 0s - loss: 0.3364 - acc: 0.8501Epoch 00000: val_loss improved from inf to 0.30819, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646862/646862 [==============================] - 68s - loss: 0.3364 - acc: 0.8501 - val_loss: 0.3082 - val_acc: 0.8600\n",
      "Epoch 2/200\n",
      "646400/646862 [============================>.] - ETA: 0s - loss: 0.2847 - acc: 0.8723Epoch 00001: val_loss improved from 0.30819 to 0.29586, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646862/646862 [==============================] - 68s - loss: 0.2847 - acc: 0.8724 - val_loss: 0.2959 - val_acc: 0.8693\n",
      "Epoch 3/200\n",
      "646592/646862 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.8867Epoch 00002: val_loss improved from 0.29586 to 0.28268, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646862/646862 [==============================] - 68s - loss: 0.2554 - acc: 0.8867 - val_loss: 0.2827 - val_acc: 0.8749\n",
      "Epoch 4/200\n",
      "646528/646862 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.8976Epoch 00003: val_loss did not improve\n",
      "646862/646862 [==============================] - 67s - loss: 0.2320 - acc: 0.8976 - val_loss: 0.3019 - val_acc: 0.8626\n",
      "Epoch 5/200\n",
      "646400/646862 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9080Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 66s - loss: 0.2111 - acc: 0.9080 - val_loss: 0.2882 - val_acc: 0.8719\n",
      "Epoch 6/200\n",
      "646336/646862 [============================>.] - ETA: 0s - loss: 0.1929 - acc: 0.9163Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 62s - loss: 0.1930 - acc: 0.9163 - val_loss: 0.2888 - val_acc: 0.8744\n",
      "Epoch 7/200\n",
      "646528/646862 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9242Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 62s - loss: 0.1757 - acc: 0.9242 - val_loss: 0.3136 - val_acc: 0.8629\n",
      "Epoch 00006: early stopping\n",
      "2343936/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.8505Epoch 00000: val_loss improved from inf to 0.33247, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646862/646862 [==============================] - 62s - loss: 0.3367 - acc: 0.8505 - val_loss: 0.3325 - val_acc: 0.8495\n",
      "Epoch 2/200\n",
      "646592/646862 [============================>.] - ETA: 0s - loss: 0.2857 - acc: 0.8722Epoch 00001: val_loss improved from 0.33247 to 0.32816, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646862/646862 [==============================] - 62s - loss: 0.2857 - acc: 0.8722 - val_loss: 0.3282 - val_acc: 0.8606\n",
      "Epoch 3/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2565 - acc: 0.8862Epoch 00002: val_loss improved from 0.32816 to 0.29209, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646862/646862 [==============================] - 64s - loss: 0.2565 - acc: 0.8861 - val_loss: 0.2921 - val_acc: 0.8678\n",
      "Epoch 4/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2325 - acc: 0.8976Epoch 00003: val_loss improved from 0.29209 to 0.29086, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646862/646862 [==============================] - 68s - loss: 0.2325 - acc: 0.8976 - val_loss: 0.2909 - val_acc: 0.8731\n",
      "Epoch 5/200\n",
      "646464/646862 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9076Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 68s - loss: 0.2111 - acc: 0.9076 - val_loss: 0.2961 - val_acc: 0.8717\n",
      "Epoch 6/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9168Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 67s - loss: 0.1923 - acc: 0.9168 - val_loss: 0.3009 - val_acc: 0.8736\n",
      "Epoch 7/200\n",
      "646464/646862 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9246Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 68s - loss: 0.1753 - acc: 0.9246 - val_loss: 0.3230 - val_acc: 0.8727\n",
      "Epoch 8/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9309Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 68s - loss: 0.1613 - acc: 0.9309 - val_loss: 0.3191 - val_acc: 0.8735\n",
      "Epoch 00007: early stopping\n",
      "2338816/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 646864 samples, validate on 161716 samples\n",
      "Epoch 1/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.8503Epoch 00000: val_loss improved from inf to 0.31671, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646864/646864 [==============================] - 68s - loss: 0.3367 - acc: 0.8503 - val_loss: 0.3167 - val_acc: 0.8583\n",
      "Epoch 2/200\n",
      "646336/646864 [============================>.] - ETA: 0s - loss: 0.2838 - acc: 0.8733Epoch 00001: val_loss improved from 0.31671 to 0.29822, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646864/646864 [==============================] - 68s - loss: 0.2838 - acc: 0.8733 - val_loss: 0.2982 - val_acc: 0.8688\n",
      "Epoch 3/200\n",
      "646400/646864 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.8874Epoch 00002: val_loss improved from 0.29822 to 0.28190, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646864/646864 [==============================] - 68s - loss: 0.2546 - acc: 0.8874 - val_loss: 0.2819 - val_acc: 0.8744\n",
      "Epoch 4/200\n",
      "646400/646864 [============================>.] - ETA: 0s - loss: 0.2310 - acc: 0.8985Epoch 00003: val_loss did not improve\n",
      "646864/646864 [==============================] - 68s - loss: 0.2310 - acc: 0.8985 - val_loss: 0.2851 - val_acc: 0.8753\n",
      "Epoch 5/200\n",
      "646592/646864 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9085Epoch 00004: val_loss improved from 0.28190 to 0.27979, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646864/646864 [==============================] - 68s - loss: 0.2100 - acc: 0.9085 - val_loss: 0.2798 - val_acc: 0.8766\n",
      "Epoch 6/200\n",
      "646784/646864 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9173Epoch 00005: val_loss did not improve\n",
      "646864/646864 [==============================] - 68s - loss: 0.1910 - acc: 0.9173 - val_loss: 0.2946 - val_acc: 0.8768\n",
      "Epoch 7/200\n",
      "646528/646864 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9252Epoch 00006: val_loss did not improve\n",
      "646864/646864 [==============================] - 68s - loss: 0.1742 - acc: 0.9252 - val_loss: 0.3103 - val_acc: 0.8750\n",
      "Epoch 8/200\n",
      "646528/646864 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9318Epoch 00007: val_loss did not improve\n",
      "646864/646864 [==============================] - 68s - loss: 0.1594 - acc: 0.9318 - val_loss: 0.3224 - val_acc: 0.8723\n",
      "Epoch 9/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9378Epoch 00008: val_loss did not improve\n",
      "646864/646864 [==============================] - 68s - loss: 0.1462 - acc: 0.9378 - val_loss: 0.3252 - val_acc: 0.8734\n",
      "Epoch 00008: early stopping\n",
      "2339840/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646464/646866 [============================>.] - ETA: 0s - loss: 0.3369 - acc: 0.8504Epoch 00000: val_loss improved from inf to 0.30349, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646866/646866 [==============================] - 69s - loss: 0.3369 - acc: 0.8504 - val_loss: 0.3035 - val_acc: 0.8637\n",
      "Epoch 2/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2856 - acc: 0.8729Epoch 00001: val_loss improved from 0.30349 to 0.29093, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646866/646866 [==============================] - 68s - loss: 0.2857 - acc: 0.8729 - val_loss: 0.2909 - val_acc: 0.8702\n",
      "Epoch 3/200\n",
      "646400/646866 [============================>.] - ETA: 0s - loss: 0.2569 - acc: 0.8865Epoch 00002: val_loss improved from 0.29093 to 0.28091, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646866/646866 [==============================] - 68s - loss: 0.2568 - acc: 0.8865 - val_loss: 0.2809 - val_acc: 0.8750\n",
      "Epoch 4/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.8978Epoch 00003: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.2332 - acc: 0.8978 - val_loss: 0.2864 - val_acc: 0.8772\n",
      "Epoch 5/200\n",
      "646464/646866 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9072Epoch 00004: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.2128 - acc: 0.9072 - val_loss: 0.2871 - val_acc: 0.8785\n",
      "Epoch 6/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9164Epoch 00005: val_loss improved from 0.28091 to 0.27868, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646866/646866 [==============================] - 68s - loss: 0.1941 - acc: 0.9164 - val_loss: 0.2787 - val_acc: 0.8811\n",
      "Epoch 7/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9236Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.1779 - acc: 0.9236 - val_loss: 0.2898 - val_acc: 0.8781\n",
      "Epoch 8/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9303Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.1627 - acc: 0.9303 - val_loss: 0.3136 - val_acc: 0.8725\n",
      "Epoch 9/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9365Epoch 00008: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.1500 - acc: 0.9365 - val_loss: 0.3280 - val_acc: 0.8727\n",
      "Epoch 10/200\n",
      "646464/646866 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9411Epoch 00009: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.1388 - acc: 0.9411 - val_loss: 0.3354 - val_acc: 0.8762\n",
      "Epoch 00009: early stopping\n",
      "2339840/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646336/646866 [============================>.] - ETA: 0s - loss: 0.3352 - acc: 0.8506Epoch 00000: val_loss improved from inf to 0.31026, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646866/646866 [==============================] - 68s - loss: 0.3352 - acc: 0.8506 - val_loss: 0.3103 - val_acc: 0.8597\n",
      "Epoch 2/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.2843 - acc: 0.8732Epoch 00001: val_loss improved from 0.31026 to 0.28476, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646866/646866 [==============================] - 68s - loss: 0.2843 - acc: 0.8732 - val_loss: 0.2848 - val_acc: 0.8726\n",
      "Epoch 3/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.2559 - acc: 0.8870Epoch 00002: val_loss improved from 0.28476 to 0.27764, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_bradleypallen_mlp_magic.h5\n",
      "646866/646866 [==============================] - 69s - loss: 0.2559 - acc: 0.8870 - val_loss: 0.2776 - val_acc: 0.8762\n",
      "Epoch 4/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.8982Epoch 00003: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.2321 - acc: 0.8982 - val_loss: 0.2921 - val_acc: 0.8768\n",
      "Epoch 5/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9076Epoch 00004: val_loss did not improve\n",
      "646866/646866 [==============================] - 67s - loss: 0.2123 - acc: 0.9076 - val_loss: 0.2819 - val_acc: 0.8793\n",
      "Epoch 6/200\n",
      "646528/646866 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9167Epoch 00005: val_loss did not improve\n",
      "646866/646866 [==============================] - 68s - loss: 0.1936 - acc: 0.9167 - val_loss: 0.2914 - val_acc: 0.8784\n",
      "Epoch 7/200\n",
      "646592/646866 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9237Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 67s - loss: 0.1774 - acc: 0.9237 - val_loss: 0.2921 - val_acc: 0.8787\n",
      "Epoch 00006: early stopping\n",
      "2339840/2345796 [============================>.] - ETA: 0sCPU times: user 1h 6min 16s, sys: 4min, total: 1h 10min 17s\n",
      "Wall time: 49min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "    X_fold_train_magic = np.vstack([X_train_magic[ix_train], X_train_magic[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "    X_fold_val_magic = np.vstack([X_train_magic[ix_val], X_train_magic[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model(model_params)\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2, X_fold_train_magic], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2, X_fold_val_magic], y_fold_val),\n",
    "\n",
    "        batch_size=64,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "        \n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_train_oofp[ix_val] = predict(model, X_train_q1[ix_val], X_train_q2[ix_val], X_train_magic[ix_val])\n",
    "    y_test_oofp[:, fold_num] = predict(model, X_test_q1, X_test_q2, X_test_magic)\n",
    "    \n",
    "    # Clear GPU memory.\n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_train_magic\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del X_fold_val_magic\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.27110014293\n"
     ]
    }
   ],
   "source": [
    "cv_score = log_loss(y_train, y_train_oofp)\n",
    "print('CV score:', cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_bradleypallen_mlp_magic',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp_mean = np.mean(y_test_oofp, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp_mean, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
