{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_lystdo_lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep\n",
    "submissions_data_folder = os.path.join(data_folder, 'submissions') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    params = {\n",
    "        'num_lstm': 361,\n",
    "        'num_dense': 115,\n",
    "        'lstm_dropout_rate': 0.32,\n",
    "        'dense_dropout_rate': 0.161,\n",
    "    }\n",
    "    \n",
    "    embedding_layer = Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    )\n",
    "    lstm_layer = LSTM(\n",
    "        params['num_lstm'],\n",
    "        dropout=params['lstm_dropout_rate'],\n",
    "        recurrent_dropout=params['lstm_dropout_rate'],\n",
    "    )\n",
    "\n",
    "    sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "    x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "    sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "    y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "    merged = concatenate([x1, y1])\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    merged = Dense(params['num_dense'], activation='relu')(merged)\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[sequence_1_input, sequence_2_input],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.6877 - acc: 0.7143Epoch 00000: val_loss improved from inf to 0.49680, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 103s - loss: 0.6876 - acc: 0.7143 - val_loss: 0.4968 - val_acc: 0.7458\n",
      "Epoch 2/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.5768 - acc: 0.7729Epoch 00001: val_loss improved from 0.49680 to 0.45456, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 104s - loss: 0.5768 - acc: 0.7729 - val_loss: 0.4546 - val_acc: 0.7757\n",
      "Epoch 3/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.7966Epoch 00002: val_loss improved from 0.45456 to 0.44289, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 103s - loss: 0.5267 - acc: 0.7966 - val_loss: 0.4429 - val_acc: 0.7844\n",
      "Epoch 4/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.8111Epoch 00003: val_loss improved from 0.44289 to 0.41278, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 103s - loss: 0.4947 - acc: 0.8111 - val_loss: 0.4128 - val_acc: 0.8033\n",
      "Epoch 5/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.4681 - acc: 0.8227Epoch 00004: val_loss improved from 0.41278 to 0.40597, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 103s - loss: 0.4681 - acc: 0.8227 - val_loss: 0.4060 - val_acc: 0.8049\n",
      "Epoch 6/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8319Epoch 00005: val_loss improved from 0.40597 to 0.40482, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 103s - loss: 0.4471 - acc: 0.8319 - val_loss: 0.4048 - val_acc: 0.8087\n",
      "Epoch 7/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.8391Epoch 00006: val_loss improved from 0.40482 to 0.40099, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 104s - loss: 0.4302 - acc: 0.8392 - val_loss: 0.4010 - val_acc: 0.8113\n",
      "Epoch 8/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.4148 - acc: 0.8458Epoch 00007: val_loss improved from 0.40099 to 0.39908, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 104s - loss: 0.4148 - acc: 0.8459 - val_loss: 0.3991 - val_acc: 0.8130\n",
      "Epoch 9/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.4031 - acc: 0.8507Epoch 00008: val_loss improved from 0.39908 to 0.38345, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_lstm.h5\n",
      "646862/646862 [==============================] - 104s - loss: 0.4031 - acc: 0.8507 - val_loss: 0.3835 - val_acc: 0.8215\n",
      "Epoch 10/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3908 - acc: 0.8561Epoch 00009: val_loss did not improve\n",
      "646862/646862 [==============================] - 104s - loss: 0.3908 - acc: 0.8561 - val_loss: 0.3844 - val_acc: 0.8228\n",
      "Epoch 11/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8602Epoch 00010: val_loss did not improve\n",
      "646862/646862 [==============================] - 104s - loss: 0.3813 - acc: 0.8602 - val_loss: 0.3921 - val_acc: 0.8177\n",
      "Epoch 12/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.8634Epoch 00011: val_loss did not improve\n",
      "646862/646862 [==============================] - 104s - loss: 0.3739 - acc: 0.8634 - val_loss: 0.4033 - val_acc: 0.8179\n",
      "Epoch 13/35\n",
      "646144/646862 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8671Epoch 00012: val_loss did not improve\n",
      "646862/646862 [==============================] - 103s - loss: 0.3656 - acc: 0.8671 - val_loss: 0.3914 - val_acc: 0.8239\n",
      "Epoch 00012: early stopping\n",
      "393216/646864 [=================>............] - ETA: 36s - loss: 0.4500 - acc: 0.8303"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "        class_weight=keras_get_class_weights(y_fold_val),\n",
    "\n",
    "        batch_size=1024,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_pred_oofp = model.predict([X_train_q1[ix_val], X_train_q2[ix_val]], batch_size=2048, verbose=1).reshape(-1)\n",
    "    y_pred_oofp += model.predict([X_train_q2[ix_val], X_train_q1[ix_val]], batch_size=2048, verbose=1).reshape(-1)\n",
    "    y_pred_oofp /= 2\n",
    "       \n",
    "    # Remember them.\n",
    "    y_train_oofp[ix_val] = y_pred_oofp\n",
    "    \n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_lystdo_lstm',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_weights(model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It would be better to fit the model on the whole training set\n",
    "# but the validation set for early stopping would be an issue.\n",
    "y_test_oofp = model.predict([X_test_q1, X_test_q2], batch_size=2048, verbose=1).reshape(-1)\n",
    "y_test_oofp += model.predict([X_test_q2, X_test_q1], batch_size=2048, verbose=1).reshape(-1)\n",
    "y_test_oofp /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = y_test_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
