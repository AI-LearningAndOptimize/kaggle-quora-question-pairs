{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine, euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_tokens_train = load_json(preproc_data_folder + 'question_tokens_train.json')\n",
    "question_tokens_test = load_json(preproc_data_folder + 'question_tokens_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_questions = set(' '.join(pair['question1']) for pair in question_tokens_train) \\\n",
    "    .union(set(' '.join(pair['question2']) for pair in question_tokens_train)) \\\n",
    "    .union(set(' '.join(pair['question1']) for pair in question_tokens_test)) \\\n",
    "    .union(set(' '.join(pair['question2']) for pair in question_tokens_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = list(all_unique_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(documents, preproc_data_folder + 'unique_documents.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    encoding='utf-8',\n",
    "    analyzer='word',\n",
    "    strip_accents='unicode',\n",
    "    ngram_range=(1, 1),\n",
    "    lowercase=True,\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(vectorizer, preproc_data_folder + 'unique_questions_all_tfidf_vectorizer.pickle'.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Train and Test Sets, Compute Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pairs_train = len(question_tokens_train)\n",
    "num_pairs_test = len(question_tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((num_pairs_train, 2), dtype=float)\n",
    "X_test = np.zeros((num_pairs_test, 2), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (404290, 2)\n",
      "X test:  (2345796, 2)\n"
     ]
    }
   ],
   "source": [
    "print('X train:', X_train.shape)\n",
    "print('X test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3aff162d8a544c8a168884fdee2d08e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "for index, pair in progressbar(enumerate(question_tokens_train), size=num_pairs_train):\n",
    "    pair_documents = [' '.join(pair['question1']), ' '.join(pair['question2'])]\n",
    "    pair_dtm = vectorizer.transform(pair_documents)\n",
    "    q1_doc_vec = pair_dtm[0, :].toarray()\n",
    "    q2_doc_vec = pair_dtm[1, :].toarray()\n",
    "    \n",
    "    X_train[index, 0] = cosine(q1_doc_vec, q2_doc_vec)\n",
    "    X_train[index, 1] = euclidean(q1_doc_vec, q2_doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(X_train, features_data_folder + 'X_train_tfidf_distances.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74656a474fad414bb485de1936361dd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "for index, pair in progressbar(enumerate(question_tokens_test), size=num_pairs_test):\n",
    "    pair_documents = [' '.join(pair['question1']), ' '.join(pair['question2'])]\n",
    "    pair_dtm = vectorizer.transform(pair_documents)\n",
    "    q1_doc_vec = pair_dtm[0, :].toarray()\n",
    "    q2_doc_vec = pair_dtm[1, :].toarray()\n",
    "    \n",
    "    X_test[index, 0] = cosine(q1_doc_vec, q2_doc_vec)\n",
    "    X_test[index, 1] = euclidean(q1_doc_vec, q2_doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(X_test, features_data_folder + 'X_test_tfidf_distances.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
