{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep\n",
    "submissions_data_folder = os.path.join(data_folder, 'submissions') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename):\n",
    "    X = pd.read_csv(filename)\n",
    "    columns_to_remove = ['id', 'is_duplicate']\n",
    "    columns_to_remove = [\n",
    "        column\n",
    "        for column in columns_to_remove\n",
    "        if column in X.columns\n",
    "    ]\n",
    "    X.drop(columns_to_remove, axis=1, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = read_dataset(features_data_folder + 'X_train_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shorter_char_len_log              float64\n",
       "longer_char_len_log               float64\n",
       "shorter_token_len_log             float64\n",
       "longer_token_len_log              float64\n",
       "char_len_diff_log                 float64\n",
       "token_len_diff_log                float64\n",
       "char_len_ratio                    float64\n",
       "token_len_ratio                   float64\n",
       "word_diff_ratio                   float64\n",
       "jaccard_ix_2gram                  float64\n",
       "jaccard_ix_norm_q1_2gram          float64\n",
       "jaccard_ix_norm_q2_2gram          float64\n",
       "jaccard_ix_3gram                  float64\n",
       "jaccard_ix_norm_q1_3gram          float64\n",
       "jaccard_ix_norm_q2_3gram          float64\n",
       "jaccard_ix_4gram                  float64\n",
       "jaccard_ix_norm_q1_4gram          float64\n",
       "jaccard_ix_norm_q2_4gram          float64\n",
       "jaccard_ix_5gram                  float64\n",
       "jaccard_ix_norm_q1_5gram          float64\n",
       "jaccard_ix_norm_q2_5gram          float64\n",
       "fuzzy_ratio                       float64\n",
       "fuzzy_partial_ratio               float64\n",
       "fuzzy_token_sort_ratio            float64\n",
       "fuzzy_token_set_ratio             float64\n",
       "fuzzy_partial_token_sort_ratio    float64\n",
       "tfidf_cosine                      float64\n",
       "tfidf_euclidean                   float64\n",
       "emb_mean_cosine                   float64\n",
       "emb_mean_cityblock_log            float64\n",
       "                                   ...   \n",
       "das_avg_word_len1                 float64\n",
       "das_avg_word_len2                 float64\n",
       "das_diff_avg_word                 float64\n",
       "das_q1_how                        float64\n",
       "das_q2_how                        float64\n",
       "das_how_both                      float64\n",
       "das_q1_what                       float64\n",
       "das_q2_what                       float64\n",
       "das_what_both                     float64\n",
       "das_q1_which                      float64\n",
       "das_q2_which                      float64\n",
       "das_which_both                    float64\n",
       "das_q1_who                        float64\n",
       "das_q2_who                        float64\n",
       "das_who_both                      float64\n",
       "das_q1_where                      float64\n",
       "das_q2_where                      float64\n",
       "das_where_both                    float64\n",
       "das_q1_when                       float64\n",
       "das_q2_when                       float64\n",
       "das_when_both                     float64\n",
       "das_q1_why                        float64\n",
       "das_q2_why                        float64\n",
       "das_why_both                      float64\n",
       "magic_jt_q1_freq                  float64\n",
       "magic_jt_q2_freq                  float64\n",
       "magic_jt_freq_ratio               float64\n",
       "oofp_nn_concat_dense_1            float64\n",
       "oofp_currie32_cnn                 float64\n",
       "oofp_lystdo_lstm                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'gbdt',\n",
    "    'device': 'cpu',\n",
    "#     'bagging_fraction': 0.5,\n",
    "#     'bagging_freq': 20,\n",
    "#     'feature_fraction': 0.8,\n",
    "    'num_leaves': 64,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_boost_round': 1000,\n",
    "    'early_stopping_rounds': 5,\n",
    "    'verbose': 1,\n",
    "    'bagging_fraction_seed': RANDOM_SEED,\n",
    "    'feature_fraction_seed': RANDOM_SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_dataset = lgb.Dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 10min 56s, sys: 30.8 s, total: 1h 11min 27s\n",
      "Wall time: 12min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params,\n",
    "    lgb_dataset,\n",
    "    num_boost_round=lgb_params['num_boost_round'],\n",
    "    early_stopping_rounds=lgb_params['early_stopping_rounds'],\n",
    "    nfold=5,\n",
    "    stratified=True,\n",
    "    shuffle=True,\n",
    "    metrics=['binary_logloss'],\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_logloss-mean</th>\n",
       "      <th>binary_logloss-stdv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.673801</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.655603</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.638409</td>\n",
       "      <td>0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622174</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.606794</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.592253</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.578436</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.565316</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.552829</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.540950</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.529650</td>\n",
       "      <td>0.000766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.518863</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.508608</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.498788</td>\n",
       "      <td>0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.489417</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.480472</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.471908</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.455846</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.448315</td>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.441098</td>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.434164</td>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.427505</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.421146</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.415044</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.409203</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.403588</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.398178</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.392970</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.387963</td>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.231837</td>\n",
       "      <td>0.002931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.231835</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.231831</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.231832</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.231831</td>\n",
       "      <td>0.002931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.231832</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.231827</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.002935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.231822</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.231816</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.231814</td>\n",
       "      <td>0.002934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.231809</td>\n",
       "      <td>0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.231811</td>\n",
       "      <td>0.002937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.231811</td>\n",
       "      <td>0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.231808</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.231803</td>\n",
       "      <td>0.002938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.231803</td>\n",
       "      <td>0.002937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.002934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.231799</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.231795</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.231795</td>\n",
       "      <td>0.002935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.231795</td>\n",
       "      <td>0.002937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.231793</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.231788</td>\n",
       "      <td>0.002940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.231791</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.231785</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.231783</td>\n",
       "      <td>0.002941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.231781</td>\n",
       "      <td>0.002943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.231782</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     binary_logloss-mean  binary_logloss-stdv\n",
       "0               0.673801             0.000104\n",
       "1               0.655603             0.000171\n",
       "2               0.638409             0.000261\n",
       "3               0.622174             0.000333\n",
       "4               0.606794             0.000409\n",
       "5               0.592253             0.000476\n",
       "6               0.578436             0.000544\n",
       "7               0.565316             0.000602\n",
       "8               0.552829             0.000659\n",
       "9               0.540950             0.000714\n",
       "10              0.529650             0.000766\n",
       "11              0.518863             0.000815\n",
       "12              0.508608             0.000862\n",
       "13              0.498788             0.000903\n",
       "14              0.489417             0.000976\n",
       "15              0.480472             0.000998\n",
       "16              0.471908             0.001061\n",
       "17              0.463693             0.001119\n",
       "18              0.455846             0.001169\n",
       "19              0.448315             0.001204\n",
       "20              0.441098             0.001221\n",
       "21              0.434164             0.001257\n",
       "22              0.427505             0.001275\n",
       "23              0.421146             0.001334\n",
       "24              0.415044             0.001379\n",
       "25              0.409203             0.001420\n",
       "26              0.403588             0.001463\n",
       "27              0.398178             0.001478\n",
       "28              0.392970             0.001499\n",
       "29              0.387963             0.001520\n",
       "..                   ...                  ...\n",
       "970             0.231837             0.002931\n",
       "971             0.231835             0.002930\n",
       "972             0.231831             0.002933\n",
       "973             0.231832             0.002932\n",
       "974             0.231831             0.002931\n",
       "975             0.231832             0.002932\n",
       "976             0.231827             0.002933\n",
       "977             0.231824             0.002935\n",
       "978             0.231822             0.002933\n",
       "979             0.231816             0.002932\n",
       "980             0.231814             0.002934\n",
       "981             0.231809             0.002938\n",
       "982             0.231811             0.002937\n",
       "983             0.231811             0.002938\n",
       "984             0.231808             0.002939\n",
       "985             0.231803             0.002938\n",
       "986             0.231803             0.002937\n",
       "987             0.231800             0.002934\n",
       "988             0.231800             0.002932\n",
       "989             0.231799             0.002932\n",
       "990             0.231795             0.002933\n",
       "991             0.231795             0.002935\n",
       "992             0.231795             0.002937\n",
       "993             0.231793             0.002939\n",
       "994             0.231788             0.002940\n",
       "995             0.231791             0.002945\n",
       "996             0.231785             0.002944\n",
       "997             0.231783             0.002941\n",
       "998             0.231781             0.002943\n",
       "999             0.231782             0.002944\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check (Train/Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_data_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_data_val = lgb.Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.673733\n",
      "Train until valid scores didn't improve in 5 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.655409\n",
      "[3]\tvalid_0's binary_logloss: 0.638133\n",
      "[4]\tvalid_0's binary_logloss: 0.621756\n",
      "[5]\tvalid_0's binary_logloss: 0.606271\n",
      "[6]\tvalid_0's binary_logloss: 0.59158\n",
      "[7]\tvalid_0's binary_logloss: 0.57769\n",
      "[8]\tvalid_0's binary_logloss: 0.564452\n",
      "[9]\tvalid_0's binary_logloss: 0.551889\n",
      "[10]\tvalid_0's binary_logloss: 0.539935\n",
      "[11]\tvalid_0's binary_logloss: 0.528516\n",
      "[12]\tvalid_0's binary_logloss: 0.517684\n",
      "[13]\tvalid_0's binary_logloss: 0.507316\n",
      "[14]\tvalid_0's binary_logloss: 0.497446\n",
      "[15]\tvalid_0's binary_logloss: 0.488074\n",
      "[16]\tvalid_0's binary_logloss: 0.479035\n",
      "[17]\tvalid_0's binary_logloss: 0.470434\n",
      "[18]\tvalid_0's binary_logloss: 0.462169\n",
      "[19]\tvalid_0's binary_logloss: 0.454278\n",
      "[20]\tvalid_0's binary_logloss: 0.446703\n",
      "[21]\tvalid_0's binary_logloss: 0.439454\n",
      "[22]\tvalid_0's binary_logloss: 0.432512\n",
      "[23]\tvalid_0's binary_logloss: 0.425813\n",
      "[24]\tvalid_0's binary_logloss: 0.419438\n",
      "[25]\tvalid_0's binary_logloss: 0.413265\n",
      "[26]\tvalid_0's binary_logloss: 0.407361\n",
      "[27]\tvalid_0's binary_logloss: 0.401722\n",
      "[28]\tvalid_0's binary_logloss: 0.396257\n",
      "[29]\tvalid_0's binary_logloss: 0.391087\n",
      "[30]\tvalid_0's binary_logloss: 0.386108\n",
      "[31]\tvalid_0's binary_logloss: 0.381269\n",
      "[32]\tvalid_0's binary_logloss: 0.376629\n",
      "[33]\tvalid_0's binary_logloss: 0.372175\n",
      "[34]\tvalid_0's binary_logloss: 0.367842\n",
      "[35]\tvalid_0's binary_logloss: 0.36367\n",
      "[36]\tvalid_0's binary_logloss: 0.359659\n",
      "[37]\tvalid_0's binary_logloss: 0.355801\n",
      "[38]\tvalid_0's binary_logloss: 0.352056\n",
      "[39]\tvalid_0's binary_logloss: 0.348431\n",
      "[40]\tvalid_0's binary_logloss: 0.344915\n",
      "[41]\tvalid_0's binary_logloss: 0.341549\n",
      "[42]\tvalid_0's binary_logloss: 0.338332\n",
      "[43]\tvalid_0's binary_logloss: 0.335211\n",
      "[44]\tvalid_0's binary_logloss: 0.332212\n",
      "[45]\tvalid_0's binary_logloss: 0.329304\n",
      "[46]\tvalid_0's binary_logloss: 0.326516\n",
      "[47]\tvalid_0's binary_logloss: 0.323846\n",
      "[48]\tvalid_0's binary_logloss: 0.321269\n",
      "[49]\tvalid_0's binary_logloss: 0.318784\n",
      "[50]\tvalid_0's binary_logloss: 0.31636\n",
      "[51]\tvalid_0's binary_logloss: 0.314018\n",
      "[52]\tvalid_0's binary_logloss: 0.311724\n",
      "[53]\tvalid_0's binary_logloss: 0.309496\n",
      "[54]\tvalid_0's binary_logloss: 0.307378\n",
      "[55]\tvalid_0's binary_logloss: 0.305319\n",
      "[56]\tvalid_0's binary_logloss: 0.303338\n",
      "[57]\tvalid_0's binary_logloss: 0.301428\n",
      "[58]\tvalid_0's binary_logloss: 0.299577\n",
      "[59]\tvalid_0's binary_logloss: 0.297747\n",
      "[60]\tvalid_0's binary_logloss: 0.295995\n",
      "[61]\tvalid_0's binary_logloss: 0.294312\n",
      "[62]\tvalid_0's binary_logloss: 0.292671\n",
      "[63]\tvalid_0's binary_logloss: 0.291104\n",
      "[64]\tvalid_0's binary_logloss: 0.289568\n",
      "[65]\tvalid_0's binary_logloss: 0.288087\n",
      "[66]\tvalid_0's binary_logloss: 0.286642\n",
      "[67]\tvalid_0's binary_logloss: 0.285268\n",
      "[68]\tvalid_0's binary_logloss: 0.283902\n",
      "[69]\tvalid_0's binary_logloss: 0.282576\n",
      "[70]\tvalid_0's binary_logloss: 0.281312\n",
      "[71]\tvalid_0's binary_logloss: 0.280116\n",
      "[72]\tvalid_0's binary_logloss: 0.27895\n",
      "[73]\tvalid_0's binary_logloss: 0.277801\n",
      "[74]\tvalid_0's binary_logloss: 0.276653\n",
      "[75]\tvalid_0's binary_logloss: 0.275574\n",
      "[76]\tvalid_0's binary_logloss: 0.274491\n",
      "[77]\tvalid_0's binary_logloss: 0.273454\n",
      "[78]\tvalid_0's binary_logloss: 0.272468\n",
      "[79]\tvalid_0's binary_logloss: 0.271519\n",
      "[80]\tvalid_0's binary_logloss: 0.270577\n",
      "[81]\tvalid_0's binary_logloss: 0.269664\n",
      "[82]\tvalid_0's binary_logloss: 0.268788\n",
      "[83]\tvalid_0's binary_logloss: 0.267918\n",
      "[84]\tvalid_0's binary_logloss: 0.267078\n",
      "[85]\tvalid_0's binary_logloss: 0.266289\n",
      "[86]\tvalid_0's binary_logloss: 0.265507\n",
      "[87]\tvalid_0's binary_logloss: 0.264746\n",
      "[88]\tvalid_0's binary_logloss: 0.263988\n",
      "[89]\tvalid_0's binary_logloss: 0.263263\n",
      "[90]\tvalid_0's binary_logloss: 0.262548\n",
      "[91]\tvalid_0's binary_logloss: 0.26186\n",
      "[92]\tvalid_0's binary_logloss: 0.261177\n",
      "[93]\tvalid_0's binary_logloss: 0.260534\n",
      "[94]\tvalid_0's binary_logloss: 0.259906\n",
      "[95]\tvalid_0's binary_logloss: 0.259268\n",
      "[96]\tvalid_0's binary_logloss: 0.258689\n",
      "[97]\tvalid_0's binary_logloss: 0.258102\n",
      "[98]\tvalid_0's binary_logloss: 0.257544\n",
      "[99]\tvalid_0's binary_logloss: 0.257008\n",
      "[100]\tvalid_0's binary_logloss: 0.256471\n",
      "[101]\tvalid_0's binary_logloss: 0.255961\n",
      "[102]\tvalid_0's binary_logloss: 0.255447\n",
      "[103]\tvalid_0's binary_logloss: 0.254968\n",
      "[104]\tvalid_0's binary_logloss: 0.254494\n",
      "[105]\tvalid_0's binary_logloss: 0.254016\n",
      "[106]\tvalid_0's binary_logloss: 0.253575\n",
      "[107]\tvalid_0's binary_logloss: 0.253136\n",
      "[108]\tvalid_0's binary_logloss: 0.252699\n",
      "[109]\tvalid_0's binary_logloss: 0.252267\n",
      "[110]\tvalid_0's binary_logloss: 0.251845\n",
      "[111]\tvalid_0's binary_logloss: 0.251446\n",
      "[112]\tvalid_0's binary_logloss: 0.251034\n",
      "[113]\tvalid_0's binary_logloss: 0.250645\n",
      "[114]\tvalid_0's binary_logloss: 0.250291\n",
      "[115]\tvalid_0's binary_logloss: 0.24987\n",
      "[116]\tvalid_0's binary_logloss: 0.249501\n",
      "[117]\tvalid_0's binary_logloss: 0.249169\n",
      "[118]\tvalid_0's binary_logloss: 0.248823\n",
      "[119]\tvalid_0's binary_logloss: 0.248478\n",
      "[120]\tvalid_0's binary_logloss: 0.248161\n",
      "[121]\tvalid_0's binary_logloss: 0.247854\n",
      "[122]\tvalid_0's binary_logloss: 0.247559\n",
      "[123]\tvalid_0's binary_logloss: 0.24726\n",
      "[124]\tvalid_0's binary_logloss: 0.246978\n",
      "[125]\tvalid_0's binary_logloss: 0.246693\n",
      "[126]\tvalid_0's binary_logloss: 0.246419\n",
      "[127]\tvalid_0's binary_logloss: 0.246161\n",
      "[128]\tvalid_0's binary_logloss: 0.245894\n",
      "[129]\tvalid_0's binary_logloss: 0.245627\n",
      "[130]\tvalid_0's binary_logloss: 0.245375\n",
      "[131]\tvalid_0's binary_logloss: 0.245131\n",
      "[132]\tvalid_0's binary_logloss: 0.244892\n",
      "[133]\tvalid_0's binary_logloss: 0.244666\n",
      "[134]\tvalid_0's binary_logloss: 0.244407\n",
      "[135]\tvalid_0's binary_logloss: 0.244174\n",
      "[136]\tvalid_0's binary_logloss: 0.243931\n",
      "[137]\tvalid_0's binary_logloss: 0.243715\n",
      "[138]\tvalid_0's binary_logloss: 0.243514\n",
      "[139]\tvalid_0's binary_logloss: 0.243302\n",
      "[140]\tvalid_0's binary_logloss: 0.243091\n",
      "[141]\tvalid_0's binary_logloss: 0.242905\n",
      "[142]\tvalid_0's binary_logloss: 0.242718\n",
      "[143]\tvalid_0's binary_logloss: 0.242538\n",
      "[144]\tvalid_0's binary_logloss: 0.242323\n",
      "[145]\tvalid_0's binary_logloss: 0.242111\n",
      "[146]\tvalid_0's binary_logloss: 0.241943\n",
      "[147]\tvalid_0's binary_logloss: 0.241772\n",
      "[148]\tvalid_0's binary_logloss: 0.241575\n",
      "[149]\tvalid_0's binary_logloss: 0.241389\n",
      "[150]\tvalid_0's binary_logloss: 0.241245\n",
      "[151]\tvalid_0's binary_logloss: 0.241073\n",
      "[152]\tvalid_0's binary_logloss: 0.240923\n",
      "[153]\tvalid_0's binary_logloss: 0.24078\n",
      "[154]\tvalid_0's binary_logloss: 0.240626\n",
      "[155]\tvalid_0's binary_logloss: 0.240468\n",
      "[156]\tvalid_0's binary_logloss: 0.240311\n",
      "[157]\tvalid_0's binary_logloss: 0.240175\n",
      "[158]\tvalid_0's binary_logloss: 0.240016\n",
      "[159]\tvalid_0's binary_logloss: 0.239891\n",
      "[160]\tvalid_0's binary_logloss: 0.239756\n",
      "[161]\tvalid_0's binary_logloss: 0.239636\n",
      "[162]\tvalid_0's binary_logloss: 0.239511\n",
      "[163]\tvalid_0's binary_logloss: 0.239386\n",
      "[164]\tvalid_0's binary_logloss: 0.239275\n",
      "[165]\tvalid_0's binary_logloss: 0.239139\n",
      "[166]\tvalid_0's binary_logloss: 0.239003\n",
      "[167]\tvalid_0's binary_logloss: 0.23886\n",
      "[168]\tvalid_0's binary_logloss: 0.238737\n",
      "[169]\tvalid_0's binary_logloss: 0.238636\n",
      "[170]\tvalid_0's binary_logloss: 0.238523\n",
      "[171]\tvalid_0's binary_logloss: 0.238416\n",
      "[172]\tvalid_0's binary_logloss: 0.238273\n",
      "[173]\tvalid_0's binary_logloss: 0.238154\n",
      "[174]\tvalid_0's binary_logloss: 0.238034\n",
      "[175]\tvalid_0's binary_logloss: 0.237902\n",
      "[176]\tvalid_0's binary_logloss: 0.2378\n",
      "[177]\tvalid_0's binary_logloss: 0.237709\n",
      "[178]\tvalid_0's binary_logloss: 0.23761\n",
      "[179]\tvalid_0's binary_logloss: 0.237493\n",
      "[180]\tvalid_0's binary_logloss: 0.237378\n",
      "[181]\tvalid_0's binary_logloss: 0.237283\n",
      "[182]\tvalid_0's binary_logloss: 0.23721\n",
      "[183]\tvalid_0's binary_logloss: 0.237141\n",
      "[184]\tvalid_0's binary_logloss: 0.237077\n",
      "[185]\tvalid_0's binary_logloss: 0.236988\n",
      "[186]\tvalid_0's binary_logloss: 0.236893\n",
      "[187]\tvalid_0's binary_logloss: 0.236821\n",
      "[188]\tvalid_0's binary_logloss: 0.236721\n",
      "[189]\tvalid_0's binary_logloss: 0.23665\n",
      "[190]\tvalid_0's binary_logloss: 0.236558\n",
      "[191]\tvalid_0's binary_logloss: 0.236484\n",
      "[192]\tvalid_0's binary_logloss: 0.236424\n",
      "[193]\tvalid_0's binary_logloss: 0.236359\n",
      "[194]\tvalid_0's binary_logloss: 0.236281\n",
      "[195]\tvalid_0's binary_logloss: 0.236208\n",
      "[196]\tvalid_0's binary_logloss: 0.236121\n",
      "[197]\tvalid_0's binary_logloss: 0.236051\n",
      "[198]\tvalid_0's binary_logloss: 0.235989\n",
      "[199]\tvalid_0's binary_logloss: 0.235917\n",
      "[200]\tvalid_0's binary_logloss: 0.235844\n",
      "[201]\tvalid_0's binary_logloss: 0.235764\n",
      "[202]\tvalid_0's binary_logloss: 0.235691\n",
      "[203]\tvalid_0's binary_logloss: 0.23563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\tvalid_0's binary_logloss: 0.235593\n",
      "[205]\tvalid_0's binary_logloss: 0.235519\n",
      "[206]\tvalid_0's binary_logloss: 0.235463\n",
      "[207]\tvalid_0's binary_logloss: 0.235411\n",
      "[208]\tvalid_0's binary_logloss: 0.235353\n",
      "[209]\tvalid_0's binary_logloss: 0.23531\n",
      "[210]\tvalid_0's binary_logloss: 0.235265\n",
      "[211]\tvalid_0's binary_logloss: 0.235227\n",
      "[212]\tvalid_0's binary_logloss: 0.23517\n",
      "[213]\tvalid_0's binary_logloss: 0.235122\n",
      "[214]\tvalid_0's binary_logloss: 0.235073\n",
      "[215]\tvalid_0's binary_logloss: 0.23502\n",
      "[216]\tvalid_0's binary_logloss: 0.234962\n",
      "[217]\tvalid_0's binary_logloss: 0.23493\n",
      "[218]\tvalid_0's binary_logloss: 0.23486\n",
      "[219]\tvalid_0's binary_logloss: 0.234823\n",
      "[220]\tvalid_0's binary_logloss: 0.234788\n",
      "[221]\tvalid_0's binary_logloss: 0.234734\n",
      "[222]\tvalid_0's binary_logloss: 0.234695\n",
      "[223]\tvalid_0's binary_logloss: 0.234646\n",
      "[224]\tvalid_0's binary_logloss: 0.234607\n",
      "[225]\tvalid_0's binary_logloss: 0.234551\n",
      "[226]\tvalid_0's binary_logloss: 0.234504\n",
      "[227]\tvalid_0's binary_logloss: 0.234468\n",
      "[228]\tvalid_0's binary_logloss: 0.234422\n",
      "[229]\tvalid_0's binary_logloss: 0.234372\n",
      "[230]\tvalid_0's binary_logloss: 0.234328\n",
      "[231]\tvalid_0's binary_logloss: 0.234301\n",
      "[232]\tvalid_0's binary_logloss: 0.234259\n",
      "[233]\tvalid_0's binary_logloss: 0.234213\n",
      "[234]\tvalid_0's binary_logloss: 0.234178\n",
      "[235]\tvalid_0's binary_logloss: 0.234147\n",
      "[236]\tvalid_0's binary_logloss: 0.234111\n",
      "[237]\tvalid_0's binary_logloss: 0.234059\n",
      "[238]\tvalid_0's binary_logloss: 0.234034\n",
      "[239]\tvalid_0's binary_logloss: 0.233987\n",
      "[240]\tvalid_0's binary_logloss: 0.23395\n",
      "[241]\tvalid_0's binary_logloss: 0.233925\n",
      "[242]\tvalid_0's binary_logloss: 0.233895\n",
      "[243]\tvalid_0's binary_logloss: 0.233856\n",
      "[244]\tvalid_0's binary_logloss: 0.233816\n",
      "[245]\tvalid_0's binary_logloss: 0.233797\n",
      "[246]\tvalid_0's binary_logloss: 0.233755\n",
      "[247]\tvalid_0's binary_logloss: 0.233724\n",
      "[248]\tvalid_0's binary_logloss: 0.233691\n",
      "[249]\tvalid_0's binary_logloss: 0.233663\n",
      "[250]\tvalid_0's binary_logloss: 0.233633\n",
      "[251]\tvalid_0's binary_logloss: 0.233618\n",
      "[252]\tvalid_0's binary_logloss: 0.23358\n",
      "[253]\tvalid_0's binary_logloss: 0.23354\n",
      "[254]\tvalid_0's binary_logloss: 0.233503\n",
      "[255]\tvalid_0's binary_logloss: 0.233472\n",
      "[256]\tvalid_0's binary_logloss: 0.233462\n",
      "[257]\tvalid_0's binary_logloss: 0.233429\n",
      "[258]\tvalid_0's binary_logloss: 0.233407\n",
      "[259]\tvalid_0's binary_logloss: 0.233373\n",
      "[260]\tvalid_0's binary_logloss: 0.233333\n",
      "[261]\tvalid_0's binary_logloss: 0.233304\n",
      "[262]\tvalid_0's binary_logloss: 0.233272\n",
      "[263]\tvalid_0's binary_logloss: 0.233248\n",
      "[264]\tvalid_0's binary_logloss: 0.233202\n",
      "[265]\tvalid_0's binary_logloss: 0.233183\n",
      "[266]\tvalid_0's binary_logloss: 0.233174\n",
      "[267]\tvalid_0's binary_logloss: 0.233164\n",
      "[268]\tvalid_0's binary_logloss: 0.233143\n",
      "[269]\tvalid_0's binary_logloss: 0.233127\n",
      "[270]\tvalid_0's binary_logloss: 0.233113\n",
      "[271]\tvalid_0's binary_logloss: 0.233065\n",
      "[272]\tvalid_0's binary_logloss: 0.233045\n",
      "[273]\tvalid_0's binary_logloss: 0.233031\n",
      "[274]\tvalid_0's binary_logloss: 0.233007\n",
      "[275]\tvalid_0's binary_logloss: 0.232981\n",
      "[276]\tvalid_0's binary_logloss: 0.232955\n",
      "[277]\tvalid_0's binary_logloss: 0.232926\n",
      "[278]\tvalid_0's binary_logloss: 0.232906\n",
      "[279]\tvalid_0's binary_logloss: 0.2329\n",
      "[280]\tvalid_0's binary_logloss: 0.232893\n",
      "[281]\tvalid_0's binary_logloss: 0.232881\n",
      "[282]\tvalid_0's binary_logloss: 0.232857\n",
      "[283]\tvalid_0's binary_logloss: 0.232843\n",
      "[284]\tvalid_0's binary_logloss: 0.232818\n",
      "[285]\tvalid_0's binary_logloss: 0.232788\n",
      "[286]\tvalid_0's binary_logloss: 0.232782\n",
      "[287]\tvalid_0's binary_logloss: 0.232784\n",
      "[288]\tvalid_0's binary_logloss: 0.232764\n",
      "[289]\tvalid_0's binary_logloss: 0.232725\n",
      "[290]\tvalid_0's binary_logloss: 0.232703\n",
      "[291]\tvalid_0's binary_logloss: 0.232688\n",
      "[292]\tvalid_0's binary_logloss: 0.232677\n",
      "[293]\tvalid_0's binary_logloss: 0.232641\n",
      "[294]\tvalid_0's binary_logloss: 0.232599\n",
      "[295]\tvalid_0's binary_logloss: 0.232572\n",
      "[296]\tvalid_0's binary_logloss: 0.232555\n",
      "[297]\tvalid_0's binary_logloss: 0.23255\n",
      "[298]\tvalid_0's binary_logloss: 0.232535\n",
      "[299]\tvalid_0's binary_logloss: 0.232539\n",
      "[300]\tvalid_0's binary_logloss: 0.232501\n",
      "[301]\tvalid_0's binary_logloss: 0.232492\n",
      "[302]\tvalid_0's binary_logloss: 0.23248\n",
      "[303]\tvalid_0's binary_logloss: 0.232463\n",
      "[304]\tvalid_0's binary_logloss: 0.23244\n",
      "[305]\tvalid_0's binary_logloss: 0.232437\n",
      "[306]\tvalid_0's binary_logloss: 0.232402\n",
      "[307]\tvalid_0's binary_logloss: 0.232394\n",
      "[308]\tvalid_0's binary_logloss: 0.232366\n",
      "[309]\tvalid_0's binary_logloss: 0.23235\n",
      "[310]\tvalid_0's binary_logloss: 0.23234\n",
      "[311]\tvalid_0's binary_logloss: 0.232312\n",
      "[312]\tvalid_0's binary_logloss: 0.232274\n",
      "[313]\tvalid_0's binary_logloss: 0.232266\n",
      "[314]\tvalid_0's binary_logloss: 0.232234\n",
      "[315]\tvalid_0's binary_logloss: 0.232225\n",
      "[316]\tvalid_0's binary_logloss: 0.232218\n",
      "[317]\tvalid_0's binary_logloss: 0.232205\n",
      "[318]\tvalid_0's binary_logloss: 0.232188\n",
      "[319]\tvalid_0's binary_logloss: 0.232166\n",
      "[320]\tvalid_0's binary_logloss: 0.23217\n",
      "[321]\tvalid_0's binary_logloss: 0.232153\n",
      "[322]\tvalid_0's binary_logloss: 0.232119\n",
      "[323]\tvalid_0's binary_logloss: 0.232112\n",
      "[324]\tvalid_0's binary_logloss: 0.23211\n",
      "[325]\tvalid_0's binary_logloss: 0.232077\n",
      "[326]\tvalid_0's binary_logloss: 0.232071\n",
      "[327]\tvalid_0's binary_logloss: 0.232076\n",
      "[328]\tvalid_0's binary_logloss: 0.232069\n",
      "[329]\tvalid_0's binary_logloss: 0.232053\n",
      "[330]\tvalid_0's binary_logloss: 0.23205\n",
      "[331]\tvalid_0's binary_logloss: 0.232026\n",
      "[332]\tvalid_0's binary_logloss: 0.231999\n",
      "[333]\tvalid_0's binary_logloss: 0.23198\n",
      "[334]\tvalid_0's binary_logloss: 0.231978\n",
      "[335]\tvalid_0's binary_logloss: 0.231955\n",
      "[336]\tvalid_0's binary_logloss: 0.231949\n",
      "[337]\tvalid_0's binary_logloss: 0.231946\n",
      "[338]\tvalid_0's binary_logloss: 0.231934\n",
      "[339]\tvalid_0's binary_logloss: 0.231933\n",
      "[340]\tvalid_0's binary_logloss: 0.231927\n",
      "[341]\tvalid_0's binary_logloss: 0.231917\n",
      "[342]\tvalid_0's binary_logloss: 0.231908\n",
      "[343]\tvalid_0's binary_logloss: 0.23191\n",
      "[344]\tvalid_0's binary_logloss: 0.231907\n",
      "[345]\tvalid_0's binary_logloss: 0.231895\n",
      "[346]\tvalid_0's binary_logloss: 0.231872\n",
      "[347]\tvalid_0's binary_logloss: 0.231865\n",
      "[348]\tvalid_0's binary_logloss: 0.231857\n",
      "[349]\tvalid_0's binary_logloss: 0.231848\n",
      "[350]\tvalid_0's binary_logloss: 0.231842\n",
      "[351]\tvalid_0's binary_logloss: 0.231841\n",
      "[352]\tvalid_0's binary_logloss: 0.231844\n",
      "[353]\tvalid_0's binary_logloss: 0.231823\n",
      "[354]\tvalid_0's binary_logloss: 0.231805\n",
      "[355]\tvalid_0's binary_logloss: 0.231803\n",
      "[356]\tvalid_0's binary_logloss: 0.231798\n",
      "[357]\tvalid_0's binary_logloss: 0.231795\n",
      "[358]\tvalid_0's binary_logloss: 0.231769\n",
      "[359]\tvalid_0's binary_logloss: 0.231767\n",
      "[360]\tvalid_0's binary_logloss: 0.23174\n",
      "[361]\tvalid_0's binary_logloss: 0.231732\n",
      "[362]\tvalid_0's binary_logloss: 0.231737\n",
      "[363]\tvalid_0's binary_logloss: 0.23174\n",
      "[364]\tvalid_0's binary_logloss: 0.231736\n",
      "[365]\tvalid_0's binary_logloss: 0.231736\n",
      "[366]\tvalid_0's binary_logloss: 0.231732\n",
      "[367]\tvalid_0's binary_logloss: 0.231724\n",
      "[368]\tvalid_0's binary_logloss: 0.231697\n",
      "[369]\tvalid_0's binary_logloss: 0.231689\n",
      "[370]\tvalid_0's binary_logloss: 0.231673\n",
      "[371]\tvalid_0's binary_logloss: 0.231649\n",
      "[372]\tvalid_0's binary_logloss: 0.231633\n",
      "[373]\tvalid_0's binary_logloss: 0.23163\n",
      "[374]\tvalid_0's binary_logloss: 0.231627\n",
      "[375]\tvalid_0's binary_logloss: 0.231619\n",
      "[376]\tvalid_0's binary_logloss: 0.231619\n",
      "[377]\tvalid_0's binary_logloss: 0.231602\n",
      "[378]\tvalid_0's binary_logloss: 0.2316\n",
      "[379]\tvalid_0's binary_logloss: 0.23157\n",
      "[380]\tvalid_0's binary_logloss: 0.231562\n",
      "[381]\tvalid_0's binary_logloss: 0.231562\n",
      "[382]\tvalid_0's binary_logloss: 0.23156\n",
      "[383]\tvalid_0's binary_logloss: 0.231539\n",
      "[384]\tvalid_0's binary_logloss: 0.231538\n",
      "[385]\tvalid_0's binary_logloss: 0.23154\n",
      "[386]\tvalid_0's binary_logloss: 0.231533\n",
      "[387]\tvalid_0's binary_logloss: 0.231505\n",
      "[388]\tvalid_0's binary_logloss: 0.23149\n",
      "[389]\tvalid_0's binary_logloss: 0.23147\n",
      "[390]\tvalid_0's binary_logloss: 0.231463\n",
      "[391]\tvalid_0's binary_logloss: 0.231453\n",
      "[392]\tvalid_0's binary_logloss: 0.231449\n",
      "[393]\tvalid_0's binary_logloss: 0.231456\n",
      "[394]\tvalid_0's binary_logloss: 0.231439\n",
      "[395]\tvalid_0's binary_logloss: 0.231428\n",
      "[396]\tvalid_0's binary_logloss: 0.231427\n",
      "[397]\tvalid_0's binary_logloss: 0.231433\n",
      "[398]\tvalid_0's binary_logloss: 0.23143\n",
      "[399]\tvalid_0's binary_logloss: 0.231423\n",
      "[400]\tvalid_0's binary_logloss: 0.231404\n",
      "[401]\tvalid_0's binary_logloss: 0.231377\n",
      "[402]\tvalid_0's binary_logloss: 0.231376\n",
      "[403]\tvalid_0's binary_logloss: 0.231369\n",
      "[404]\tvalid_0's binary_logloss: 0.231365\n",
      "[405]\tvalid_0's binary_logloss: 0.231346\n",
      "[406]\tvalid_0's binary_logloss: 0.231343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[407]\tvalid_0's binary_logloss: 0.23133\n",
      "[408]\tvalid_0's binary_logloss: 0.231301\n",
      "[409]\tvalid_0's binary_logloss: 0.231297\n",
      "[410]\tvalid_0's binary_logloss: 0.231296\n",
      "[411]\tvalid_0's binary_logloss: 0.231288\n",
      "[412]\tvalid_0's binary_logloss: 0.231277\n",
      "[413]\tvalid_0's binary_logloss: 0.231277\n",
      "[414]\tvalid_0's binary_logloss: 0.23128\n",
      "[415]\tvalid_0's binary_logloss: 0.231276\n",
      "[416]\tvalid_0's binary_logloss: 0.231273\n",
      "[417]\tvalid_0's binary_logloss: 0.231257\n",
      "[418]\tvalid_0's binary_logloss: 0.231243\n",
      "[419]\tvalid_0's binary_logloss: 0.231227\n",
      "[420]\tvalid_0's binary_logloss: 0.231221\n",
      "[421]\tvalid_0's binary_logloss: 0.231206\n",
      "[422]\tvalid_0's binary_logloss: 0.231192\n",
      "[423]\tvalid_0's binary_logloss: 0.231191\n",
      "[424]\tvalid_0's binary_logloss: 0.231172\n",
      "[425]\tvalid_0's binary_logloss: 0.231171\n",
      "[426]\tvalid_0's binary_logloss: 0.231169\n",
      "[427]\tvalid_0's binary_logloss: 0.231166\n",
      "[428]\tvalid_0's binary_logloss: 0.231167\n",
      "[429]\tvalid_0's binary_logloss: 0.231157\n",
      "[430]\tvalid_0's binary_logloss: 0.231154\n",
      "[431]\tvalid_0's binary_logloss: 0.231146\n",
      "[432]\tvalid_0's binary_logloss: 0.231143\n",
      "[433]\tvalid_0's binary_logloss: 0.231126\n",
      "[434]\tvalid_0's binary_logloss: 0.231124\n",
      "[435]\tvalid_0's binary_logloss: 0.231123\n",
      "[436]\tvalid_0's binary_logloss: 0.231113\n",
      "[437]\tvalid_0's binary_logloss: 0.231113\n",
      "[438]\tvalid_0's binary_logloss: 0.231088\n",
      "[439]\tvalid_0's binary_logloss: 0.231077\n",
      "[440]\tvalid_0's binary_logloss: 0.231076\n",
      "[441]\tvalid_0's binary_logloss: 0.231066\n",
      "[442]\tvalid_0's binary_logloss: 0.231072\n",
      "[443]\tvalid_0's binary_logloss: 0.231067\n",
      "[444]\tvalid_0's binary_logloss: 0.231066\n",
      "[445]\tvalid_0's binary_logloss: 0.231054\n",
      "[446]\tvalid_0's binary_logloss: 0.23105\n",
      "[447]\tvalid_0's binary_logloss: 0.231047\n",
      "[448]\tvalid_0's binary_logloss: 0.231037\n",
      "[449]\tvalid_0's binary_logloss: 0.231018\n",
      "[450]\tvalid_0's binary_logloss: 0.230999\n",
      "[451]\tvalid_0's binary_logloss: 0.230983\n",
      "[452]\tvalid_0's binary_logloss: 0.230975\n",
      "[453]\tvalid_0's binary_logloss: 0.230972\n",
      "[454]\tvalid_0's binary_logloss: 0.230976\n",
      "[455]\tvalid_0's binary_logloss: 0.230966\n",
      "[456]\tvalid_0's binary_logloss: 0.230972\n",
      "[457]\tvalid_0's binary_logloss: 0.23097\n",
      "[458]\tvalid_0's binary_logloss: 0.230973\n",
      "[459]\tvalid_0's binary_logloss: 0.230979\n",
      "[460]\tvalid_0's binary_logloss: 0.230964\n",
      "[461]\tvalid_0's binary_logloss: 0.230943\n",
      "[462]\tvalid_0's binary_logloss: 0.230928\n",
      "[463]\tvalid_0's binary_logloss: 0.230919\n",
      "[464]\tvalid_0's binary_logloss: 0.230912\n",
      "[465]\tvalid_0's binary_logloss: 0.230893\n",
      "[466]\tvalid_0's binary_logloss: 0.230877\n",
      "[467]\tvalid_0's binary_logloss: 0.23088\n",
      "[468]\tvalid_0's binary_logloss: 0.230877\n",
      "[469]\tvalid_0's binary_logloss: 0.230878\n",
      "[470]\tvalid_0's binary_logloss: 0.230871\n",
      "[471]\tvalid_0's binary_logloss: 0.230868\n",
      "[472]\tvalid_0's binary_logloss: 0.230869\n",
      "[473]\tvalid_0's binary_logloss: 0.230864\n",
      "[474]\tvalid_0's binary_logloss: 0.230853\n",
      "[475]\tvalid_0's binary_logloss: 0.230853\n",
      "[476]\tvalid_0's binary_logloss: 0.230851\n",
      "[477]\tvalid_0's binary_logloss: 0.230844\n",
      "[478]\tvalid_0's binary_logloss: 0.230843\n",
      "[479]\tvalid_0's binary_logloss: 0.230847\n",
      "[480]\tvalid_0's binary_logloss: 0.230835\n",
      "[481]\tvalid_0's binary_logloss: 0.230837\n",
      "[482]\tvalid_0's binary_logloss: 0.230827\n",
      "[483]\tvalid_0's binary_logloss: 0.230815\n",
      "[484]\tvalid_0's binary_logloss: 0.230806\n",
      "[485]\tvalid_0's binary_logloss: 0.230789\n",
      "[486]\tvalid_0's binary_logloss: 0.230791\n",
      "[487]\tvalid_0's binary_logloss: 0.23079\n",
      "[488]\tvalid_0's binary_logloss: 0.230787\n",
      "[489]\tvalid_0's binary_logloss: 0.23079\n",
      "[490]\tvalid_0's binary_logloss: 0.230776\n",
      "[491]\tvalid_0's binary_logloss: 0.230768\n",
      "[492]\tvalid_0's binary_logloss: 0.230766\n",
      "[493]\tvalid_0's binary_logloss: 0.230769\n",
      "[494]\tvalid_0's binary_logloss: 0.23077\n",
      "[495]\tvalid_0's binary_logloss: 0.230766\n",
      "[496]\tvalid_0's binary_logloss: 0.230766\n",
      "[497]\tvalid_0's binary_logloss: 0.230765\n",
      "[498]\tvalid_0's binary_logloss: 0.230767\n",
      "[499]\tvalid_0's binary_logloss: 0.23077\n",
      "[500]\tvalid_0's binary_logloss: 0.23077\n",
      "[501]\tvalid_0's binary_logloss: 0.230764\n",
      "[502]\tvalid_0's binary_logloss: 0.230754\n",
      "[503]\tvalid_0's binary_logloss: 0.230743\n",
      "[504]\tvalid_0's binary_logloss: 0.230737\n",
      "[505]\tvalid_0's binary_logloss: 0.23073\n",
      "[506]\tvalid_0's binary_logloss: 0.230718\n",
      "[507]\tvalid_0's binary_logloss: 0.230721\n",
      "[508]\tvalid_0's binary_logloss: 0.230722\n",
      "[509]\tvalid_0's binary_logloss: 0.230704\n",
      "[510]\tvalid_0's binary_logloss: 0.230693\n",
      "[511]\tvalid_0's binary_logloss: 0.230688\n",
      "[512]\tvalid_0's binary_logloss: 0.230685\n",
      "[513]\tvalid_0's binary_logloss: 0.230684\n",
      "[514]\tvalid_0's binary_logloss: 0.230664\n",
      "[515]\tvalid_0's binary_logloss: 0.230656\n",
      "[516]\tvalid_0's binary_logloss: 0.230648\n",
      "[517]\tvalid_0's binary_logloss: 0.230639\n",
      "[518]\tvalid_0's binary_logloss: 0.230638\n",
      "[519]\tvalid_0's binary_logloss: 0.230632\n",
      "[520]\tvalid_0's binary_logloss: 0.230629\n",
      "[521]\tvalid_0's binary_logloss: 0.230616\n",
      "[522]\tvalid_0's binary_logloss: 0.230605\n",
      "[523]\tvalid_0's binary_logloss: 0.230601\n",
      "[524]\tvalid_0's binary_logloss: 0.230594\n",
      "[525]\tvalid_0's binary_logloss: 0.230577\n",
      "[526]\tvalid_0's binary_logloss: 0.230572\n",
      "[527]\tvalid_0's binary_logloss: 0.230563\n",
      "[528]\tvalid_0's binary_logloss: 0.230558\n",
      "[529]\tvalid_0's binary_logloss: 0.230549\n",
      "[530]\tvalid_0's binary_logloss: 0.230544\n",
      "[531]\tvalid_0's binary_logloss: 0.230528\n",
      "[532]\tvalid_0's binary_logloss: 0.230522\n",
      "[533]\tvalid_0's binary_logloss: 0.230521\n",
      "[534]\tvalid_0's binary_logloss: 0.230519\n",
      "[535]\tvalid_0's binary_logloss: 0.230515\n",
      "[536]\tvalid_0's binary_logloss: 0.230511\n",
      "[537]\tvalid_0's binary_logloss: 0.230512\n",
      "[538]\tvalid_0's binary_logloss: 0.230499\n",
      "[539]\tvalid_0's binary_logloss: 0.230499\n",
      "[540]\tvalid_0's binary_logloss: 0.230489\n",
      "[541]\tvalid_0's binary_logloss: 0.230465\n",
      "[542]\tvalid_0's binary_logloss: 0.230459\n",
      "[543]\tvalid_0's binary_logloss: 0.23046\n",
      "[544]\tvalid_0's binary_logloss: 0.230454\n",
      "[545]\tvalid_0's binary_logloss: 0.230455\n",
      "[546]\tvalid_0's binary_logloss: 0.230437\n",
      "[547]\tvalid_0's binary_logloss: 0.230428\n",
      "[548]\tvalid_0's binary_logloss: 0.230431\n",
      "[549]\tvalid_0's binary_logloss: 0.230429\n",
      "[550]\tvalid_0's binary_logloss: 0.230429\n",
      "[551]\tvalid_0's binary_logloss: 0.230421\n",
      "[552]\tvalid_0's binary_logloss: 0.230421\n",
      "[553]\tvalid_0's binary_logloss: 0.230413\n",
      "[554]\tvalid_0's binary_logloss: 0.230408\n",
      "[555]\tvalid_0's binary_logloss: 0.230406\n",
      "[556]\tvalid_0's binary_logloss: 0.230401\n",
      "[557]\tvalid_0's binary_logloss: 0.230402\n",
      "[558]\tvalid_0's binary_logloss: 0.230389\n",
      "[559]\tvalid_0's binary_logloss: 0.230382\n",
      "[560]\tvalid_0's binary_logloss: 0.23038\n",
      "[561]\tvalid_0's binary_logloss: 0.230388\n",
      "[562]\tvalid_0's binary_logloss: 0.230384\n",
      "[563]\tvalid_0's binary_logloss: 0.230378\n",
      "[564]\tvalid_0's binary_logloss: 0.23037\n",
      "[565]\tvalid_0's binary_logloss: 0.230361\n",
      "[566]\tvalid_0's binary_logloss: 0.230339\n",
      "[567]\tvalid_0's binary_logloss: 0.230331\n",
      "[568]\tvalid_0's binary_logloss: 0.230332\n",
      "[569]\tvalid_0's binary_logloss: 0.230329\n",
      "[570]\tvalid_0's binary_logloss: 0.230325\n",
      "[571]\tvalid_0's binary_logloss: 0.230327\n",
      "[572]\tvalid_0's binary_logloss: 0.230327\n",
      "[573]\tvalid_0's binary_logloss: 0.230327\n",
      "[574]\tvalid_0's binary_logloss: 0.230313\n",
      "[575]\tvalid_0's binary_logloss: 0.230301\n",
      "[576]\tvalid_0's binary_logloss: 0.230288\n",
      "[577]\tvalid_0's binary_logloss: 0.230284\n",
      "[578]\tvalid_0's binary_logloss: 0.230277\n",
      "[579]\tvalid_0's binary_logloss: 0.230269\n",
      "[580]\tvalid_0's binary_logloss: 0.230263\n",
      "[581]\tvalid_0's binary_logloss: 0.230263\n",
      "[582]\tvalid_0's binary_logloss: 0.230263\n",
      "[583]\tvalid_0's binary_logloss: 0.230261\n",
      "[584]\tvalid_0's binary_logloss: 0.230252\n",
      "[585]\tvalid_0's binary_logloss: 0.230246\n",
      "[586]\tvalid_0's binary_logloss: 0.230244\n",
      "[587]\tvalid_0's binary_logloss: 0.230237\n",
      "[588]\tvalid_0's binary_logloss: 0.230243\n",
      "[589]\tvalid_0's binary_logloss: 0.230222\n",
      "[590]\tvalid_0's binary_logloss: 0.230213\n",
      "[591]\tvalid_0's binary_logloss: 0.230212\n",
      "[592]\tvalid_0's binary_logloss: 0.230187\n",
      "[593]\tvalid_0's binary_logloss: 0.230185\n",
      "[594]\tvalid_0's binary_logloss: 0.230179\n",
      "[595]\tvalid_0's binary_logloss: 0.230178\n",
      "[596]\tvalid_0's binary_logloss: 0.230162\n",
      "[597]\tvalid_0's binary_logloss: 0.230161\n",
      "[598]\tvalid_0's binary_logloss: 0.230153\n",
      "[599]\tvalid_0's binary_logloss: 0.230149\n",
      "[600]\tvalid_0's binary_logloss: 0.230143\n",
      "[601]\tvalid_0's binary_logloss: 0.230138\n",
      "[602]\tvalid_0's binary_logloss: 0.230114\n",
      "[603]\tvalid_0's binary_logloss: 0.230108\n",
      "[604]\tvalid_0's binary_logloss: 0.230114\n",
      "[605]\tvalid_0's binary_logloss: 0.230105\n",
      "[606]\tvalid_0's binary_logloss: 0.23011\n",
      "[607]\tvalid_0's binary_logloss: 0.230106\n",
      "[608]\tvalid_0's binary_logloss: 0.230096\n",
      "[609]\tvalid_0's binary_logloss: 0.23009\n",
      "[610]\tvalid_0's binary_logloss: 0.230088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[611]\tvalid_0's binary_logloss: 0.230081\n",
      "[612]\tvalid_0's binary_logloss: 0.230079\n",
      "[613]\tvalid_0's binary_logloss: 0.230072\n",
      "[614]\tvalid_0's binary_logloss: 0.230072\n",
      "[615]\tvalid_0's binary_logloss: 0.230074\n",
      "[616]\tvalid_0's binary_logloss: 0.230063\n",
      "[617]\tvalid_0's binary_logloss: 0.230045\n",
      "[618]\tvalid_0's binary_logloss: 0.230032\n",
      "[619]\tvalid_0's binary_logloss: 0.230035\n",
      "[620]\tvalid_0's binary_logloss: 0.230031\n",
      "[621]\tvalid_0's binary_logloss: 0.23003\n",
      "[622]\tvalid_0's binary_logloss: 0.230026\n",
      "[623]\tvalid_0's binary_logloss: 0.23003\n",
      "[624]\tvalid_0's binary_logloss: 0.230032\n",
      "[625]\tvalid_0's binary_logloss: 0.230025\n",
      "[626]\tvalid_0's binary_logloss: 0.230016\n",
      "[627]\tvalid_0's binary_logloss: 0.230007\n",
      "[628]\tvalid_0's binary_logloss: 0.230009\n",
      "[629]\tvalid_0's binary_logloss: 0.230008\n",
      "[630]\tvalid_0's binary_logloss: 0.230007\n",
      "[631]\tvalid_0's binary_logloss: 0.230014\n",
      "[632]\tvalid_0's binary_logloss: 0.230003\n",
      "[633]\tvalid_0's binary_logloss: 0.230006\n",
      "[634]\tvalid_0's binary_logloss: 0.230006\n",
      "[635]\tvalid_0's binary_logloss: 0.230006\n",
      "[636]\tvalid_0's binary_logloss: 0.229995\n",
      "[637]\tvalid_0's binary_logloss: 0.229983\n",
      "[638]\tvalid_0's binary_logloss: 0.229973\n",
      "[639]\tvalid_0's binary_logloss: 0.229973\n",
      "[640]\tvalid_0's binary_logloss: 0.229969\n",
      "[641]\tvalid_0's binary_logloss: 0.229963\n",
      "[642]\tvalid_0's binary_logloss: 0.22996\n",
      "[643]\tvalid_0's binary_logloss: 0.229969\n",
      "[644]\tvalid_0's binary_logloss: 0.229969\n",
      "[645]\tvalid_0's binary_logloss: 0.229968\n",
      "[646]\tvalid_0's binary_logloss: 0.229962\n",
      "[647]\tvalid_0's binary_logloss: 0.229957\n",
      "[648]\tvalid_0's binary_logloss: 0.229952\n",
      "[649]\tvalid_0's binary_logloss: 0.229957\n",
      "[650]\tvalid_0's binary_logloss: 0.229957\n",
      "[651]\tvalid_0's binary_logloss: 0.229955\n",
      "[652]\tvalid_0's binary_logloss: 0.229949\n",
      "[653]\tvalid_0's binary_logloss: 0.229947\n",
      "[654]\tvalid_0's binary_logloss: 0.22995\n",
      "[655]\tvalid_0's binary_logloss: 0.229952\n",
      "[656]\tvalid_0's binary_logloss: 0.229952\n",
      "[657]\tvalid_0's binary_logloss: 0.229946\n",
      "[658]\tvalid_0's binary_logloss: 0.229939\n",
      "[659]\tvalid_0's binary_logloss: 0.22993\n",
      "[660]\tvalid_0's binary_logloss: 0.229935\n",
      "[661]\tvalid_0's binary_logloss: 0.229937\n",
      "[662]\tvalid_0's binary_logloss: 0.229941\n",
      "[663]\tvalid_0's binary_logloss: 0.229936\n",
      "[664]\tvalid_0's binary_logloss: 0.22994\n",
      "Early stopping, best iteration is:\n",
      "[659]\tvalid_0's binary_logloss: 0.22993\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_data_train,\n",
    "    valid_sets=[lgb_data_val],\n",
    "    num_boost_round=lgb_params['num_boost_round'],\n",
    "    early_stopping_rounds=lgb_params['early_stopping_rounds'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>das_diff_len</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>das_who_both</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>das_where_both</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>emb_norm_sum_cosine</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>das_how_both</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>das_q1_when</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>das_word_match_2root</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>das_q2_where</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>das_q2_when</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>das_q1_why</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>das_when_both</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>das_q2_why</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>das_which_both</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>das_q1_who</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>das_q2_who</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>das_q2_how</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>das_q1_how</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>das_q1_where</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>das_q2_which</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>das_q1_which</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>das_q2_what</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>das_why_both</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>das_what_both</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>das_q1_what</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>token_len_diff_log</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>das_shared_count</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>emb_norm_sum_euclidean</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>das_len_word_q2</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>das_diff_len_word</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>das_len_word_q1</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jaccard_ix_2gram</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>das_stops1_ratio</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>emb_mean_cityblock_log</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fuzzy_partial_ratio</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>das_diff_stops_r</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>emb_mean_euclidean</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fuzzy_ratio</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>char_len_ratio</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>longer_char_len_log</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jaccard_ix_norm_q2_2gram</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>das_stops2_ratio</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>wmd</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>das_diff_avg_word</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>word_diff_ratio</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>das_avg_word_len1</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>das_avg_word_len2</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>das_words_hamming</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_cosine</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>das_shared_2gram</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>wordnet_similarity_raw</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fuzzy_token_sort_ratio</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>wordnet_similarity_brown</td>\n",
       "      <td>1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>magic_jt_q2_freq</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>magic_jt_q1_freq</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>das_cosine</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>oofp_nn_concat_dense_1</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>oofp_currie32_cnn</td>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>das_tfidf_word_match</td>\n",
       "      <td>1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>oofp_lystdo_lstm</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>magic_jt_freq_ratio</td>\n",
       "      <td>2095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      column  importance\n",
       "49              das_diff_len           0\n",
       "73              das_who_both           2\n",
       "76            das_where_both           3\n",
       "31       emb_norm_sum_cosine          12\n",
       "64              das_how_both          16\n",
       "77               das_q1_when          18\n",
       "38      das_word_match_2root          18\n",
       "75              das_q2_where          23\n",
       "78               das_q2_when          28\n",
       "80                das_q1_why          30\n",
       "79             das_when_both          33\n",
       "81                das_q2_why          34\n",
       "70            das_which_both          35\n",
       "71                das_q1_who          36\n",
       "72                das_q2_who          38\n",
       "63                das_q2_how          42\n",
       "62                das_q1_how          51\n",
       "74              das_q1_where          51\n",
       "69              das_q2_which          51\n",
       "68              das_q1_which          54\n",
       "66               das_q2_what          54\n",
       "82              das_why_both          55\n",
       "67             das_what_both          89\n",
       "65               das_q1_what          94\n",
       "5         token_len_diff_log         159\n",
       "40          das_shared_count         160\n",
       "33    emb_norm_sum_euclidean         183\n",
       "57           das_len_word_q2         212\n",
       "58         das_diff_len_word         219\n",
       "56           das_len_word_q1         228\n",
       "..                       ...         ...\n",
       "9           jaccard_ix_2gram         594\n",
       "41          das_stops1_ratio         597\n",
       "29    emb_mean_cityblock_log         603\n",
       "22       fuzzy_partial_ratio         606\n",
       "46          das_diff_stops_r         617\n",
       "30        emb_mean_euclidean         619\n",
       "21               fuzzy_ratio         621\n",
       "6             char_len_ratio         622\n",
       "1        longer_char_len_log         634\n",
       "11  jaccard_ix_norm_q2_2gram         687\n",
       "42          das_stops2_ratio         705\n",
       "34                       wmd         727\n",
       "61         das_diff_avg_word         727\n",
       "8            word_diff_ratio         777\n",
       "59         das_avg_word_len1         796\n",
       "60         das_avg_word_len2         825\n",
       "45         das_words_hamming         867\n",
       "26              tfidf_cosine         911\n",
       "43          das_shared_2gram         955\n",
       "35    wordnet_similarity_raw         991\n",
       "23    fuzzy_token_sort_ratio        1011\n",
       "36  wordnet_similarity_brown        1039\n",
       "84          magic_jt_q2_freq        1131\n",
       "83          magic_jt_q1_freq        1185\n",
       "44                das_cosine        1186\n",
       "86    oofp_nn_concat_dense_1        1354\n",
       "87         oofp_currie32_cnn        1392\n",
       "39      das_tfidf_word_match        1423\n",
       "88          oofp_lystdo_lstm        2035\n",
       "85       magic_jt_freq_ratio        2095\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'column': list(X_train.columns),\n",
    "    'importance': model.feature_importance(),\n",
    "}).sort_values(by='importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_classes(model, data, threshold=0.5):\n",
    "    y_pred = model.predict(data)\n",
    "    y_pred[y_pred < threshold] = 0\n",
    "    y_pred[y_pred >= threshold] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = predict_classes(model, X_train)\n",
    "y_pred_proba_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_val = predict_classes(model, X_val)\n",
    "y_pred_proba_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_metrics = [log_loss, roc_auc_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_metrics = [accuracy_score, precision_score, recall_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss            :    0.20147\n",
      "roc_auc_score       :    0.97385\n",
      "accuracy_score      :    0.90827\n",
      "precision_score     :    0.87437\n",
      "recall_score        :    0.87764\n"
     ]
    }
   ],
   "source": [
    "for metric in continuous_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_train, y_pred_proba_train)))\n",
    "for metric in binary_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss            :    0.22993\n",
      "roc_auc_score       :    0.96482\n",
      "accuracy_score      :    0.89514\n",
      "precision_score     :    0.86136\n",
      "recall_score        :    0.85331\n"
     ]
    }
   ],
   "source": [
    "for metric in continuous_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_val, y_pred_proba_val)))\n",
    "for metric in binary_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_val, y_pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stopping before the test set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-40376fef8556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping before the test set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Stopping before the test set"
     ]
    }
   ],
   "source": [
    "raise ValueError('Stopping before the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = read_dataset(features_data_folder + 'X_test_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_id = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\n",
    "    'test_id': range(len(y_test)),\n",
    "    'is_duplicate': y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = df_submission[['test_id', 'is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.274911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.325483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.047734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.991386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.692499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.215036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.004318\n",
       "1        1      0.274911\n",
       "2        2      0.325483\n",
       "3        3      0.000041\n",
       "4        4      0.047734\n",
       "5        5      0.000254\n",
       "6        6      0.991386\n",
       "7        7      0.692499\n",
       "8        8      0.215036\n",
       "9        9      0.003128"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(\n",
    "    submissions_data_folder + submission_id + '-submission-draft.csv',\n",
    "    header=True,\n",
    "    float_format='%.8f',\n",
    "    index=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
