{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep\n",
    "submissions_data_folder = os.path.join(data_folder, 'submissions') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename):\n",
    "    X = pd.read_csv(filename)\n",
    "    columns_to_remove = ['id', 'is_duplicate']\n",
    "    columns_to_remove = [\n",
    "        column\n",
    "        for column in columns_to_remove\n",
    "        if column in X.columns\n",
    "    ]\n",
    "    X.drop(columns_to_remove, axis=1, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = read_dataset(features_data_folder + 'X_train_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shorter_char_len_log              float64\n",
       "longer_char_len_log               float64\n",
       "shorter_token_len_log             float64\n",
       "longer_token_len_log              float64\n",
       "char_len_diff_log                 float64\n",
       "token_len_diff_log                float64\n",
       "char_len_ratio                    float64\n",
       "token_len_ratio                   float64\n",
       "word_diff_ratio                   float64\n",
       "fuzzy_ratio                       float64\n",
       "fuzzy_partial_ratio               float64\n",
       "fuzzy_token_sort_ratio            float64\n",
       "fuzzy_token_set_ratio             float64\n",
       "fuzzy_partial_token_sort_ratio    float64\n",
       "tfidf_cosine                      float64\n",
       "tfidf_euclidean                   float64\n",
       "emb_mean_cosine                   float64\n",
       "emb_mean_cityblock_log            float64\n",
       "emb_mean_euclidean                float64\n",
       "emb_norm_sum_cosine               float64\n",
       "emb_norm_sum_cityblock_log        float64\n",
       "emb_norm_sum_euclidean            float64\n",
       "wmd                               float64\n",
       "wordnet_similarity_raw            float64\n",
       "wordnet_similarity_brown          float64\n",
       "oofp_nn_concat_dense_1            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'device': 'cpu',\n",
    "#     'bagging_fraction': 0.5,\n",
    "#     'bagging_freq': 20,\n",
    "#     'feature_fraction': 0.8,\n",
    "    'num_leaves': 128,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_boost_round': 1000,\n",
    "    'early_stopping_rounds': 5,\n",
    "    'verbose': 1,\n",
    "    'bagging_fraction_seed': RANDOM_SEED,\n",
    "    'feature_fraction_seed': RANDOM_SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_dataset = lgb.Dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 38s, sys: 3.13 s, total: 12min 41s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_results = lgb.cv(\n",
    "    lgb_params,\n",
    "    lgb_dataset,\n",
    "    num_boost_round=lgb_params['num_boost_round'],\n",
    "    early_stopping_rounds=lgb_params['early_stopping_rounds'],\n",
    "    nfold=5,\n",
    "    stratified=True,\n",
    "    shuffle=True,\n",
    "    metrics=['binary_logloss'],\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_logloss-mean</th>\n",
       "      <th>binary_logloss-stdv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676657</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661117</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.646448</td>\n",
       "      <td>0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632602</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.619504</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.607107</td>\n",
       "      <td>0.003035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.595348</td>\n",
       "      <td>0.003421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.584207</td>\n",
       "      <td>0.003785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.573622</td>\n",
       "      <td>0.004108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.563563</td>\n",
       "      <td>0.004413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.553994</td>\n",
       "      <td>0.004708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.544894</td>\n",
       "      <td>0.004981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.536223</td>\n",
       "      <td>0.005228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.527961</td>\n",
       "      <td>0.005462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.520076</td>\n",
       "      <td>0.005669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.512564</td>\n",
       "      <td>0.005871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.505386</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.498525</td>\n",
       "      <td>0.006201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.491969</td>\n",
       "      <td>0.006356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.485700</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.479714</td>\n",
       "      <td>0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.006746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.468502</td>\n",
       "      <td>0.006865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.463250</td>\n",
       "      <td>0.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.458221</td>\n",
       "      <td>0.007063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.453418</td>\n",
       "      <td>0.007155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.448798</td>\n",
       "      <td>0.007221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.444376</td>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.440132</td>\n",
       "      <td>0.007368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.436060</td>\n",
       "      <td>0.007416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0.322455</td>\n",
       "      <td>0.005202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0.322459</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.322457</td>\n",
       "      <td>0.005203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.322450</td>\n",
       "      <td>0.005205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0.322450</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.322450</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.322447</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.322449</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.322446</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.322446</td>\n",
       "      <td>0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.322441</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0.322437</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.322435</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0.322430</td>\n",
       "      <td>0.005194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0.322425</td>\n",
       "      <td>0.005195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0.322423</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.322418</td>\n",
       "      <td>0.005186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0.322414</td>\n",
       "      <td>0.005186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.322415</td>\n",
       "      <td>0.005184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.322411</td>\n",
       "      <td>0.005188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.322409</td>\n",
       "      <td>0.005186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0.322409</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0.322405</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.322405</td>\n",
       "      <td>0.005184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0.322405</td>\n",
       "      <td>0.005186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.322399</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.322397</td>\n",
       "      <td>0.005187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.322395</td>\n",
       "      <td>0.005190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.322392</td>\n",
       "      <td>0.005191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.322390</td>\n",
       "      <td>0.005190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     binary_logloss-mean  binary_logloss-stdv\n",
       "0               0.676657             0.000616\n",
       "1               0.661117             0.001177\n",
       "2               0.646448             0.001702\n",
       "3               0.632602             0.002188\n",
       "4               0.619504             0.002634\n",
       "5               0.607107             0.003035\n",
       "6               0.595348             0.003421\n",
       "7               0.584207             0.003785\n",
       "8               0.573622             0.004108\n",
       "9               0.563563             0.004413\n",
       "10              0.553994             0.004708\n",
       "11              0.544894             0.004981\n",
       "12              0.536223             0.005228\n",
       "13              0.527961             0.005462\n",
       "14              0.520076             0.005669\n",
       "15              0.512564             0.005871\n",
       "16              0.505386             0.006040\n",
       "17              0.498525             0.006201\n",
       "18              0.491969             0.006356\n",
       "19              0.485700             0.006494\n",
       "20              0.479714             0.006625\n",
       "21              0.473986             0.006746\n",
       "22              0.468502             0.006865\n",
       "23              0.463250             0.006966\n",
       "24              0.458221             0.007063\n",
       "25              0.453418             0.007155\n",
       "26              0.448798             0.007221\n",
       "27              0.444376             0.007299\n",
       "28              0.440132             0.007368\n",
       "29              0.436060             0.007416\n",
       "..                   ...                  ...\n",
       "658             0.322455             0.005202\n",
       "659             0.322459             0.005204\n",
       "660             0.322457             0.005203\n",
       "661             0.322450             0.005205\n",
       "662             0.322450             0.005200\n",
       "663             0.322450             0.005198\n",
       "664             0.322447             0.005196\n",
       "665             0.322449             0.005196\n",
       "666             0.322446             0.005195\n",
       "667             0.322446             0.005192\n",
       "668             0.322441             0.005195\n",
       "669             0.322437             0.005195\n",
       "670             0.322435             0.005197\n",
       "671             0.322430             0.005194\n",
       "672             0.322425             0.005195\n",
       "673             0.322423             0.005198\n",
       "674             0.322418             0.005186\n",
       "675             0.322414             0.005186\n",
       "676             0.322415             0.005184\n",
       "677             0.322411             0.005188\n",
       "678             0.322409             0.005186\n",
       "679             0.322409             0.005185\n",
       "680             0.322405             0.005185\n",
       "681             0.322405             0.005184\n",
       "682             0.322405             0.005186\n",
       "683             0.322399             0.005185\n",
       "684             0.322397             0.005187\n",
       "685             0.322395             0.005190\n",
       "686             0.322392             0.005191\n",
       "687             0.322390             0.005190\n",
       "\n",
       "[688 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check (Train/Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_data_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_data_val = lgb.Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.676442\n",
      "Train until valid scores didn't improve in 5 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.660716\n",
      "[3]\tvalid_0's binary_logloss: 0.645893\n",
      "[4]\tvalid_0's binary_logloss: 0.631887\n",
      "[5]\tvalid_0's binary_logloss: 0.618627\n",
      "[6]\tvalid_0's binary_logloss: 0.606065\n",
      "[7]\tvalid_0's binary_logloss: 0.594184\n",
      "[8]\tvalid_0's binary_logloss: 0.5829\n",
      "[9]\tvalid_0's binary_logloss: 0.5722\n",
      "[10]\tvalid_0's binary_logloss: 0.562034\n",
      "[11]\tvalid_0's binary_logloss: 0.552351\n",
      "[12]\tvalid_0's binary_logloss: 0.543158\n",
      "[13]\tvalid_0's binary_logloss: 0.534389\n",
      "[14]\tvalid_0's binary_logloss: 0.52604\n",
      "[15]\tvalid_0's binary_logloss: 0.51807\n",
      "[16]\tvalid_0's binary_logloss: 0.510487\n",
      "[17]\tvalid_0's binary_logloss: 0.503261\n",
      "[18]\tvalid_0's binary_logloss: 0.496344\n",
      "[19]\tvalid_0's binary_logloss: 0.489728\n",
      "[20]\tvalid_0's binary_logloss: 0.483398\n",
      "[21]\tvalid_0's binary_logloss: 0.477352\n",
      "[22]\tvalid_0's binary_logloss: 0.471577\n",
      "[23]\tvalid_0's binary_logloss: 0.466049\n",
      "[24]\tvalid_0's binary_logloss: 0.460742\n",
      "[25]\tvalid_0's binary_logloss: 0.455669\n",
      "[26]\tvalid_0's binary_logloss: 0.4508\n",
      "[27]\tvalid_0's binary_logloss: 0.446144\n",
      "[28]\tvalid_0's binary_logloss: 0.441676\n",
      "[29]\tvalid_0's binary_logloss: 0.437403\n",
      "[30]\tvalid_0's binary_logloss: 0.433322\n",
      "[31]\tvalid_0's binary_logloss: 0.429399\n",
      "[32]\tvalid_0's binary_logloss: 0.42563\n",
      "[33]\tvalid_0's binary_logloss: 0.422017\n",
      "[34]\tvalid_0's binary_logloss: 0.41853\n",
      "[35]\tvalid_0's binary_logloss: 0.415191\n",
      "[36]\tvalid_0's binary_logloss: 0.412002\n",
      "[37]\tvalid_0's binary_logloss: 0.408916\n",
      "[38]\tvalid_0's binary_logloss: 0.405976\n",
      "[39]\tvalid_0's binary_logloss: 0.403124\n",
      "[40]\tvalid_0's binary_logloss: 0.400395\n",
      "[41]\tvalid_0's binary_logloss: 0.397772\n",
      "[42]\tvalid_0's binary_logloss: 0.395249\n",
      "[43]\tvalid_0's binary_logloss: 0.392822\n",
      "[44]\tvalid_0's binary_logloss: 0.390493\n",
      "[45]\tvalid_0's binary_logloss: 0.388251\n",
      "[46]\tvalid_0's binary_logloss: 0.38608\n",
      "[47]\tvalid_0's binary_logloss: 0.384008\n",
      "[48]\tvalid_0's binary_logloss: 0.382018\n",
      "[49]\tvalid_0's binary_logloss: 0.380098\n",
      "[50]\tvalid_0's binary_logloss: 0.378255\n",
      "[51]\tvalid_0's binary_logloss: 0.376469\n",
      "[52]\tvalid_0's binary_logloss: 0.374768\n",
      "[53]\tvalid_0's binary_logloss: 0.373117\n",
      "[54]\tvalid_0's binary_logloss: 0.371531\n",
      "[55]\tvalid_0's binary_logloss: 0.36999\n",
      "[56]\tvalid_0's binary_logloss: 0.368524\n",
      "[57]\tvalid_0's binary_logloss: 0.367099\n",
      "[58]\tvalid_0's binary_logloss: 0.365744\n",
      "[59]\tvalid_0's binary_logloss: 0.364443\n",
      "[60]\tvalid_0's binary_logloss: 0.363166\n",
      "[61]\tvalid_0's binary_logloss: 0.361919\n",
      "[62]\tvalid_0's binary_logloss: 0.360729\n",
      "[63]\tvalid_0's binary_logloss: 0.359593\n",
      "[64]\tvalid_0's binary_logloss: 0.358502\n",
      "[65]\tvalid_0's binary_logloss: 0.357449\n",
      "[66]\tvalid_0's binary_logloss: 0.356432\n",
      "[67]\tvalid_0's binary_logloss: 0.355443\n",
      "[68]\tvalid_0's binary_logloss: 0.354502\n",
      "[69]\tvalid_0's binary_logloss: 0.353586\n",
      "[70]\tvalid_0's binary_logloss: 0.352686\n",
      "[71]\tvalid_0's binary_logloss: 0.351826\n",
      "[72]\tvalid_0's binary_logloss: 0.350994\n",
      "[73]\tvalid_0's binary_logloss: 0.350189\n",
      "[74]\tvalid_0's binary_logloss: 0.349409\n",
      "[75]\tvalid_0's binary_logloss: 0.348636\n",
      "[76]\tvalid_0's binary_logloss: 0.347887\n",
      "[77]\tvalid_0's binary_logloss: 0.347177\n",
      "[78]\tvalid_0's binary_logloss: 0.346489\n",
      "[79]\tvalid_0's binary_logloss: 0.345839\n",
      "[80]\tvalid_0's binary_logloss: 0.345199\n",
      "[81]\tvalid_0's binary_logloss: 0.344591\n",
      "[82]\tvalid_0's binary_logloss: 0.343983\n",
      "[83]\tvalid_0's binary_logloss: 0.343404\n",
      "[84]\tvalid_0's binary_logloss: 0.34284\n",
      "[85]\tvalid_0's binary_logloss: 0.342306\n",
      "[86]\tvalid_0's binary_logloss: 0.341791\n",
      "[87]\tvalid_0's binary_logloss: 0.341296\n",
      "[88]\tvalid_0's binary_logloss: 0.340817\n",
      "[89]\tvalid_0's binary_logloss: 0.340324\n",
      "[90]\tvalid_0's binary_logloss: 0.339863\n",
      "[91]\tvalid_0's binary_logloss: 0.339426\n",
      "[92]\tvalid_0's binary_logloss: 0.339023\n",
      "[93]\tvalid_0's binary_logloss: 0.338598\n",
      "[94]\tvalid_0's binary_logloss: 0.338191\n",
      "[95]\tvalid_0's binary_logloss: 0.337814\n",
      "[96]\tvalid_0's binary_logloss: 0.337432\n",
      "[97]\tvalid_0's binary_logloss: 0.337061\n",
      "[98]\tvalid_0's binary_logloss: 0.336703\n",
      "[99]\tvalid_0's binary_logloss: 0.336374\n",
      "[100]\tvalid_0's binary_logloss: 0.336049\n",
      "[101]\tvalid_0's binary_logloss: 0.335693\n",
      "[102]\tvalid_0's binary_logloss: 0.335385\n",
      "[103]\tvalid_0's binary_logloss: 0.335084\n",
      "[104]\tvalid_0's binary_logloss: 0.334803\n",
      "[105]\tvalid_0's binary_logloss: 0.334502\n",
      "[106]\tvalid_0's binary_logloss: 0.334218\n",
      "[107]\tvalid_0's binary_logloss: 0.333936\n",
      "[108]\tvalid_0's binary_logloss: 0.333677\n",
      "[109]\tvalid_0's binary_logloss: 0.333421\n",
      "[110]\tvalid_0's binary_logloss: 0.333152\n",
      "[111]\tvalid_0's binary_logloss: 0.332923\n",
      "[112]\tvalid_0's binary_logloss: 0.3327\n",
      "[113]\tvalid_0's binary_logloss: 0.332482\n",
      "[114]\tvalid_0's binary_logloss: 0.332247\n",
      "[115]\tvalid_0's binary_logloss: 0.332026\n",
      "[116]\tvalid_0's binary_logloss: 0.331795\n",
      "[117]\tvalid_0's binary_logloss: 0.331587\n",
      "[118]\tvalid_0's binary_logloss: 0.331378\n",
      "[119]\tvalid_0's binary_logloss: 0.331192\n",
      "[120]\tvalid_0's binary_logloss: 0.331008\n",
      "[121]\tvalid_0's binary_logloss: 0.330826\n",
      "[122]\tvalid_0's binary_logloss: 0.330662\n",
      "[123]\tvalid_0's binary_logloss: 0.330502\n",
      "[124]\tvalid_0's binary_logloss: 0.330331\n",
      "[125]\tvalid_0's binary_logloss: 0.330172\n",
      "[126]\tvalid_0's binary_logloss: 0.330045\n",
      "[127]\tvalid_0's binary_logloss: 0.329903\n",
      "[128]\tvalid_0's binary_logloss: 0.329732\n",
      "[129]\tvalid_0's binary_logloss: 0.329561\n",
      "[130]\tvalid_0's binary_logloss: 0.329422\n",
      "[131]\tvalid_0's binary_logloss: 0.329284\n",
      "[132]\tvalid_0's binary_logloss: 0.32915\n",
      "[133]\tvalid_0's binary_logloss: 0.329\n",
      "[134]\tvalid_0's binary_logloss: 0.328862\n",
      "[135]\tvalid_0's binary_logloss: 0.328712\n",
      "[136]\tvalid_0's binary_logloss: 0.328558\n",
      "[137]\tvalid_0's binary_logloss: 0.328444\n",
      "[138]\tvalid_0's binary_logloss: 0.328318\n",
      "[139]\tvalid_0's binary_logloss: 0.328216\n",
      "[140]\tvalid_0's binary_logloss: 0.32808\n",
      "[141]\tvalid_0's binary_logloss: 0.327954\n",
      "[142]\tvalid_0's binary_logloss: 0.327847\n",
      "[143]\tvalid_0's binary_logloss: 0.327749\n",
      "[144]\tvalid_0's binary_logloss: 0.327658\n",
      "[145]\tvalid_0's binary_logloss: 0.327567\n",
      "[146]\tvalid_0's binary_logloss: 0.327453\n",
      "[147]\tvalid_0's binary_logloss: 0.327367\n",
      "[148]\tvalid_0's binary_logloss: 0.32727\n",
      "[149]\tvalid_0's binary_logloss: 0.327141\n",
      "[150]\tvalid_0's binary_logloss: 0.327055\n",
      "[151]\tvalid_0's binary_logloss: 0.326927\n",
      "[152]\tvalid_0's binary_logloss: 0.326852\n",
      "[153]\tvalid_0's binary_logloss: 0.326718\n",
      "[154]\tvalid_0's binary_logloss: 0.326612\n",
      "[155]\tvalid_0's binary_logloss: 0.32654\n",
      "[156]\tvalid_0's binary_logloss: 0.326426\n",
      "[157]\tvalid_0's binary_logloss: 0.326353\n",
      "[158]\tvalid_0's binary_logloss: 0.326288\n",
      "[159]\tvalid_0's binary_logloss: 0.326242\n",
      "[160]\tvalid_0's binary_logloss: 0.326186\n",
      "[161]\tvalid_0's binary_logloss: 0.32612\n",
      "[162]\tvalid_0's binary_logloss: 0.326032\n",
      "[163]\tvalid_0's binary_logloss: 0.325957\n",
      "[164]\tvalid_0's binary_logloss: 0.325868\n",
      "[165]\tvalid_0's binary_logloss: 0.325787\n",
      "[166]\tvalid_0's binary_logloss: 0.32571\n",
      "[167]\tvalid_0's binary_logloss: 0.325647\n",
      "[168]\tvalid_0's binary_logloss: 0.325558\n",
      "[169]\tvalid_0's binary_logloss: 0.325478\n",
      "[170]\tvalid_0's binary_logloss: 0.325424\n",
      "[171]\tvalid_0's binary_logloss: 0.325355\n",
      "[172]\tvalid_0's binary_logloss: 0.325286\n",
      "[173]\tvalid_0's binary_logloss: 0.325209\n",
      "[174]\tvalid_0's binary_logloss: 0.325147\n",
      "[175]\tvalid_0's binary_logloss: 0.325113\n",
      "[176]\tvalid_0's binary_logloss: 0.325047\n",
      "[177]\tvalid_0's binary_logloss: 0.324991\n",
      "[178]\tvalid_0's binary_logloss: 0.324962\n",
      "[179]\tvalid_0's binary_logloss: 0.324908\n",
      "[180]\tvalid_0's binary_logloss: 0.324873\n",
      "[181]\tvalid_0's binary_logloss: 0.324851\n",
      "[182]\tvalid_0's binary_logloss: 0.324798\n",
      "[183]\tvalid_0's binary_logloss: 0.324761\n",
      "[184]\tvalid_0's binary_logloss: 0.324729\n",
      "[185]\tvalid_0's binary_logloss: 0.324675\n",
      "[186]\tvalid_0's binary_logloss: 0.324641\n",
      "[187]\tvalid_0's binary_logloss: 0.324612\n",
      "[188]\tvalid_0's binary_logloss: 0.324563\n",
      "[189]\tvalid_0's binary_logloss: 0.324524\n",
      "[190]\tvalid_0's binary_logloss: 0.324497\n",
      "[191]\tvalid_0's binary_logloss: 0.324441\n",
      "[192]\tvalid_0's binary_logloss: 0.324389\n",
      "[193]\tvalid_0's binary_logloss: 0.324348\n",
      "[194]\tvalid_0's binary_logloss: 0.324296\n",
      "[195]\tvalid_0's binary_logloss: 0.324266\n",
      "[196]\tvalid_0's binary_logloss: 0.324221\n",
      "[197]\tvalid_0's binary_logloss: 0.324202\n",
      "[198]\tvalid_0's binary_logloss: 0.324169\n",
      "[199]\tvalid_0's binary_logloss: 0.32414\n",
      "[200]\tvalid_0's binary_logloss: 0.324111\n",
      "[201]\tvalid_0's binary_logloss: 0.324076\n",
      "[202]\tvalid_0's binary_logloss: 0.324053\n",
      "[203]\tvalid_0's binary_logloss: 0.324035\n",
      "[204]\tvalid_0's binary_logloss: 0.32402\n",
      "[205]\tvalid_0's binary_logloss: 0.323988\n",
      "[206]\tvalid_0's binary_logloss: 0.323965\n",
      "[207]\tvalid_0's binary_logloss: 0.323949\n",
      "[208]\tvalid_0's binary_logloss: 0.32393\n",
      "[209]\tvalid_0's binary_logloss: 0.323917\n",
      "[210]\tvalid_0's binary_logloss: 0.323895\n",
      "[211]\tvalid_0's binary_logloss: 0.323891\n",
      "[212]\tvalid_0's binary_logloss: 0.323878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213]\tvalid_0's binary_logloss: 0.323852\n",
      "[214]\tvalid_0's binary_logloss: 0.323794\n",
      "[215]\tvalid_0's binary_logloss: 0.323767\n",
      "[216]\tvalid_0's binary_logloss: 0.32374\n",
      "[217]\tvalid_0's binary_logloss: 0.32371\n",
      "[218]\tvalid_0's binary_logloss: 0.323683\n",
      "[219]\tvalid_0's binary_logloss: 0.323666\n",
      "[220]\tvalid_0's binary_logloss: 0.32365\n",
      "[221]\tvalid_0's binary_logloss: 0.323627\n",
      "[222]\tvalid_0's binary_logloss: 0.323615\n",
      "[223]\tvalid_0's binary_logloss: 0.323606\n",
      "[224]\tvalid_0's binary_logloss: 0.32358\n",
      "[225]\tvalid_0's binary_logloss: 0.323555\n",
      "[226]\tvalid_0's binary_logloss: 0.323525\n",
      "[227]\tvalid_0's binary_logloss: 0.323512\n",
      "[228]\tvalid_0's binary_logloss: 0.323506\n",
      "[229]\tvalid_0's binary_logloss: 0.323495\n",
      "[230]\tvalid_0's binary_logloss: 0.323454\n",
      "[231]\tvalid_0's binary_logloss: 0.323451\n",
      "[232]\tvalid_0's binary_logloss: 0.323416\n",
      "[233]\tvalid_0's binary_logloss: 0.323402\n",
      "[234]\tvalid_0's binary_logloss: 0.323351\n",
      "[235]\tvalid_0's binary_logloss: 0.323349\n",
      "[236]\tvalid_0's binary_logloss: 0.323341\n",
      "[237]\tvalid_0's binary_logloss: 0.323328\n",
      "[238]\tvalid_0's binary_logloss: 0.32332\n",
      "[239]\tvalid_0's binary_logloss: 0.323286\n",
      "[240]\tvalid_0's binary_logloss: 0.323243\n",
      "[241]\tvalid_0's binary_logloss: 0.323231\n",
      "[242]\tvalid_0's binary_logloss: 0.323222\n",
      "[243]\tvalid_0's binary_logloss: 0.323181\n",
      "[244]\tvalid_0's binary_logloss: 0.32315\n",
      "[245]\tvalid_0's binary_logloss: 0.323152\n",
      "[246]\tvalid_0's binary_logloss: 0.323131\n",
      "[247]\tvalid_0's binary_logloss: 0.323124\n",
      "[248]\tvalid_0's binary_logloss: 0.323115\n",
      "[249]\tvalid_0's binary_logloss: 0.323071\n",
      "[250]\tvalid_0's binary_logloss: 0.323042\n",
      "[251]\tvalid_0's binary_logloss: 0.32302\n",
      "[252]\tvalid_0's binary_logloss: 0.322997\n",
      "[253]\tvalid_0's binary_logloss: 0.32299\n",
      "[254]\tvalid_0's binary_logloss: 0.322971\n",
      "[255]\tvalid_0's binary_logloss: 0.322964\n",
      "[256]\tvalid_0's binary_logloss: 0.322951\n",
      "[257]\tvalid_0's binary_logloss: 0.322921\n",
      "[258]\tvalid_0's binary_logloss: 0.322915\n",
      "[259]\tvalid_0's binary_logloss: 0.322897\n",
      "[260]\tvalid_0's binary_logloss: 0.32287\n",
      "[261]\tvalid_0's binary_logloss: 0.322861\n",
      "[262]\tvalid_0's binary_logloss: 0.322834\n",
      "[263]\tvalid_0's binary_logloss: 0.322822\n",
      "[264]\tvalid_0's binary_logloss: 0.322803\n",
      "[265]\tvalid_0's binary_logloss: 0.3228\n",
      "[266]\tvalid_0's binary_logloss: 0.322781\n",
      "[267]\tvalid_0's binary_logloss: 0.322775\n",
      "[268]\tvalid_0's binary_logloss: 0.322737\n",
      "[269]\tvalid_0's binary_logloss: 0.32273\n",
      "[270]\tvalid_0's binary_logloss: 0.322726\n",
      "[271]\tvalid_0's binary_logloss: 0.322725\n",
      "[272]\tvalid_0's binary_logloss: 0.322721\n",
      "[273]\tvalid_0's binary_logloss: 0.322693\n",
      "[274]\tvalid_0's binary_logloss: 0.322691\n",
      "[275]\tvalid_0's binary_logloss: 0.322688\n",
      "[276]\tvalid_0's binary_logloss: 0.322688\n",
      "[277]\tvalid_0's binary_logloss: 0.322678\n",
      "[278]\tvalid_0's binary_logloss: 0.322671\n",
      "[279]\tvalid_0's binary_logloss: 0.322652\n",
      "[280]\tvalid_0's binary_logloss: 0.322637\n",
      "[281]\tvalid_0's binary_logloss: 0.322639\n",
      "[282]\tvalid_0's binary_logloss: 0.322636\n",
      "[283]\tvalid_0's binary_logloss: 0.322629\n",
      "[284]\tvalid_0's binary_logloss: 0.322596\n",
      "[285]\tvalid_0's binary_logloss: 0.322598\n",
      "[286]\tvalid_0's binary_logloss: 0.322593\n",
      "[287]\tvalid_0's binary_logloss: 0.322572\n",
      "[288]\tvalid_0's binary_logloss: 0.322565\n",
      "[289]\tvalid_0's binary_logloss: 0.322571\n",
      "[290]\tvalid_0's binary_logloss: 0.322556\n",
      "[291]\tvalid_0's binary_logloss: 0.322551\n",
      "[292]\tvalid_0's binary_logloss: 0.32254\n",
      "[293]\tvalid_0's binary_logloss: 0.322527\n",
      "[294]\tvalid_0's binary_logloss: 0.32252\n",
      "[295]\tvalid_0's binary_logloss: 0.322506\n",
      "[296]\tvalid_0's binary_logloss: 0.322498\n",
      "[297]\tvalid_0's binary_logloss: 0.322472\n",
      "[298]\tvalid_0's binary_logloss: 0.32247\n",
      "[299]\tvalid_0's binary_logloss: 0.322467\n",
      "[300]\tvalid_0's binary_logloss: 0.322464\n",
      "[301]\tvalid_0's binary_logloss: 0.32245\n",
      "[302]\tvalid_0's binary_logloss: 0.322445\n",
      "[303]\tvalid_0's binary_logloss: 0.32244\n",
      "[304]\tvalid_0's binary_logloss: 0.322431\n",
      "[305]\tvalid_0's binary_logloss: 0.322436\n",
      "[306]\tvalid_0's binary_logloss: 0.322423\n",
      "[307]\tvalid_0's binary_logloss: 0.322409\n",
      "[308]\tvalid_0's binary_logloss: 0.322407\n",
      "[309]\tvalid_0's binary_logloss: 0.322394\n",
      "[310]\tvalid_0's binary_logloss: 0.322373\n",
      "[311]\tvalid_0's binary_logloss: 0.322353\n",
      "[312]\tvalid_0's binary_logloss: 0.322354\n",
      "[313]\tvalid_0's binary_logloss: 0.322355\n",
      "[314]\tvalid_0's binary_logloss: 0.322357\n",
      "[315]\tvalid_0's binary_logloss: 0.322346\n",
      "[316]\tvalid_0's binary_logloss: 0.32234\n",
      "[317]\tvalid_0's binary_logloss: 0.322326\n",
      "[318]\tvalid_0's binary_logloss: 0.322307\n",
      "[319]\tvalid_0's binary_logloss: 0.322292\n",
      "[320]\tvalid_0's binary_logloss: 0.322262\n",
      "[321]\tvalid_0's binary_logloss: 0.322254\n",
      "[322]\tvalid_0's binary_logloss: 0.322247\n",
      "[323]\tvalid_0's binary_logloss: 0.322231\n",
      "[324]\tvalid_0's binary_logloss: 0.322219\n",
      "[325]\tvalid_0's binary_logloss: 0.322199\n",
      "[326]\tvalid_0's binary_logloss: 0.322184\n",
      "[327]\tvalid_0's binary_logloss: 0.32217\n",
      "[328]\tvalid_0's binary_logloss: 0.32217\n",
      "[329]\tvalid_0's binary_logloss: 0.322168\n",
      "[330]\tvalid_0's binary_logloss: 0.322158\n",
      "[331]\tvalid_0's binary_logloss: 0.322149\n",
      "[332]\tvalid_0's binary_logloss: 0.322148\n",
      "[333]\tvalid_0's binary_logloss: 0.322138\n",
      "[334]\tvalid_0's binary_logloss: 0.322122\n",
      "[335]\tvalid_0's binary_logloss: 0.322117\n",
      "[336]\tvalid_0's binary_logloss: 0.322094\n",
      "[337]\tvalid_0's binary_logloss: 0.322087\n",
      "[338]\tvalid_0's binary_logloss: 0.322091\n",
      "[339]\tvalid_0's binary_logloss: 0.322085\n",
      "[340]\tvalid_0's binary_logloss: 0.32208\n",
      "[341]\tvalid_0's binary_logloss: 0.322076\n",
      "[342]\tvalid_0's binary_logloss: 0.322069\n",
      "[343]\tvalid_0's binary_logloss: 0.322056\n",
      "[344]\tvalid_0's binary_logloss: 0.32205\n",
      "[345]\tvalid_0's binary_logloss: 0.322053\n",
      "[346]\tvalid_0's binary_logloss: 0.322016\n",
      "[347]\tvalid_0's binary_logloss: 0.322017\n",
      "[348]\tvalid_0's binary_logloss: 0.321994\n",
      "[349]\tvalid_0's binary_logloss: 0.321997\n",
      "[350]\tvalid_0's binary_logloss: 0.321994\n",
      "[351]\tvalid_0's binary_logloss: 0.321967\n",
      "[352]\tvalid_0's binary_logloss: 0.321952\n",
      "[353]\tvalid_0's binary_logloss: 0.321959\n",
      "[354]\tvalid_0's binary_logloss: 0.321959\n",
      "[355]\tvalid_0's binary_logloss: 0.321945\n",
      "[356]\tvalid_0's binary_logloss: 0.321936\n",
      "[357]\tvalid_0's binary_logloss: 0.321927\n",
      "[358]\tvalid_0's binary_logloss: 0.321921\n",
      "[359]\tvalid_0's binary_logloss: 0.321916\n",
      "[360]\tvalid_0's binary_logloss: 0.321906\n",
      "[361]\tvalid_0's binary_logloss: 0.321898\n",
      "[362]\tvalid_0's binary_logloss: 0.321885\n",
      "[363]\tvalid_0's binary_logloss: 0.321879\n",
      "[364]\tvalid_0's binary_logloss: 0.321875\n",
      "[365]\tvalid_0's binary_logloss: 0.321864\n",
      "[366]\tvalid_0's binary_logloss: 0.32186\n",
      "[367]\tvalid_0's binary_logloss: 0.321852\n",
      "[368]\tvalid_0's binary_logloss: 0.321855\n",
      "[369]\tvalid_0's binary_logloss: 0.321859\n",
      "[370]\tvalid_0's binary_logloss: 0.321842\n",
      "[371]\tvalid_0's binary_logloss: 0.321836\n",
      "[372]\tvalid_0's binary_logloss: 0.32183\n",
      "[373]\tvalid_0's binary_logloss: 0.321813\n",
      "[374]\tvalid_0's binary_logloss: 0.321807\n",
      "[375]\tvalid_0's binary_logloss: 0.321802\n",
      "[376]\tvalid_0's binary_logloss: 0.321805\n",
      "[377]\tvalid_0's binary_logloss: 0.321797\n",
      "[378]\tvalid_0's binary_logloss: 0.321779\n",
      "[379]\tvalid_0's binary_logloss: 0.32178\n",
      "[380]\tvalid_0's binary_logloss: 0.321771\n",
      "[381]\tvalid_0's binary_logloss: 0.321768\n",
      "[382]\tvalid_0's binary_logloss: 0.321762\n",
      "[383]\tvalid_0's binary_logloss: 0.321768\n",
      "[384]\tvalid_0's binary_logloss: 0.321752\n",
      "[385]\tvalid_0's binary_logloss: 0.321739\n",
      "[386]\tvalid_0's binary_logloss: 0.321726\n",
      "[387]\tvalid_0's binary_logloss: 0.321714\n",
      "[388]\tvalid_0's binary_logloss: 0.321718\n",
      "[389]\tvalid_0's binary_logloss: 0.321716\n",
      "[390]\tvalid_0's binary_logloss: 0.321707\n",
      "[391]\tvalid_0's binary_logloss: 0.321702\n",
      "[392]\tvalid_0's binary_logloss: 0.321684\n",
      "[393]\tvalid_0's binary_logloss: 0.321688\n",
      "[394]\tvalid_0's binary_logloss: 0.321669\n",
      "[395]\tvalid_0's binary_logloss: 0.321662\n",
      "[396]\tvalid_0's binary_logloss: 0.32166\n",
      "[397]\tvalid_0's binary_logloss: 0.321657\n",
      "[398]\tvalid_0's binary_logloss: 0.321657\n",
      "[399]\tvalid_0's binary_logloss: 0.321649\n",
      "[400]\tvalid_0's binary_logloss: 0.321633\n",
      "[401]\tvalid_0's binary_logloss: 0.321628\n",
      "[402]\tvalid_0's binary_logloss: 0.321622\n",
      "[403]\tvalid_0's binary_logloss: 0.321605\n",
      "[404]\tvalid_0's binary_logloss: 0.321609\n",
      "[405]\tvalid_0's binary_logloss: 0.321603\n",
      "[406]\tvalid_0's binary_logloss: 0.321612\n",
      "[407]\tvalid_0's binary_logloss: 0.321605\n",
      "[408]\tvalid_0's binary_logloss: 0.321608\n",
      "[409]\tvalid_0's binary_logloss: 0.3216\n",
      "[410]\tvalid_0's binary_logloss: 0.321589\n",
      "[411]\tvalid_0's binary_logloss: 0.321576\n",
      "[412]\tvalid_0's binary_logloss: 0.32157\n",
      "[413]\tvalid_0's binary_logloss: 0.321566\n",
      "[414]\tvalid_0's binary_logloss: 0.32156\n",
      "[415]\tvalid_0's binary_logloss: 0.321557\n",
      "[416]\tvalid_0's binary_logloss: 0.321563\n",
      "[417]\tvalid_0's binary_logloss: 0.32156\n",
      "[418]\tvalid_0's binary_logloss: 0.32155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[419]\tvalid_0's binary_logloss: 0.321556\n",
      "[420]\tvalid_0's binary_logloss: 0.321542\n",
      "[421]\tvalid_0's binary_logloss: 0.32152\n",
      "[422]\tvalid_0's binary_logloss: 0.32152\n",
      "[423]\tvalid_0's binary_logloss: 0.321506\n",
      "[424]\tvalid_0's binary_logloss: 0.321497\n",
      "[425]\tvalid_0's binary_logloss: 0.321484\n",
      "[426]\tvalid_0's binary_logloss: 0.321488\n",
      "[427]\tvalid_0's binary_logloss: 0.321488\n",
      "[428]\tvalid_0's binary_logloss: 0.321476\n",
      "[429]\tvalid_0's binary_logloss: 0.321477\n",
      "[430]\tvalid_0's binary_logloss: 0.321477\n",
      "[431]\tvalid_0's binary_logloss: 0.32146\n",
      "[432]\tvalid_0's binary_logloss: 0.321452\n",
      "[433]\tvalid_0's binary_logloss: 0.321443\n",
      "[434]\tvalid_0's binary_logloss: 0.321443\n",
      "[435]\tvalid_0's binary_logloss: 0.321441\n",
      "[436]\tvalid_0's binary_logloss: 0.321435\n",
      "[437]\tvalid_0's binary_logloss: 0.321431\n",
      "[438]\tvalid_0's binary_logloss: 0.321427\n",
      "[439]\tvalid_0's binary_logloss: 0.321415\n",
      "[440]\tvalid_0's binary_logloss: 0.32141\n",
      "[441]\tvalid_0's binary_logloss: 0.321403\n",
      "[442]\tvalid_0's binary_logloss: 0.321379\n",
      "[443]\tvalid_0's binary_logloss: 0.321359\n",
      "[444]\tvalid_0's binary_logloss: 0.321364\n",
      "[445]\tvalid_0's binary_logloss: 0.321356\n",
      "[446]\tvalid_0's binary_logloss: 0.321343\n",
      "[447]\tvalid_0's binary_logloss: 0.321345\n",
      "[448]\tvalid_0's binary_logloss: 0.321342\n",
      "[449]\tvalid_0's binary_logloss: 0.321348\n",
      "[450]\tvalid_0's binary_logloss: 0.321343\n",
      "[451]\tvalid_0's binary_logloss: 0.321339\n",
      "[452]\tvalid_0's binary_logloss: 0.321334\n",
      "[453]\tvalid_0's binary_logloss: 0.321329\n",
      "[454]\tvalid_0's binary_logloss: 0.321325\n",
      "[455]\tvalid_0's binary_logloss: 0.321308\n",
      "[456]\tvalid_0's binary_logloss: 0.321318\n",
      "[457]\tvalid_0's binary_logloss: 0.321316\n",
      "[458]\tvalid_0's binary_logloss: 0.321305\n",
      "[459]\tvalid_0's binary_logloss: 0.321285\n",
      "[460]\tvalid_0's binary_logloss: 0.321277\n",
      "[461]\tvalid_0's binary_logloss: 0.321264\n",
      "[462]\tvalid_0's binary_logloss: 0.321265\n",
      "[463]\tvalid_0's binary_logloss: 0.321263\n",
      "[464]\tvalid_0's binary_logloss: 0.321265\n",
      "[465]\tvalid_0's binary_logloss: 0.321259\n",
      "[466]\tvalid_0's binary_logloss: 0.321257\n",
      "[467]\tvalid_0's binary_logloss: 0.321249\n",
      "[468]\tvalid_0's binary_logloss: 0.321232\n",
      "[469]\tvalid_0's binary_logloss: 0.321233\n",
      "[470]\tvalid_0's binary_logloss: 0.321231\n",
      "[471]\tvalid_0's binary_logloss: 0.321228\n",
      "[472]\tvalid_0's binary_logloss: 0.321218\n",
      "[473]\tvalid_0's binary_logloss: 0.321218\n",
      "[474]\tvalid_0's binary_logloss: 0.321215\n",
      "[475]\tvalid_0's binary_logloss: 0.321218\n",
      "[476]\tvalid_0's binary_logloss: 0.321209\n",
      "[477]\tvalid_0's binary_logloss: 0.321207\n",
      "[478]\tvalid_0's binary_logloss: 0.321215\n",
      "[479]\tvalid_0's binary_logloss: 0.321215\n",
      "[480]\tvalid_0's binary_logloss: 0.321212\n",
      "[481]\tvalid_0's binary_logloss: 0.321204\n",
      "[482]\tvalid_0's binary_logloss: 0.321204\n",
      "[483]\tvalid_0's binary_logloss: 0.321207\n",
      "[484]\tvalid_0's binary_logloss: 0.321211\n",
      "[485]\tvalid_0's binary_logloss: 0.321208\n",
      "[486]\tvalid_0's binary_logloss: 0.321199\n",
      "[487]\tvalid_0's binary_logloss: 0.321198\n",
      "[488]\tvalid_0's binary_logloss: 0.321193\n",
      "[489]\tvalid_0's binary_logloss: 0.321193\n",
      "[490]\tvalid_0's binary_logloss: 0.321192\n",
      "[491]\tvalid_0's binary_logloss: 0.321186\n",
      "[492]\tvalid_0's binary_logloss: 0.321167\n",
      "[493]\tvalid_0's binary_logloss: 0.321167\n",
      "[494]\tvalid_0's binary_logloss: 0.321156\n",
      "[495]\tvalid_0's binary_logloss: 0.321164\n",
      "[496]\tvalid_0's binary_logloss: 0.321159\n",
      "[497]\tvalid_0's binary_logloss: 0.321158\n",
      "[498]\tvalid_0's binary_logloss: 0.32115\n",
      "[499]\tvalid_0's binary_logloss: 0.321147\n",
      "[500]\tvalid_0's binary_logloss: 0.321135\n",
      "[501]\tvalid_0's binary_logloss: 0.321131\n",
      "[502]\tvalid_0's binary_logloss: 0.321129\n",
      "[503]\tvalid_0's binary_logloss: 0.321131\n",
      "[504]\tvalid_0's binary_logloss: 0.321127\n",
      "[505]\tvalid_0's binary_logloss: 0.321112\n",
      "[506]\tvalid_0's binary_logloss: 0.321113\n",
      "[507]\tvalid_0's binary_logloss: 0.321104\n",
      "[508]\tvalid_0's binary_logloss: 0.3211\n",
      "[509]\tvalid_0's binary_logloss: 0.321102\n",
      "[510]\tvalid_0's binary_logloss: 0.321103\n",
      "[511]\tvalid_0's binary_logloss: 0.321105\n",
      "[512]\tvalid_0's binary_logloss: 0.321108\n",
      "[513]\tvalid_0's binary_logloss: 0.321109\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's binary_logloss: 0.3211\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_data_train,\n",
    "    valid_sets=[lgb_data_val],\n",
    "    num_boost_round=lgb_params['num_boost_round'],\n",
    "    early_stopping_rounds=lgb_params['early_stopping_rounds'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_classes(model, data, threshold=0.5):\n",
    "    y_pred = model.predict(data)\n",
    "    y_pred[y_pred < threshold] = 0\n",
    "    y_pred[y_pred >= threshold] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = predict_classes(model, X_train)\n",
    "y_pred_proba_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_val = predict_classes(model, X_val)\n",
    "y_pred_proba_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_metrics = [log_loss, roc_auc_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_metrics = [accuracy_score, precision_score, recall_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss            :    0.28266\n",
      "roc_auc_score       :    0.94744\n",
      "accuracy_score      :    0.86968\n",
      "precision_score     :    0.81639\n",
      "recall_score        :    0.83476\n"
     ]
    }
   ],
   "source": [
    "for metric in continuous_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_train, y_pred_proba_train)))\n",
    "for metric in binary_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss            :    0.32110\n",
      "roc_auc_score       :    0.93017\n",
      "accuracy_score      :    0.85090\n",
      "precision_score     :    0.78773\n",
      "recall_score        :    0.81607\n"
     ]
    }
   ],
   "source": [
    "for metric in continuous_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_val, y_pred_proba_val)))\n",
    "for metric in binary_metrics:\n",
    "    print('{:20s}: {:10.5f}'.format(metric.__name__, metric(y_val, y_pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stopping before the test set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-40376fef8556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping before the test set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Stopping before the test set"
     ]
    }
   ],
   "source": [
    "raise ValueError('Stopping before the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = read_dataset(features_data_folder + 'X_test_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_id = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\n",
    "    'test_id': range(len(y_test)),\n",
    "    'is_duplicate': y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = df_submission[['test_id', 'is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(\n",
    "    submissions_data_folder + submission_id + '-submission-draft.csv',\n",
    "    header=True,\n",
    "    float_format='%.8f',\n",
    "    index=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
