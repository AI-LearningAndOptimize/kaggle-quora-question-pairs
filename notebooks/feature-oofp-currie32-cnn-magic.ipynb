{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_currie32_cnn_magic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "magic_feature_lists = [\n",
    "    'magic_jturkewitz',\n",
    "    'magic_stas_svd_150',\n",
    "    'magic_stas_avito',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic, X_test_magic, _ = load_feature_lists(magic_feature_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic = X_train_magic.values\n",
    "X_test_magic = X_test_magic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack([X_train_magic, X_test_magic]))\n",
    "X_train_magic = scaler.transform(X_train_magic)\n",
    "X_test_magic = scaler.transform(X_test_magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
    "init_bias = 'zeros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedding_block():\n",
    "    input_seq = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n",
    "    \n",
    "    embedding_seq = Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    )(input_seq)\n",
    "    \n",
    "    output_seq = embedding_seq\n",
    "    return input_seq, output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_question_conv_branch(input_seq, params):\n",
    "    conv_1 = Conv1D(\n",
    "        params['num_conv_filters'],\n",
    "        kernel_size=params['conv_kernel_size'],\n",
    "        padding='same',\n",
    "    )(input_seq)\n",
    "    \n",
    "    bn_1 = BatchNormalization()(conv_1)\n",
    "    relu_1 = Activation('relu')(bn_1)\n",
    "    dropout_1 = Dropout(params['conv_dropout_rate'])(relu_1)\n",
    "\n",
    "    conv_2 = Conv1D(\n",
    "        params['num_conv_filters'],\n",
    "        kernel_size=params['conv_kernel_size'],\n",
    "        padding='same',\n",
    "    )(dropout_1)\n",
    "    \n",
    "    bn_2 = BatchNormalization()(conv_2)\n",
    "    relu_2 = Activation('relu')(bn_2)\n",
    "    dropout_2 = Dropout(params['conv_dropout_rate'])(relu_2)\n",
    "    \n",
    "    flatten = Flatten()(dropout_2)\n",
    "    output = flatten\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_question_timedist_max_branch(input_seq, params):\n",
    "    timedist = TimeDistributed(Dense(EMBEDDING_DIM))(input_seq)\n",
    "    bn = BatchNormalization()(timedist)\n",
    "    relu = Activation('relu')(bn)\n",
    "    dropout = Dropout(params['timedist_dropout_rate'])(relu)\n",
    "\n",
    "    lambda_max = Lambda(\n",
    "        lambda x: K.max(x, axis=1),\n",
    "        output_shape=(EMBEDDING_DIM, )\n",
    "    )(dropout)\n",
    "    \n",
    "    output = lambda_max\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dense_block(input_layer, num_units, dropout_rate):\n",
    "    dense = Dense(\n",
    "        num_units,\n",
    "        kernel_initializer=init_weights,\n",
    "        bias_initializer=init_bias,\n",
    "    )(input_layer)\n",
    "    bn = BatchNormalization()(dense)\n",
    "    relu = Activation('relu')(bn)\n",
    "    dropout = Dropout(dropout_rate)(relu)\n",
    "    output = dropout\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    input_q1, emb_q1 = create_embedding_block()\n",
    "    input_q2, emb_q2 = create_embedding_block()\n",
    "    \n",
    "    # Feature extractors.\n",
    "    conv_q1_output = create_model_question_conv_branch(emb_q1, params)\n",
    "    conv_q2_output = create_model_question_conv_branch(emb_q2, params)\n",
    "    \n",
    "    timedist_q1_output = create_model_question_timedist_max_branch(emb_q1, params)\n",
    "    timedist_q2_output = create_model_question_timedist_max_branch(emb_q2, params)\n",
    "    \n",
    "    # Mid-level transforms.\n",
    "    conv_merged = concatenate([conv_q1_output, conv_q2_output])\n",
    "    conv_dense_1 = create_dense_block(conv_merged, params['num_dense_1'], params['dense_dropout_rate'])\n",
    "    conv_dense_2 = create_dense_block(conv_dense_1, params['num_dense_2'], params['dense_dropout_rate'])\n",
    "\n",
    "    td_merged = concatenate([timedist_q1_output, timedist_q2_output])\n",
    "    td_dense_1 = create_dense_block(td_merged, params['num_dense_1'], params['dense_dropout_rate'])\n",
    "    td_dense_2 = create_dense_block(td_dense_1, params['num_dense_2'], params['dense_dropout_rate'])\n",
    "\n",
    "    # Magic features.\n",
    "    magic_input = Input(shape=(X_train_magic.shape[-1], ))\n",
    "    \n",
    "    # Main dense block.\n",
    "    merged_main = concatenate([conv_dense_2, td_dense_2, magic_input])\n",
    "    dense_main_1 = create_dense_block(merged_main, params['num_dense_1'], params['dense_dropout_rate'])\n",
    "    dense_main_2 = create_dense_block(dense_main_1, params['num_dense_2'], params['dense_dropout_rate'])\n",
    "    dense_main_3 = create_dense_block(dense_main_2, params['num_dense_3'], params['dense_dropout_rate'])\n",
    "    \n",
    "    output = Dense(\n",
    "        1,\n",
    "        kernel_initializer=init_weights,\n",
    "        bias_initializer=init_bias,\n",
    "        activation='sigmoid',\n",
    "    )(dense_main_3)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_q1, input_q2, magic_input],\n",
    "        outputs=output,\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'num_conv_filters': 32,\n",
    "    'num_dense_1': 256,\n",
    "    'num_dense_2': 128,\n",
    "    'num_dense_3': 100,\n",
    "    'conv_kernel_size': 3,\n",
    "    'conv_dropout_rate': 0.25,\n",
    "    'timedist_dropout_rate': 0.25,\n",
    "    'dense_dropout_rate': 0.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X_q1, X_q2, X_magic):\n",
    "    y1 = model.predict(\n",
    "        [X_q1, X_q2, X_magic],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    y2 = model.predict(\n",
    "        [X_q2, X_q1, X_magic],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    return (y1 + y2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.3511 - acc: 0.8451Epoch 00000: val_loss improved from inf to 0.32128, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 229s - loss: 0.3511 - acc: 0.8451 - val_loss: 0.3213 - val_acc: 0.8555\n",
      "Epoch 2/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.8572Epoch 00001: val_loss improved from 0.32128 to 0.29850, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 255s - loss: 0.3171 - acc: 0.8572 - val_loss: 0.2985 - val_acc: 0.8664\n",
      "Epoch 3/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.3010 - acc: 0.8654Epoch 00002: val_loss improved from 0.29850 to 0.29053, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 260s - loss: 0.3010 - acc: 0.8654 - val_loss: 0.2905 - val_acc: 0.8712\n",
      "Epoch 4/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.8714Epoch 00003: val_loss improved from 0.29053 to 0.28527, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 260s - loss: 0.2890 - acc: 0.8714 - val_loss: 0.2853 - val_acc: 0.8735\n",
      "Epoch 5/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.8761Epoch 00004: val_loss improved from 0.28527 to 0.28468, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 254s - loss: 0.2790 - acc: 0.8761 - val_loss: 0.2847 - val_acc: 0.8762\n",
      "Epoch 6/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2719 - acc: 0.8795Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 261s - loss: 0.2719 - acc: 0.8795 - val_loss: 0.3005 - val_acc: 0.8713\n",
      "Epoch 7/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.8826Epoch 00006: val_loss improved from 0.28468 to 0.28168, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 250s - loss: 0.2653 - acc: 0.8826 - val_loss: 0.2817 - val_acc: 0.8761\n",
      "Epoch 8/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.8853Epoch 00007: val_loss improved from 0.28168 to 0.27584, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 260s - loss: 0.2596 - acc: 0.8853 - val_loss: 0.2758 - val_acc: 0.8794\n",
      "Epoch 9/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2538 - acc: 0.8877Epoch 00008: val_loss did not improve\n",
      "646862/646862 [==============================] - 232s - loss: 0.2538 - acc: 0.8877 - val_loss: 0.2768 - val_acc: 0.8801\n",
      "Epoch 10/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2495 - acc: 0.8905Epoch 00009: val_loss did not improve\n",
      "646862/646862 [==============================] - 172s - loss: 0.2495 - acc: 0.8905 - val_loss: 0.2769 - val_acc: 0.8804\n",
      "Epoch 11/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.8922Epoch 00010: val_loss improved from 0.27584 to 0.26649, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 178s - loss: 0.2460 - acc: 0.8922 - val_loss: 0.2665 - val_acc: 0.8830\n",
      "Epoch 12/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.8942Epoch 00011: val_loss did not improve\n",
      "646862/646862 [==============================] - 179s - loss: 0.2408 - acc: 0.8943 - val_loss: 0.2825 - val_acc: 0.8790\n",
      "Epoch 13/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.8955Epoch 00012: val_loss did not improve\n",
      "646862/646862 [==============================] - 179s - loss: 0.2381 - acc: 0.8955 - val_loss: 0.2812 - val_acc: 0.8830\n",
      "Epoch 14/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.8974Epoch 00013: val_loss did not improve\n",
      "646862/646862 [==============================] - 179s - loss: 0.2352 - acc: 0.8974 - val_loss: 0.2789 - val_acc: 0.8790\n",
      "Epoch 15/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2312 - acc: 0.8993Epoch 00014: val_loss did not improve\n",
      "646862/646862 [==============================] - 178s - loss: 0.2312 - acc: 0.8993 - val_loss: 0.2719 - val_acc: 0.8834\n",
      "Epoch 00014: early stopping\n",
      "80859/80859 [==============================] - 1s     \n",
      "2345796/2345796 [==============================] - 37s    \n",
      "2344960/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.3503 - acc: 0.8454Epoch 00000: val_loss improved from inf to 0.31980, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 180s - loss: 0.3503 - acc: 0.8454 - val_loss: 0.3198 - val_acc: 0.8576\n",
      "Epoch 2/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.8587Epoch 00001: val_loss improved from 0.31980 to 0.30184, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 179s - loss: 0.3154 - acc: 0.8587 - val_loss: 0.3018 - val_acc: 0.8644\n",
      "Epoch 3/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2982 - acc: 0.8653Epoch 00002: val_loss improved from 0.30184 to 0.29901, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 179s - loss: 0.2982 - acc: 0.8653 - val_loss: 0.2990 - val_acc: 0.8663\n",
      "Epoch 4/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2868 - acc: 0.8721Epoch 00003: val_loss improved from 0.29901 to 0.28362, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 179s - loss: 0.2868 - acc: 0.8721 - val_loss: 0.2836 - val_acc: 0.8746\n",
      "Epoch 5/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2775 - acc: 0.8766Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 179s - loss: 0.2775 - acc: 0.8766 - val_loss: 0.2943 - val_acc: 0.8734\n",
      "Epoch 6/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.8801Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 178s - loss: 0.2699 - acc: 0.8801 - val_loss: 0.2880 - val_acc: 0.8742\n",
      "Epoch 7/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.8838Epoch 00006: val_loss improved from 0.28362 to 0.28147, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 179s - loss: 0.2628 - acc: 0.8838 - val_loss: 0.2815 - val_acc: 0.8763\n",
      "Epoch 8/200\n",
      "646720/646862 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.8863Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 178s - loss: 0.2577 - acc: 0.8863 - val_loss: 0.2837 - val_acc: 0.8745\n",
      "Epoch 9/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2525 - acc: 0.8886Epoch 00008: val_loss improved from 0.28147 to 0.27784, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646862/646862 [==============================] - 179s - loss: 0.2525 - acc: 0.8886 - val_loss: 0.2778 - val_acc: 0.8779\n",
      "Epoch 10/200\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.8910Epoch 00009: val_loss did not improve\n",
      "646862/646862 [==============================] - 179s - loss: 0.2478 - acc: 0.8910 - val_loss: 0.2951 - val_acc: 0.8728\n",
      "Epoch 11/200\n",
      "646784/646862 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.8928Epoch 00010: val_loss did not improve\n",
      "646862/646862 [==============================] - 179s - loss: 0.2439 - acc: 0.8928 - val_loss: 0.2936 - val_acc: 0.8731\n",
      "Epoch 12/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.8949Epoch 00011: val_loss did not improve\n",
      "646862/646862 [==============================] - 179s - loss: 0.2399 - acc: 0.8949 - val_loss: 0.2882 - val_acc: 0.8775\n",
      "Epoch 13/200\n",
      "646848/646862 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.8965Epoch 00012: val_loss improved from 0.27784 to 0.27761, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646862/646862 [==============================] - 179s - loss: 0.2361 - acc: 0.8965 - val_loss: 0.2776 - val_acc: 0.8791\n",
      "Epoch 00012: early stopping\n",
      "2343936/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 646864 samples, validate on 161716 samples\n",
      "Epoch 1/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.8450Epoch 00000: val_loss improved from inf to 0.31776, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 179s - loss: 0.3506 - acc: 0.8450 - val_loss: 0.3178 - val_acc: 0.8570\n",
      "Epoch 2/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.8585Epoch 00001: val_loss improved from 0.31776 to 0.30055, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 179s - loss: 0.3158 - acc: 0.8585 - val_loss: 0.3006 - val_acc: 0.8640\n",
      "Epoch 3/200\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.8659Epoch 00002: val_loss improved from 0.30055 to 0.29081, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 178s - loss: 0.2992 - acc: 0.8659 - val_loss: 0.2908 - val_acc: 0.8710\n",
      "Epoch 4/200\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.2868 - acc: 0.8721Epoch 00003: val_loss improved from 0.29081 to 0.29060, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 178s - loss: 0.2868 - acc: 0.8722 - val_loss: 0.2906 - val_acc: 0.8717\n",
      "Epoch 5/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.2778 - acc: 0.8763Epoch 00004: val_loss improved from 0.29060 to 0.27872, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 176s - loss: 0.2778 - acc: 0.8763 - val_loss: 0.2787 - val_acc: 0.8758\n",
      "Epoch 6/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.8801Epoch 00005: val_loss improved from 0.27872 to 0.27700, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 176s - loss: 0.2702 - acc: 0.8801 - val_loss: 0.2770 - val_acc: 0.8768\n",
      "Epoch 7/200\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.2634 - acc: 0.8836Epoch 00006: val_loss did not improve\n",
      "646864/646864 [==============================] - 176s - loss: 0.2634 - acc: 0.8836 - val_loss: 0.2854 - val_acc: 0.8748\n",
      "Epoch 8/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.8862Epoch 00007: val_loss improved from 0.27700 to 0.27475, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 176s - loss: 0.2581 - acc: 0.8862 - val_loss: 0.2748 - val_acc: 0.8790\n",
      "Epoch 9/200\n",
      "646784/646864 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.8885Epoch 00008: val_loss improved from 0.27475 to 0.27429, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 175s - loss: 0.2529 - acc: 0.8885 - val_loss: 0.2743 - val_acc: 0.8797\n",
      "Epoch 10/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.2483 - acc: 0.8909Epoch 00009: val_loss improved from 0.27429 to 0.27159, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 175s - loss: 0.2483 - acc: 0.8909 - val_loss: 0.2716 - val_acc: 0.8804\n",
      "Epoch 11/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.8925Epoch 00010: val_loss improved from 0.27159 to 0.27004, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646864/646864 [==============================] - 175s - loss: 0.2443 - acc: 0.8925 - val_loss: 0.2700 - val_acc: 0.8821\n",
      "Epoch 12/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.8947Epoch 00011: val_loss did not improve\n",
      "646864/646864 [==============================] - 175s - loss: 0.2401 - acc: 0.8947 - val_loss: 0.2861 - val_acc: 0.8766\n",
      "Epoch 13/200\n",
      "646848/646864 [============================>.] - ETA: 0s - loss: 0.2370 - acc: 0.8963Epoch 00012: val_loss did not improve\n",
      "646864/646864 [==============================] - 175s - loss: 0.2370 - acc: 0.8963 - val_loss: 0.2785 - val_acc: 0.8789\n",
      "Epoch 14/200\n",
      "646720/646864 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.8984Epoch 00013: val_loss did not improve\n",
      "646864/646864 [==============================] - 175s - loss: 0.2331 - acc: 0.8984 - val_loss: 0.2824 - val_acc: 0.8790\n",
      "Epoch 15/200\n",
      "646784/646864 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.8995Epoch 00014: val_loss did not improve\n",
      "646864/646864 [==============================] - 175s - loss: 0.2299 - acc: 0.8996 - val_loss: 0.2778 - val_acc: 0.8818\n",
      "Epoch 00014: early stopping\n",
      "80858/80858 [==============================] - 1s     \n",
      "2345796/2345796 [==============================] - 38s    \n",
      "\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.8456Epoch 00000: val_loss improved from inf to 0.31943, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 177s - loss: 0.3509 - acc: 0.8456 - val_loss: 0.3194 - val_acc: 0.8572\n",
      "Epoch 2/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.8581Epoch 00001: val_loss improved from 0.31943 to 0.29859, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 176s - loss: 0.3161 - acc: 0.8581 - val_loss: 0.2986 - val_acc: 0.8649\n",
      "Epoch 3/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.2997 - acc: 0.8659Epoch 00002: val_loss improved from 0.29859 to 0.28791, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 176s - loss: 0.2997 - acc: 0.8659 - val_loss: 0.2879 - val_acc: 0.8711\n",
      "Epoch 4/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.8717Epoch 00003: val_loss improved from 0.28791 to 0.28347, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646866/646866 [==============================] - 176s - loss: 0.2881 - acc: 0.8717 - val_loss: 0.2835 - val_acc: 0.8727\n",
      "Epoch 5/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.8758Epoch 00004: val_loss improved from 0.28347 to 0.27861, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 176s - loss: 0.2791 - acc: 0.8758 - val_loss: 0.2786 - val_acc: 0.8753\n",
      "Epoch 6/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.8791Epoch 00005: val_loss improved from 0.27861 to 0.27100, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 176s - loss: 0.2718 - acc: 0.8791 - val_loss: 0.2710 - val_acc: 0.8800\n",
      "Epoch 7/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.8826Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2650 - acc: 0.8826 - val_loss: 0.2746 - val_acc: 0.8781\n",
      "Epoch 8/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.8854Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 175s - loss: 0.2597 - acc: 0.8854 - val_loss: 0.2743 - val_acc: 0.8782\n",
      "Epoch 9/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.8880Epoch 00008: val_loss did not improve\n",
      "646866/646866 [==============================] - 167s - loss: 0.2539 - acc: 0.8880 - val_loss: 0.2753 - val_acc: 0.8800\n",
      "Epoch 10/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.8903Epoch 00009: val_loss did not improve\n",
      "646866/646866 [==============================] - 173s - loss: 0.2492 - acc: 0.8903 - val_loss: 0.2767 - val_acc: 0.8811\n",
      "Epoch 00009: early stopping\n",
      "80857/80857 [==============================] - 1s     \n",
      "2345796/2345796 [==============================] - 37s    \n",
      "2343936/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.3511 - acc: 0.8450Epoch 00000: val_loss improved from inf to 0.31564, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 179s - loss: 0.3511 - acc: 0.8450 - val_loss: 0.3156 - val_acc: 0.8569\n",
      "Epoch 2/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.8572Epoch 00001: val_loss improved from 0.31564 to 0.30065, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 177s - loss: 0.3168 - acc: 0.8572 - val_loss: 0.3006 - val_acc: 0.8643\n",
      "Epoch 3/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2993 - acc: 0.8660Epoch 00002: val_loss improved from 0.30065 to 0.29000, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 177s - loss: 0.2994 - acc: 0.8660 - val_loss: 0.2900 - val_acc: 0.8706\n",
      "Epoch 4/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.8716Epoch 00003: val_loss improved from 0.29000 to 0.28439, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 177s - loss: 0.2878 - acc: 0.8716 - val_loss: 0.2844 - val_acc: 0.8735\n",
      "Epoch 5/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2787 - acc: 0.8758Epoch 00004: val_loss improved from 0.28439 to 0.28400, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 177s - loss: 0.2787 - acc: 0.8758 - val_loss: 0.2840 - val_acc: 0.8739\n",
      "Epoch 6/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.8800Epoch 00005: val_loss improved from 0.28400 to 0.27798, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 177s - loss: 0.2707 - acc: 0.8800 - val_loss: 0.2780 - val_acc: 0.8771\n",
      "Epoch 7/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.2644 - acc: 0.8833Epoch 00006: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2644 - acc: 0.8833 - val_loss: 0.2784 - val_acc: 0.8787\n",
      "Epoch 8/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.2590 - acc: 0.8855Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2590 - acc: 0.8855 - val_loss: 0.2880 - val_acc: 0.8757\n",
      "Epoch 9/200\n",
      "646848/646866 [============================>.] - ETA: 0s - loss: 0.2537 - acc: 0.8880Epoch 00008: val_loss improved from 0.27798 to 0.27482, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 176s - loss: 0.2537 - acc: 0.8880 - val_loss: 0.2748 - val_acc: 0.8800\n",
      "Epoch 10/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2491 - acc: 0.8905Epoch 00009: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2491 - acc: 0.8905 - val_loss: 0.2868 - val_acc: 0.8773\n",
      "Epoch 11/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.8927Epoch 00010: val_loss improved from 0.27482 to 0.27206, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn_magic.h5\n",
      "646866/646866 [==============================] - 176s - loss: 0.2450 - acc: 0.8927 - val_loss: 0.2721 - val_acc: 0.8798\n",
      "Epoch 12/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2407 - acc: 0.8944Epoch 00011: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2407 - acc: 0.8944 - val_loss: 0.2721 - val_acc: 0.8805\n",
      "Epoch 13/200\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.8961Epoch 00012: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2368 - acc: 0.8961 - val_loss: 0.2848 - val_acc: 0.8784\n",
      "Epoch 14/200\n",
      "646720/646866 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.8980Epoch 00013: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2331 - acc: 0.8980 - val_loss: 0.2901 - val_acc: 0.8774\n",
      "Epoch 15/200\n",
      "646784/646866 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.8996Epoch 00014: val_loss did not improve\n",
      "646866/646866 [==============================] - 176s - loss: 0.2303 - acc: 0.8996 - val_loss: 0.2828 - val_acc: 0.8795\n",
      "Epoch 00014: early stopping\n",
      "2343936/2345796 [============================>.] - ETA: 0sCPU times: user 4h 38min 21s, sys: 14min 34s, total: 4h 52min 55s\n",
      "Wall time: 3h 38min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "    X_fold_train_magic = np.vstack([X_train_magic[ix_train], X_train_magic[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "    X_fold_val_magic = np.vstack([X_train_magic[ix_val], X_train_magic[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model(model_params)\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2, X_fold_train_magic], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2, X_fold_val_magic], y_fold_val),\n",
    "\n",
    "        batch_size=64,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "        \n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_train_oofp[ix_val] = predict(model, X_train_q1[ix_val], X_train_q2[ix_val], X_train_magic[ix_val])\n",
    "    y_test_oofp[:, fold_num] = predict(model, X_test_q1, X_test_q2, X_test_magic)\n",
    "    \n",
    "    # Clear GPU memory.\n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_train_magic\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del X_fold_val_magic\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.266362794559\n"
     ]
    }
   ],
   "source": [
    "cv_score = log_loss(y_train, y_train_oofp)\n",
    "print('CV score:', cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_currie32_cnn_magic',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp_mean = np.mean(y_test_oofp, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp_mean, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
