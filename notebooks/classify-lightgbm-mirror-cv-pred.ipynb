{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_lists = [\n",
    "    'simple_summaries',\n",
    "    'jaccard_ngrams',\n",
    "    'fuzzy',\n",
    "    'jellyfish',\n",
    "    'tfidf_distances',\n",
    "    'embedding_mean',\n",
    "    'embedding_normalized_sum',\n",
    "    'wmd',\n",
    "    'wordnet_similarity',\n",
    "    'dasolmar_whq',\n",
    "    'magic_jturkewitz',\n",
    "    'magic_stas_svd_150',\n",
    "    'magic_stas_avito',\n",
    "#     'magic_kcore',\n",
    "#     'magic_tour1st',\n",
    "#     'magic_qid',\n",
    "    'oofp_manual_lightgbm',\n",
    "    'oofp_bradleypallen_mlp',\n",
    "    'oofp_currie32_cnn',\n",
    "    'oofp_lystdo_bi_lstm',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test, _ = load_feature_lists(feature_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.values\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models & compute test predictions from each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mirror_dataset(X_orig):\n",
    "    X = X_orig.copy(deep=True)\n",
    "    pairs_to_flip = [\n",
    "        ['jaccard_ix_norm_q1_2gram', 'jaccard_ix_norm_q2_2gram'],\n",
    "        ['jaccard_ix_norm_q1_3gram', 'jaccard_ix_norm_q2_3gram'],\n",
    "        ['jaccard_ix_norm_q1_4gram', 'jaccard_ix_norm_q2_4gram'],\n",
    "        ['jaccard_ix_norm_q1_5gram', 'jaccard_ix_norm_q2_5gram'],\n",
    "        ['das_stops1_ratio', 'das_stops2_ratio'],\n",
    "        ['das_len_q1', 'das_len_q2'],\n",
    "        ['das_caps_count_q1', 'das_caps_count_q2'],\n",
    "        ['das_len_char_q1', 'das_len_char_q2'],\n",
    "        ['das_len_word_q1', 'das_len_word_q2'],\n",
    "        ['das_avg_word_len1', 'das_avg_word_len2'],\n",
    "        ['das_q1_how', 'das_q2_how'],\n",
    "        ['das_q1_what', 'das_q2_what'],\n",
    "        ['das_q1_which', 'das_q2_which'],\n",
    "        ['das_q1_who', 'das_q2_who'],\n",
    "        ['das_q1_where', 'das_q2_where'],\n",
    "        ['das_q1_when', 'das_q2_when'],\n",
    "        ['das_q1_why', 'das_q2_why'],\n",
    "        ['whq_count_q1', 'whq_count_q2'],\n",
    "        ['magic_jt_q1_freq', 'magic_jt_q2_freq'],\n",
    "    ]\n",
    "    \n",
    "    for pair in pairs_to_flip:\n",
    "        X[[pair[0], pair[1]]] = X[[pair[1], pair[0]]]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X_orig, X_mirror):\n",
    "    y_pred_orig = model.predict(X_orig).reshape(-1)\n",
    "    y_pred_mirror = model.predict(X_mirror).reshape(-1)\n",
    "    return (y_pred_orig + y_pred_mirror) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_mirror = mirror_dataset(df_train).values\n",
    "X_test_mirror = mirror_dataset(df_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.zeros((len(X_test), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train, y_train)):\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    \n",
    "    X_fold_train = np.vstack([X_train[ix_train], X_train_mirror[ix_train]])\n",
    "    X_fold_val = np.vstack([X_train[ix_val], X_train_mirror[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'device': 'cpu',\n",
    "        'num_leaves': 64,\n",
    "        'feature_fraction': 1.0,\n",
    "        'learning_rate': 0.03,\n",
    "#         'num_leaves': 279,\n",
    "#         'feature_fraction': 0.614,\n",
    "#         'lambda_l2': 9.45,\n",
    "#         'learning_rate': 0.01,\n",
    "        'num_boost_round': 1000,\n",
    "        'early_stopping_rounds': 5,\n",
    "        'verbose': 1,\n",
    "        'bagging_fraction_seed': RANDOM_SEED,\n",
    "        'feature_fraction_seed': RANDOM_SEED,\n",
    "    }\n",
    "    \n",
    "    lgb_data_train = lgb.Dataset(X_fold_train, y_fold_train)\n",
    "    lgb_data_val = lgb.Dataset(X_fold_val, y_fold_val)    \n",
    "    evals_result = {}\n",
    "    \n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        lgb_data_train,\n",
    "        valid_sets=[lgb_data_train, lgb_data_val],\n",
    "        evals_result=evals_result,\n",
    "        num_boost_round=lgb_params['num_boost_round'],\n",
    "        early_stopping_rounds=lgb_params['early_stopping_rounds'],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    \n",
    "    fold_train_scores = evals_result['training'][lgb_params['metric']]\n",
    "    fold_val_scores = evals_result['valid_1'][lgb_params['metric']]\n",
    "    \n",
    "    print('Fold {}: {} rounds, training loss {:.6f}, validation loss {:.6f}'.format(\n",
    "        fold_num + 1,\n",
    "        len(fold_train_scores),\n",
    "        fold_train_scores[-1],\n",
    "        fold_val_scores[-1],\n",
    "    ))\n",
    "    print()\n",
    "    \n",
    "    cv_scores.append(fold_val_scores[-1])\n",
    "    y_test_pred[:, fold_num] = predict(model, X_test, X_test_mirror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'column': list(df_train.columns),\n",
    "    'importance': model.feature_importance(),\n",
    "}).sort_values(by='importance').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_cv_score = np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Final CV score:', final_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np.mean(y_test_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_id = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\n",
    "    'test_id': range(len(y_test)),\n",
    "    'is_duplicate': y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalibrate predictions for a different target balance on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recalibrate_prediction(pred, train_pos_ratio=0.3692, test_pos_ratio=0.1746):\n",
    "    a = test_pos_ratio / train_pos_ratio\n",
    "    b = (1 - test_pos_ratio) / (1 - train_pos_ratio)\n",
    "    return a * pred / (a * pred + b * (1 - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission['is_duplicate'] = df_submission['is_duplicate'].map(recalibrate_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = df_submission[['test_id', 'is_duplicate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission[df_submission.is_duplicate > 0.9].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(\n",
    "    submissions_data_folder + f'{submission_id}-submission-draft-cv-{final_cv_score:.6f}.csv',\n",
    "    header=True,\n",
    "    float_format='%.8f',\n",
    "    index=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
