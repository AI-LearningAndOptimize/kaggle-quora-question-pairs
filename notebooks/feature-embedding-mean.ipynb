{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.wrappers.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, euclidean, cityblock, jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'embedding_mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_questions_train = pd.read_csv(data_folder + 'train.csv').fillna('')\n",
    "df_questions_test = pd.read_csv(data_folder + 'test.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_tokens_train = load_json(preproc_data_folder + 'question_tokens_train.json')\n",
    "question_tokens_test = load_json(preproc_data_folder + 'question_tokens_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_model = FastText.load_word2vec_format(aux_data_folder + 'quora_filtered_no_stopwords.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_features(questions_tokenized, embedding_model):\n",
    "    num_pairs = len(questions_tokenized)\n",
    "    word_vector_dim = len(embedding_model['apple'])\n",
    "    num_features = 3\n",
    "    \n",
    "    X = np.zeros((num_pairs, num_features), dtype=float)\n",
    "    \n",
    "    for index, pair in progressbar(enumerate(questions_tokenized), size=num_pairs):\n",
    "        q1_vectors = [embedding_model[token] for token in pair['question1'] if token in embedding_model.vocab]\n",
    "        q2_vectors = [embedding_model[token] for token in pair['question2'] if token in embedding_model.vocab]\n",
    "\n",
    "        if len(q1_vectors) == 0:\n",
    "            q1_vectors.append(np.zeros(word_vector_dim))\n",
    "        if len(q2_vectors) == 0:\n",
    "            q2_vectors.append(np.zeros(word_vector_dim))\n",
    "        \n",
    "        q1_mean = np.mean(q1_vectors, axis=0)\n",
    "        q2_mean = np.mean(q2_vectors, axis=0)\n",
    "\n",
    "        # Cosine distance between average word vectors\n",
    "        X[index, 0] = cosine(q1_mean, q2_mean)\n",
    "\n",
    "        # Manhattan distance between average word vectors\n",
    "        X[index, 1] = np.log(cityblock(q1_mean, q2_mean) + 1)\n",
    "\n",
    "        # Euclidean distance between average word vectors\n",
    "        X[index, 2] = euclidean(q1_mean, q2_mean)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'emb_mean_cosine',\n",
    "    'emb_mean_cityblock_log',\n",
    "    'emb_mean_euclidean',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = build_features(question_tokens_train, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(X_train, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = build_features(question_tokens_test, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(X_test, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
