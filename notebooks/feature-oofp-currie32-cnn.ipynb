{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_currie32_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep\n",
    "submissions_data_folder = os.path.join(data_folder, 'submissions') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
    "init_bias = 'zeros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_question_conv_branch():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():   \n",
    "    units = 128 # Number of nodes in the Dense layers\n",
    "    dropout = 0.25 # Percentage of nodes to drop\n",
    "    nb_filter = 32 # Number of filters to use in Convolution1D\n",
    "    filter_length = 3 # Length of filter for Convolution1D\n",
    "    # Initialize weights and biases for the Dense layers\n",
    "    \n",
    "    weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
    "    bias = bias_initializer='zeros'\n",
    "\n",
    "    model1 = Sequential()\n",
    "    model1.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "\n",
    "    model1.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(dropout))\n",
    "\n",
    "    model1.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(dropout))\n",
    "\n",
    "    model1.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "    model2 = Sequential()\n",
    "    model2.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "\n",
    "    model2.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(dropout))\n",
    "\n",
    "    model2.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(dropout))\n",
    "\n",
    "    model2.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "    model3 = Sequential()\n",
    "    model3.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "    model3.add(TimeDistributed(Dense(EMBEDDING_DIM)))\n",
    "    model3.add(BatchNormalization())\n",
    "    model3.add(Activation('relu'))\n",
    "    model3.add(Dropout(dropout))\n",
    "    model3.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "\n",
    "\n",
    "    model4 = Sequential()\n",
    "    model4.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "\n",
    "    model4.add(TimeDistributed(Dense(EMBEDDING_DIM)))\n",
    "    model4.add(BatchNormalization())\n",
    "    model4.add(Activation('relu'))\n",
    "    model4.add(Dropout(dropout))\n",
    "    model4.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    modela = Sequential()\n",
    "    modela.add(Merge([model1, model2], mode='concat'))\n",
    "    modela.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modela.add(BatchNormalization())\n",
    "    modela.add(Activation('relu'))\n",
    "    modela.add(Dropout(dropout))\n",
    "\n",
    "    modela.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modela.add(BatchNormalization())\n",
    "    modela.add(Activation('relu'))\n",
    "    modela.add(Dropout(dropout))\n",
    "\n",
    "    modelb = Sequential()\n",
    "    modelb.add(Merge([model3, model4], mode='concat'))\n",
    "    modelb.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modelb.add(BatchNormalization())\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Dropout(dropout))\n",
    "\n",
    "    modelb.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modelb.add(BatchNormalization())\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([modela, modelb], mode='concat'))\n",
    "    model.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:104: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:118: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323431 samples, validate on 80859 samples\n",
      "Epoch 1/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.5063 - acc: 0.7459Epoch 00000: val_loss improved from inf to 0.45996, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 53s - loss: 0.5063 - acc: 0.7459 - val_loss: 0.4600 - val_acc: 0.7719\n",
      "Epoch 2/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4484 - acc: 0.7812Epoch 00001: val_loss improved from 0.45996 to 0.42863, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.4484 - acc: 0.7812 - val_loss: 0.4286 - val_acc: 0.7932\n",
      "Epoch 3/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4214 - acc: 0.7971Epoch 00002: val_loss improved from 0.42863 to 0.41312, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.4214 - acc: 0.7971 - val_loss: 0.4131 - val_acc: 0.8036\n",
      "Epoch 4/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8080Epoch 00003: val_loss improved from 0.41312 to 0.40946, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.4026 - acc: 0.8080 - val_loss: 0.4095 - val_acc: 0.8029\n",
      "Epoch 5/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3869 - acc: 0.8179Epoch 00004: val_loss improved from 0.40946 to 0.40313, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3869 - acc: 0.8179 - val_loss: 0.4031 - val_acc: 0.8067\n",
      "Epoch 6/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3731 - acc: 0.8257Epoch 00005: val_loss improved from 0.40313 to 0.39423, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3731 - acc: 0.8257 - val_loss: 0.3942 - val_acc: 0.8126\n",
      "Epoch 7/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3613 - acc: 0.8324Epoch 00006: val_loss improved from 0.39423 to 0.38509, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3612 - acc: 0.8324 - val_loss: 0.3851 - val_acc: 0.8178\n",
      "Epoch 8/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8388Epoch 00007: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3495 - acc: 0.8388 - val_loss: 0.3998 - val_acc: 0.8117\n",
      "Epoch 9/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3410 - acc: 0.8437Epoch 00008: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3410 - acc: 0.8437 - val_loss: 0.3893 - val_acc: 0.8186\n",
      "Epoch 10/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.8493Epoch 00009: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3317 - acc: 0.8493 - val_loss: 0.3857 - val_acc: 0.8185\n",
      "Epoch 11/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8539Epoch 00010: val_loss improved from 0.38509 to 0.37756, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3237 - acc: 0.8539 - val_loss: 0.3776 - val_acc: 0.8243\n",
      "Epoch 12/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.8571Epoch 00011: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3161 - acc: 0.8571 - val_loss: 0.3801 - val_acc: 0.8237\n",
      "Epoch 13/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3098 - acc: 0.8604Epoch 00012: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3098 - acc: 0.8604 - val_loss: 0.3796 - val_acc: 0.8234\n",
      "Epoch 14/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3022 - acc: 0.8648Epoch 00013: val_loss improved from 0.37756 to 0.36963, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3022 - acc: 0.8648 - val_loss: 0.3696 - val_acc: 0.8298\n",
      "Epoch 15/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.8685Epoch 00014: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.2963 - acc: 0.8685 - val_loss: 0.3827 - val_acc: 0.8238\n",
      "Epoch 16/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.2915 - acc: 0.8710Epoch 00015: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.2915 - acc: 0.8710 - val_loss: 0.3760 - val_acc: 0.8273\n",
      "Epoch 17/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.2870 - acc: 0.8735Epoch 00016: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.2870 - acc: 0.8735 - val_loss: 0.3798 - val_acc: 0.8285\n",
      "Epoch 18/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.2820 - acc: 0.8761Epoch 00017: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.2820 - acc: 0.8761 - val_loss: 0.3816 - val_acc: 0.8255\n",
      "Epoch 00017: early stopping\n",
      "80859/80859 [==============================] - 1s     \n",
      "2345796/2345796 [==============================] - 38s    \n",
      "\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 323431 samples, validate on 80859 samples\n",
      "Epoch 1/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.5057 - acc: 0.7464Epoch 00000: val_loss improved from inf to 0.47317, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 54s - loss: 0.5057 - acc: 0.7464 - val_loss: 0.4732 - val_acc: 0.7736\n",
      "Epoch 2/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4476 - acc: 0.7819Epoch 00001: val_loss improved from 0.47317 to 0.43488, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.4476 - acc: 0.7819 - val_loss: 0.4349 - val_acc: 0.7885\n",
      "Epoch 3/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4213 - acc: 0.7974Epoch 00002: val_loss improved from 0.43488 to 0.41727, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.4213 - acc: 0.7974 - val_loss: 0.4173 - val_acc: 0.8006\n",
      "Epoch 4/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4010 - acc: 0.8097Epoch 00003: val_loss improved from 0.41727 to 0.40961, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.4010 - acc: 0.8097 - val_loss: 0.4096 - val_acc: 0.8049\n",
      "Epoch 5/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3858 - acc: 0.8183Epoch 00004: val_loss improved from 0.40961 to 0.40766, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 53s - loss: 0.3858 - acc: 0.8183 - val_loss: 0.4077 - val_acc: 0.8084\n",
      "Epoch 6/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3725 - acc: 0.8260Epoch 00005: val_loss improved from 0.40766 to 0.39526, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323431/323431 [==============================] - 52s - loss: 0.3725 - acc: 0.8260 - val_loss: 0.3953 - val_acc: 0.8124\n",
      "Epoch 7/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.8327Epoch 00006: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3603 - acc: 0.8327 - val_loss: 0.3972 - val_acc: 0.8111\n",
      "Epoch 8/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3504 - acc: 0.8397Epoch 00007: val_loss improved from 0.39526 to 0.39232, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3504 - acc: 0.8397 - val_loss: 0.3923 - val_acc: 0.8169\n",
      "Epoch 9/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3402 - acc: 0.8447Epoch 00008: val_loss improved from 0.39232 to 0.38940, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3401 - acc: 0.8447 - val_loss: 0.3894 - val_acc: 0.8170\n",
      "Epoch 10/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8499Epoch 00009: val_loss improved from 0.38940 to 0.38075, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 52s - loss: 0.3314 - acc: 0.8499 - val_loss: 0.3807 - val_acc: 0.8231\n",
      "Epoch 11/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3238 - acc: 0.8540Epoch 00010: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3238 - acc: 0.8539 - val_loss: 0.3815 - val_acc: 0.8221\n",
      "Epoch 12/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.8583Epoch 00011: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3161 - acc: 0.8583 - val_loss: 0.3815 - val_acc: 0.8223\n",
      "Epoch 13/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.8613Epoch 00012: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3102 - acc: 0.8613 - val_loss: 0.3858 - val_acc: 0.8234\n",
      "Epoch 14/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.8643Epoch 00013: val_loss did not improve\n",
      "323431/323431 [==============================] - 52s - loss: 0.3033 - acc: 0.8642 - val_loss: 0.3938 - val_acc: 0.8196\n",
      "Epoch 00013: early stopping\n",
      "80859/80859 [==============================] - 1s     \n",
      "2342912/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 323432 samples, validate on 80858 samples\n",
      "Epoch 1/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.7447Epoch 00000: val_loss improved from inf to 0.47806, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 51s - loss: 0.5077 - acc: 0.7447 - val_loss: 0.4781 - val_acc: 0.7659\n",
      "Epoch 2/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.7808Epoch 00001: val_loss improved from 0.47806 to 0.43038, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 49s - loss: 0.4488 - acc: 0.7808 - val_loss: 0.4304 - val_acc: 0.7911\n",
      "Epoch 3/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.7970Epoch 00002: val_loss improved from 0.43038 to 0.42476, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 50s - loss: 0.4212 - acc: 0.7970 - val_loss: 0.4248 - val_acc: 0.7960\n",
      "Epoch 4/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8084Epoch 00003: val_loss improved from 0.42476 to 0.40208, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 49s - loss: 0.4028 - acc: 0.8084 - val_loss: 0.4021 - val_acc: 0.8082\n",
      "Epoch 5/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8182Epoch 00004: val_loss improved from 0.40208 to 0.40120, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 49s - loss: 0.3853 - acc: 0.8183 - val_loss: 0.4012 - val_acc: 0.8055\n",
      "Epoch 6/35\n",
      "323200/323432 [============================>.] - ETA: 0s - loss: 0.3727 - acc: 0.8261Epoch 00005: val_loss improved from 0.40120 to 0.39433, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 49s - loss: 0.3727 - acc: 0.8261 - val_loss: 0.3943 - val_acc: 0.8122\n",
      "Epoch 7/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3591 - acc: 0.8336Epoch 00006: val_loss did not improve\n",
      "323432/323432 [==============================] - 49s - loss: 0.3591 - acc: 0.8336 - val_loss: 0.3985 - val_acc: 0.8098\n",
      "Epoch 8/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3483 - acc: 0.8394Epoch 00007: val_loss did not improve\n",
      "323432/323432 [==============================] - 49s - loss: 0.3483 - acc: 0.8394 - val_loss: 0.3943 - val_acc: 0.8152\n",
      "Epoch 9/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8451Epoch 00008: val_loss improved from 0.39433 to 0.38380, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 49s - loss: 0.3385 - acc: 0.8451 - val_loss: 0.3838 - val_acc: 0.8176\n",
      "Epoch 10/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.8504Epoch 00009: val_loss did not improve\n",
      "323432/323432 [==============================] - 49s - loss: 0.3288 - acc: 0.8504 - val_loss: 0.3858 - val_acc: 0.8200\n",
      "Epoch 11/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.8548Epoch 00010: val_loss did not improve\n",
      "323432/323432 [==============================] - 49s - loss: 0.3210 - acc: 0.8548 - val_loss: 0.3852 - val_acc: 0.8190\n",
      "Epoch 12/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.8587Epoch 00011: val_loss did not improve\n",
      "323432/323432 [==============================] - 49s - loss: 0.3140 - acc: 0.8587 - val_loss: 0.3861 - val_acc: 0.8195\n",
      "Epoch 13/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.8628Epoch 00012: val_loss did not improve\n",
      "323432/323432 [==============================] - 50s - loss: 0.3061 - acc: 0.8628 - val_loss: 0.3945 - val_acc: 0.8170\n",
      "Epoch 00012: early stopping\n",
      "80858/80858 [==============================] - 1s     \n",
      "2342912/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 323433 samples, validate on 80857 samples\n",
      "Epoch 1/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.7438Epoch 00000: val_loss improved from inf to 0.46984, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 53s - loss: 0.5068 - acc: 0.7438 - val_loss: 0.4698 - val_acc: 0.7700\n",
      "Epoch 2/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.7793Epoch 00001: val_loss improved from 0.46984 to 0.43274, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.4503 - acc: 0.7793 - val_loss: 0.4327 - val_acc: 0.7903\n",
      "Epoch 3/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4230 - acc: 0.7964Epoch 00002: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.4230 - acc: 0.7963 - val_loss: 0.4374 - val_acc: 0.7873\n",
      "Epoch 4/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4044 - acc: 0.8076Epoch 00003: val_loss improved from 0.43274 to 0.40525, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.4044 - acc: 0.8076 - val_loss: 0.4052 - val_acc: 0.8051\n",
      "Epoch 5/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.3873 - acc: 0.8178Epoch 00004: val_loss improved from 0.40525 to 0.40330, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3873 - acc: 0.8178 - val_loss: 0.4033 - val_acc: 0.8095\n",
      "Epoch 6/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.8250Epoch 00005: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3738 - acc: 0.8250 - val_loss: 0.4068 - val_acc: 0.8017\n",
      "Epoch 7/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.3607 - acc: 0.8324Epoch 00006: val_loss improved from 0.40330 to 0.38903, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3607 - acc: 0.8324 - val_loss: 0.3890 - val_acc: 0.8175\n",
      "Epoch 8/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.3507 - acc: 0.8382Epoch 00007: val_loss improved from 0.38903 to 0.38141, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3508 - acc: 0.8382 - val_loss: 0.3814 - val_acc: 0.8222\n",
      "Epoch 9/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3399 - acc: 0.8444Epoch 00008: val_loss improved from 0.38141 to 0.37917, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3399 - acc: 0.8444 - val_loss: 0.3792 - val_acc: 0.8223\n",
      "Epoch 10/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3322 - acc: 0.8490Epoch 00009: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3322 - acc: 0.8489 - val_loss: 0.3824 - val_acc: 0.8207\n",
      "Epoch 11/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.3238 - acc: 0.8533Epoch 00010: val_loss improved from 0.37917 to 0.37643, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3239 - acc: 0.8533 - val_loss: 0.3764 - val_acc: 0.8232\n",
      "Epoch 12/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.8573Epoch 00011: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3162 - acc: 0.8573 - val_loss: 0.3832 - val_acc: 0.8212\n",
      "Epoch 13/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.8602Epoch 00012: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3102 - acc: 0.8602 - val_loss: 0.3772 - val_acc: 0.8262\n",
      "Epoch 14/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.8640Epoch 00013: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3039 - acc: 0.8640 - val_loss: 0.3856 - val_acc: 0.8235\n",
      "Epoch 15/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.8677Epoch 00014: val_loss did not improve\n",
      "323433/323433 [==============================] - 53s - loss: 0.2968 - acc: 0.8677 - val_loss: 0.3867 - val_acc: 0.8250\n",
      "Epoch 00014: early stopping\n",
      "80857/80857 [==============================] - 1s     \n",
      "2344960/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 323433 samples, validate on 80857 samples\n",
      "Epoch 1/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.5062 - acc: 0.7465Epoch 00000: val_loss improved from inf to 0.45364, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 54s - loss: 0.5062 - acc: 0.7465 - val_loss: 0.4536 - val_acc: 0.7807\n",
      "Epoch 2/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.7812Epoch 00001: val_loss improved from 0.45364 to 0.43260, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.4494 - acc: 0.7812 - val_loss: 0.4326 - val_acc: 0.7921\n",
      "Epoch 3/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4239 - acc: 0.7961Epoch 00002: val_loss improved from 0.43260 to 0.41315, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.4239 - acc: 0.7961 - val_loss: 0.4131 - val_acc: 0.8021\n",
      "Epoch 4/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4042 - acc: 0.8072Epoch 00003: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.4042 - acc: 0.8072 - val_loss: 0.4137 - val_acc: 0.8031\n",
      "Epoch 5/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8172Epoch 00004: val_loss improved from 0.41315 to 0.40508, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3876 - acc: 0.8172 - val_loss: 0.4051 - val_acc: 0.8106\n",
      "Epoch 6/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.3737 - acc: 0.8260Epoch 00005: val_loss improved from 0.40508 to 0.39211, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3737 - acc: 0.8260 - val_loss: 0.3921 - val_acc: 0.8152\n",
      "Epoch 7/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8327Epoch 00006: val_loss improved from 0.39211 to 0.38613, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3612 - acc: 0.8327 - val_loss: 0.3861 - val_acc: 0.8201\n",
      "Epoch 8/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.8380Epoch 00007: val_loss improved from 0.38613 to 0.37795, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 52s - loss: 0.3513 - acc: 0.8380 - val_loss: 0.3780 - val_acc: 0.8229\n",
      "Epoch 9/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3410 - acc: 0.8445Epoch 00008: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3410 - acc: 0.8445 - val_loss: 0.3936 - val_acc: 0.8163\n",
      "Epoch 10/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3324 - acc: 0.8486Epoch 00009: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3325 - acc: 0.8486 - val_loss: 0.3790 - val_acc: 0.8214\n",
      "Epoch 11/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.3241 - acc: 0.8533Epoch 00010: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3241 - acc: 0.8533 - val_loss: 0.3866 - val_acc: 0.8210\n",
      "Epoch 12/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.8579Epoch 00011: val_loss did not improve\n",
      "323433/323433 [==============================] - 52s - loss: 0.3171 - acc: 0.8579 - val_loss: 0.3812 - val_acc: 0.8213\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2342912/2345796 [============================>.] - ETA: 0sCPU times: user 1h 23min 23s, sys: 5min 4s, total: 1h 28min 28s\n",
      "Wall time: 1h 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = X_train_q1[ix_train]\n",
    "    X_fold_train_q2 = X_train_q2[ix_train]\n",
    "\n",
    "    X_fold_val_q1 = X_train_q1[ix_val]\n",
    "    X_fold_val_q2 = X_train_q2[ix_val]\n",
    "\n",
    "    y_fold_train = y_train[ix_train]\n",
    "    y_fold_val = y_train[ix_val]\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2, X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2, X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "#         class_weight=keras_get_class_weights(y_fold_val),\n",
    "\n",
    "        batch_size=128,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_pred_oofp = model.predict(\n",
    "        [X_train_q1[ix_val], X_train_q2[ix_val], X_train_q1[ix_val], X_train_q2[ix_val]],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    y_test_oofp[:, fold_num] = model.predict(\n",
    "        [X_test_q1, X_test_q2, X_test_q1, X_test_q2],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    # Remember them.\n",
    "    y_train_oofp[ix_val] = y_pred_oofp\n",
    "    \n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_currie32_cnn',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp_mean = np.mean(y_test_oofp, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp_mean, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
