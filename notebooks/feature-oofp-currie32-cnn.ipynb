{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_currie32_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.abspath(os.path.join(os.curdir, os.pardir, 'data')) + os.path.sep\n",
    "aux_data_folder = os.path.join(data_folder, 'aux') + os.path.sep\n",
    "preproc_data_folder = os.path.join(data_folder, 'preproc') + os.path.sep\n",
    "features_data_folder = os.path.join(data_folder, 'features') + os.path.sep\n",
    "submissions_data_folder = os.path.join(data_folder, 'submissions') + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():   \n",
    "    units = 128 # Number of nodes in the Dense layers\n",
    "    dropout = 0.25 # Percentage of nodes to drop\n",
    "    nb_filter = 32 # Number of filters to use in Convolution1D\n",
    "    filter_length = 3 # Length of filter for Convolution1D\n",
    "    # Initialize weights and biases for the Dense layers\n",
    "    \n",
    "    weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
    "    bias = bias_initializer='zeros'\n",
    "\n",
    "    model1 = Sequential()\n",
    "    model1.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "\n",
    "    model1.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(dropout))\n",
    "\n",
    "    model1.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(dropout))\n",
    "\n",
    "    model1.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "    model2 = Sequential()\n",
    "    model2.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "\n",
    "    model2.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(dropout))\n",
    "\n",
    "    model2.add(Convolution1D(filters = nb_filter, \n",
    "                             kernel_size = filter_length, \n",
    "                             padding = 'same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(dropout))\n",
    "\n",
    "    model2.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "    model3 = Sequential()\n",
    "    model3.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "    model3.add(TimeDistributed(Dense(EMBEDDING_DIM)))\n",
    "    model3.add(BatchNormalization())\n",
    "    model3.add(Activation('relu'))\n",
    "    model3.add(Dropout(dropout))\n",
    "    model3.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "\n",
    "\n",
    "    model4 = Sequential()\n",
    "    model4.add(Embedding(VOCAB_LENGTH,\n",
    "                         EMBEDDING_DIM,\n",
    "                         weights=[embedding_matrix],\n",
    "                         input_length = MAX_SEQUENCE_LENGTH,\n",
    "                         trainable = False))\n",
    "\n",
    "    model4.add(TimeDistributed(Dense(EMBEDDING_DIM)))\n",
    "    model4.add(BatchNormalization())\n",
    "    model4.add(Activation('relu'))\n",
    "    model4.add(Dropout(dropout))\n",
    "    model4.add(Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, )))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    modela = Sequential()\n",
    "    modela.add(Merge([model1, model2], mode='concat'))\n",
    "    modela.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modela.add(BatchNormalization())\n",
    "    modela.add(Activation('relu'))\n",
    "    modela.add(Dropout(dropout))\n",
    "\n",
    "    modela.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modela.add(BatchNormalization())\n",
    "    modela.add(Activation('relu'))\n",
    "    modela.add(Dropout(dropout))\n",
    "\n",
    "    modelb = Sequential()\n",
    "    modelb.add(Merge([model3, model4], mode='concat'))\n",
    "    modelb.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modelb.add(BatchNormalization())\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Dropout(dropout))\n",
    "\n",
    "    modelb.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    modelb.add(BatchNormalization())\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([modela, modelb], mode='concat'))\n",
    "    model.add(Dense(units*2, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer=weights, bias_initializer=bias))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = np.zeros((len(X_test_q1), NUM_FOLDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:104: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/yuriyguts/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:118: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323431 samples, validate on 80859 samples\n",
      "Epoch 1/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.6625 - acc: 0.7276Epoch 00000: val_loss improved from inf to 0.46178, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 48s - loss: 0.6624 - acc: 0.7276 - val_loss: 0.4618 - val_acc: 0.7736\n",
      "Epoch 2/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.5892 - acc: 0.7672Epoch 00001: val_loss improved from 0.46178 to 0.44320, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 43s - loss: 0.5892 - acc: 0.7672 - val_loss: 0.4432 - val_acc: 0.7827\n",
      "Epoch 3/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.5549 - acc: 0.7830Epoch 00002: val_loss improved from 0.44320 to 0.43608, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 43s - loss: 0.5549 - acc: 0.7830 - val_loss: 0.4361 - val_acc: 0.7835\n",
      "Epoch 4/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.5294 - acc: 0.7947Epoch 00003: val_loss improved from 0.43608 to 0.41793, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 44s - loss: 0.5294 - acc: 0.7946 - val_loss: 0.4179 - val_acc: 0.7936\n",
      "Epoch 5/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.8044Epoch 00004: val_loss did not improve\n",
      "323431/323431 [==============================] - 48s - loss: 0.5078 - acc: 0.8044 - val_loss: 0.4275 - val_acc: 0.7895\n",
      "Epoch 6/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.8135Epoch 00005: val_loss improved from 0.41793 to 0.40981, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 48s - loss: 0.4886 - acc: 0.8135 - val_loss: 0.4098 - val_acc: 0.8016\n",
      "Epoch 7/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8219Epoch 00006: val_loss improved from 0.40981 to 0.40221, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 48s - loss: 0.4726 - acc: 0.8219 - val_loss: 0.4022 - val_acc: 0.8042\n",
      "Epoch 8/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4593 - acc: 0.8274Epoch 00007: val_loss improved from 0.40221 to 0.39248, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 48s - loss: 0.4593 - acc: 0.8274 - val_loss: 0.3925 - val_acc: 0.8138\n",
      "Epoch 9/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.8329Epoch 00008: val_loss did not improve\n",
      "323431/323431 [==============================] - 48s - loss: 0.4454 - acc: 0.8329 - val_loss: 0.3930 - val_acc: 0.8131\n",
      "Epoch 10/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4327 - acc: 0.8382Epoch 00009: val_loss did not improve\n",
      "323431/323431 [==============================] - 48s - loss: 0.4326 - acc: 0.8382 - val_loss: 0.3975 - val_acc: 0.8110\n",
      "Epoch 11/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4220 - acc: 0.8437Epoch 00010: val_loss did not improve\n",
      "323431/323431 [==============================] - 50s - loss: 0.4220 - acc: 0.8437 - val_loss: 0.3981 - val_acc: 0.8080\n",
      "Epoch 12/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4126 - acc: 0.8480Epoch 00011: val_loss improved from 0.39248 to 0.38974, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 50s - loss: 0.4126 - acc: 0.8480 - val_loss: 0.3897 - val_acc: 0.8170\n",
      "Epoch 13/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.4037 - acc: 0.8512Epoch 00012: val_loss improved from 0.38974 to 0.38769, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 47s - loss: 0.4037 - acc: 0.8512 - val_loss: 0.3877 - val_acc: 0.8158\n",
      "Epoch 14/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3955 - acc: 0.8554Epoch 00013: val_loss did not improve\n",
      "323431/323431 [==============================] - 50s - loss: 0.3955 - acc: 0.8554 - val_loss: 0.3879 - val_acc: 0.8153\n",
      "Epoch 15/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8585Epoch 00014: val_loss did not improve\n",
      "323431/323431 [==============================] - 50s - loss: 0.3878 - acc: 0.8585 - val_loss: 0.3958 - val_acc: 0.8153\n",
      "Epoch 16/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8625Epoch 00015: val_loss did not improve\n",
      "323431/323431 [==============================] - 51s - loss: 0.3808 - acc: 0.8625 - val_loss: 0.3963 - val_acc: 0.8163\n",
      "Epoch 17/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.3745 - acc: 0.8643Epoch 00016: val_loss improved from 0.38769 to 0.38412, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 50s - loss: 0.3745 - acc: 0.8643 - val_loss: 0.3841 - val_acc: 0.8242\n",
      "Epoch 18/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8662Epoch 00017: val_loss improved from 0.38412 to 0.37992, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 50s - loss: 0.3688 - acc: 0.8662 - val_loss: 0.3799 - val_acc: 0.8269\n",
      "Epoch 19/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3646 - acc: 0.8686Epoch 00018: val_loss did not improve\n",
      "323431/323431 [==============================] - 45s - loss: 0.3646 - acc: 0.8686 - val_loss: 0.3869 - val_acc: 0.8221\n",
      "Epoch 20/35\n",
      "322944/323431 [============================>.] - ETA: 0s - loss: 0.3582 - acc: 0.8718Epoch 00019: val_loss improved from 0.37992 to 0.37889, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 44s - loss: 0.3582 - acc: 0.8718 - val_loss: 0.3789 - val_acc: 0.8243\n",
      "Epoch 21/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8735Epoch 00020: val_loss did not improve\n",
      "323431/323431 [==============================] - 45s - loss: 0.3520 - acc: 0.8735 - val_loss: 0.3859 - val_acc: 0.8247\n",
      "Epoch 22/35\n",
      "322944/323431 [============================>.] - ETA: 0s - loss: 0.3486 - acc: 0.8755Epoch 00021: val_loss did not improve\n",
      "323431/323431 [==============================] - 44s - loss: 0.3487 - acc: 0.8755 - val_loss: 0.3935 - val_acc: 0.8198\n",
      "Epoch 23/35\n",
      "322944/323431 [============================>.] - ETA: 0s - loss: 0.3423 - acc: 0.8780Epoch 00022: val_loss did not improve\n",
      "323431/323431 [==============================] - 43s - loss: 0.3422 - acc: 0.8780 - val_loss: 0.3933 - val_acc: 0.8244\n",
      "Epoch 24/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.8795Epoch 00023: val_loss did not improve\n",
      "323431/323431 [==============================] - 45s - loss: 0.3382 - acc: 0.8795 - val_loss: 0.3861 - val_acc: 0.8251\n",
      "Epoch 00023: early stopping\n",
      "80859/80859 [==============================] - 1s     \n",
      "2345796/2345796 [==============================] - 31s    \n",
      "\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 323431 samples, validate on 80859 samples\n",
      "Epoch 1/35\n",
      "322944/323431 [============================>.] - ETA: 0s - loss: 0.6622 - acc: 0.7276Epoch 00000: val_loss improved from inf to 0.48108, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323431/323431 [==============================] - 45s - loss: 0.6621 - acc: 0.7277 - val_loss: 0.4811 - val_acc: 0.7605\n",
      "Epoch 2/35\n",
      "322944/323431 [============================>.] - ETA: 0s - loss: 0.5879 - acc: 0.7666Epoch 00001: val_loss improved from 0.48108 to 0.44747, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 46s - loss: 0.5879 - acc: 0.7666 - val_loss: 0.4475 - val_acc: 0.7768\n",
      "Epoch 3/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.5535 - acc: 0.7830Epoch 00002: val_loss improved from 0.44747 to 0.42075, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 48s - loss: 0.5535 - acc: 0.7830 - val_loss: 0.4208 - val_acc: 0.7957\n",
      "Epoch 4/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7955Epoch 00003: val_loss did not improve\n",
      "323431/323431 [==============================] - 47s - loss: 0.5259 - acc: 0.7955 - val_loss: 0.4337 - val_acc: 0.7857\n",
      "Epoch 5/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.5046 - acc: 0.8062Epoch 00004: val_loss did not improve\n",
      "323431/323431 [==============================] - 47s - loss: 0.5047 - acc: 0.8062 - val_loss: 0.4397 - val_acc: 0.7774\n",
      "Epoch 6/35\n",
      "323328/323431 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8147Epoch 00005: val_loss improved from 0.42075 to 0.40043, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 48s - loss: 0.4868 - acc: 0.8147 - val_loss: 0.4004 - val_acc: 0.8077\n",
      "Epoch 7/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4704 - acc: 0.8226Epoch 00006: val_loss did not improve\n",
      "323431/323431 [==============================] - 48s - loss: 0.4704 - acc: 0.8226 - val_loss: 0.4126 - val_acc: 0.8001\n",
      "Epoch 8/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4569 - acc: 0.8283Epoch 00007: val_loss did not improve\n",
      "323431/323431 [==============================] - 49s - loss: 0.4569 - acc: 0.8283 - val_loss: 0.4163 - val_acc: 0.7944\n",
      "Epoch 9/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8337Epoch 00008: val_loss improved from 0.40043 to 0.40032, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 47s - loss: 0.4434 - acc: 0.8337 - val_loss: 0.4003 - val_acc: 0.8072\n",
      "Epoch 10/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4312 - acc: 0.8396Epoch 00009: val_loss improved from 0.40032 to 0.39030, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323431/323431 [==============================] - 50s - loss: 0.4314 - acc: 0.8396 - val_loss: 0.3903 - val_acc: 0.8163\n",
      "Epoch 11/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4207 - acc: 0.8435Epoch 00010: val_loss did not improve\n",
      "323431/323431 [==============================] - 49s - loss: 0.4208 - acc: 0.8435 - val_loss: 0.4087 - val_acc: 0.8019\n",
      "Epoch 12/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.4116 - acc: 0.8481Epoch 00011: val_loss did not improve\n",
      "323431/323431 [==============================] - 50s - loss: 0.4116 - acc: 0.8481 - val_loss: 0.3996 - val_acc: 0.8127\n",
      "Epoch 13/35\n",
      "323072/323431 [============================>.] - ETA: 0s - loss: 0.4020 - acc: 0.8523Epoch 00012: val_loss did not improve\n",
      "323431/323431 [==============================] - 50s - loss: 0.4021 - acc: 0.8522 - val_loss: 0.3984 - val_acc: 0.8122\n",
      "Epoch 14/35\n",
      "323200/323431 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8549Epoch 00013: val_loss did not improve\n",
      "323431/323431 [==============================] - 50s - loss: 0.3954 - acc: 0.8549 - val_loss: 0.4031 - val_acc: 0.8145\n",
      "Epoch 00013: early stopping\n",
      "2343936/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 323432 samples, validate on 80858 samples\n",
      "Epoch 1/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.6642 - acc: 0.7269Epoch 00000: val_loss improved from inf to 0.52618, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 51s - loss: 0.6642 - acc: 0.7270 - val_loss: 0.5262 - val_acc: 0.7084\n",
      "Epoch 2/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.5925 - acc: 0.7644Epoch 00001: val_loss improved from 0.52618 to 0.43751, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 50s - loss: 0.5925 - acc: 0.7644 - val_loss: 0.4375 - val_acc: 0.7871\n",
      "Epoch 3/35\n",
      "323200/323432 [============================>.] - ETA: 0s - loss: 0.5562 - acc: 0.7814Epoch 00002: val_loss improved from 0.43751 to 0.43255, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 51s - loss: 0.5561 - acc: 0.7814 - val_loss: 0.4325 - val_acc: 0.7885\n",
      "Epoch 4/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.5303 - acc: 0.7950Epoch 00003: val_loss improved from 0.43255 to 0.41735, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 51s - loss: 0.5302 - acc: 0.7950 - val_loss: 0.4174 - val_acc: 0.7988\n",
      "Epoch 5/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.5075 - acc: 0.8053Epoch 00004: val_loss did not improve\n",
      "323432/323432 [==============================] - 51s - loss: 0.5075 - acc: 0.8052 - val_loss: 0.4292 - val_acc: 0.7881\n",
      "Epoch 6/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.8136Epoch 00005: val_loss improved from 0.41735 to 0.40487, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 51s - loss: 0.4886 - acc: 0.8136 - val_loss: 0.4049 - val_acc: 0.8049\n",
      "Epoch 7/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8204Epoch 00006: val_loss improved from 0.40487 to 0.39528, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 51s - loss: 0.4729 - acc: 0.8204 - val_loss: 0.3953 - val_acc: 0.8100\n",
      "Epoch 8/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8273Epoch 00007: val_loss improved from 0.39528 to 0.38699, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 54s - loss: 0.4579 - acc: 0.8273 - val_loss: 0.3870 - val_acc: 0.8178\n",
      "Epoch 9/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8328Epoch 00008: val_loss did not improve\n",
      "323432/323432 [==============================] - 51s - loss: 0.4452 - acc: 0.8328 - val_loss: 0.4040 - val_acc: 0.8020\n",
      "Epoch 10/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8380Epoch 00009: val_loss improved from 0.38699 to 0.38628, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 51s - loss: 0.4334 - acc: 0.8380 - val_loss: 0.3863 - val_acc: 0.8193\n",
      "Epoch 11/35\n",
      "323200/323432 [============================>.] - ETA: 0s - loss: 0.4238 - acc: 0.8426Epoch 00010: val_loss improved from 0.38628 to 0.38575, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323432/323432 [==============================] - 51s - loss: 0.4237 - acc: 0.8426 - val_loss: 0.3858 - val_acc: 0.8157\n",
      "Epoch 12/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.4137 - acc: 0.8480Epoch 00011: val_loss improved from 0.38575 to 0.38201, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323432/323432 [==============================] - 45s - loss: 0.4137 - acc: 0.8480 - val_loss: 0.3820 - val_acc: 0.8213\n",
      "Epoch 13/35\n",
      "323328/323432 [============================>.] - ETA: 0s - loss: 0.4060 - acc: 0.8507Epoch 00012: val_loss did not improve\n",
      "323432/323432 [==============================] - 45s - loss: 0.4060 - acc: 0.8507 - val_loss: 0.3878 - val_acc: 0.8172\n",
      "Epoch 14/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3976 - acc: 0.8538Epoch 00013: val_loss did not improve\n",
      "323432/323432 [==============================] - 45s - loss: 0.3975 - acc: 0.8538 - val_loss: 0.3977 - val_acc: 0.8123\n",
      "Epoch 15/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8580Epoch 00014: val_loss did not improve\n",
      "323432/323432 [==============================] - 45s - loss: 0.3876 - acc: 0.8580 - val_loss: 0.3843 - val_acc: 0.8224\n",
      "Epoch 16/35\n",
      "323072/323432 [============================>.] - ETA: 0s - loss: 0.3809 - acc: 0.8620Epoch 00015: val_loss did not improve\n",
      "323432/323432 [==============================] - 45s - loss: 0.3809 - acc: 0.8620 - val_loss: 0.3922 - val_acc: 0.8165\n",
      "Epoch 00015: early stopping\n",
      "80858/80858 [==============================] - 1s     \n",
      "2344960/2345796 [============================>.] - ETA: 0s\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 323433 samples, validate on 80857 samples\n",
      "Epoch 1/35\n",
      "322944/323433 [============================>.] - ETA: 0s - loss: 0.6660 - acc: 0.7250Epoch 00000: val_loss improved from inf to 0.46959, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 47s - loss: 0.6659 - acc: 0.7250 - val_loss: 0.4696 - val_acc: 0.7663\n",
      "Epoch 2/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.7635Epoch 00001: val_loss improved from 0.46959 to 0.43563, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.5951 - acc: 0.7635 - val_loss: 0.4356 - val_acc: 0.7886\n",
      "Epoch 3/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.5574 - acc: 0.7818Epoch 00002: val_loss improved from 0.43563 to 0.43166, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.5574 - acc: 0.7818 - val_loss: 0.4317 - val_acc: 0.7898\n",
      "Epoch 4/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.5296 - acc: 0.7941Epoch 00003: val_loss improved from 0.43166 to 0.42968, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.5296 - acc: 0.7941 - val_loss: 0.4297 - val_acc: 0.7886\n",
      "Epoch 5/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.8047Epoch 00004: val_loss improved from 0.42968 to 0.40995, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.5086 - acc: 0.8047 - val_loss: 0.4100 - val_acc: 0.7997\n",
      "Epoch 6/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4899 - acc: 0.8126Epoch 00005: val_loss improved from 0.40995 to 0.40340, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.4900 - acc: 0.8126 - val_loss: 0.4034 - val_acc: 0.8026\n",
      "Epoch 7/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.8212Epoch 00006: val_loss improved from 0.40340 to 0.40126, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.4733 - acc: 0.8212 - val_loss: 0.4013 - val_acc: 0.8043\n",
      "Epoch 8/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.4584 - acc: 0.8276Epoch 00007: val_loss improved from 0.40126 to 0.39693, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.4584 - acc: 0.8276 - val_loss: 0.3969 - val_acc: 0.8121\n",
      "Epoch 9/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8330Epoch 00008: val_loss improved from 0.39693 to 0.38810, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.4460 - acc: 0.8331 - val_loss: 0.3881 - val_acc: 0.8137\n",
      "Epoch 10/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.4338 - acc: 0.8380Epoch 00009: val_loss improved from 0.38810 to 0.38387, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 47s - loss: 0.4337 - acc: 0.8380 - val_loss: 0.3839 - val_acc: 0.8174\n",
      "Epoch 11/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4229 - acc: 0.8430Epoch 00010: val_loss did not improve\n",
      "323433/323433 [==============================] - 45s - loss: 0.4229 - acc: 0.8429 - val_loss: 0.3903 - val_acc: 0.8120\n",
      "Epoch 12/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4122 - acc: 0.8487Epoch 00011: val_loss improved from 0.38387 to 0.38190, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.4123 - acc: 0.8486 - val_loss: 0.3819 - val_acc: 0.8208\n",
      "Epoch 13/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4039 - acc: 0.8513Epoch 00012: val_loss did not improve\n",
      "323433/323433 [==============================] - 45s - loss: 0.4040 - acc: 0.8513 - val_loss: 0.3938 - val_acc: 0.8126\n",
      "Epoch 14/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.3949 - acc: 0.8549Epoch 00013: val_loss did not improve\n",
      "323433/323433 [==============================] - 45s - loss: 0.3949 - acc: 0.8549 - val_loss: 0.3874 - val_acc: 0.8187\n",
      "Epoch 15/35\n",
      "322944/323433 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8570Epoch 00014: val_loss improved from 0.38190 to 0.38136, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.3888 - acc: 0.8570 - val_loss: 0.3814 - val_acc: 0.8214\n",
      "Epoch 16/35\n",
      "322944/323433 [============================>.] - ETA: 0s - loss: 0.3808 - acc: 0.8615Epoch 00015: val_loss did not improve\n",
      "323433/323433 [==============================] - 45s - loss: 0.3808 - acc: 0.8615 - val_loss: 0.3825 - val_acc: 0.8214\n",
      "Epoch 00015: early stopping\n",
      "80857/80857 [==============================] - 1s     \n",
      "2345796/2345796 [==============================] - 31s    \n",
      "\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 323433 samples, validate on 80857 samples\n",
      "Epoch 1/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.6645 - acc: 0.7265Epoch 00000: val_loss improved from inf to 0.47315, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 44s - loss: 0.6645 - acc: 0.7265 - val_loss: 0.4732 - val_acc: 0.7667\n",
      "Epoch 2/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.7645Epoch 00001: val_loss improved from 0.47315 to 0.46051, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323433/323433 [==============================] - 43s - loss: 0.5920 - acc: 0.7645 - val_loss: 0.4605 - val_acc: 0.7705\n",
      "Epoch 3/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.5563 - acc: 0.7818Epoch 00002: val_loss improved from 0.46051 to 0.42570, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 43s - loss: 0.5562 - acc: 0.7818 - val_loss: 0.4257 - val_acc: 0.7888\n",
      "Epoch 4/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.5290 - acc: 0.7942Epoch 00003: val_loss improved from 0.42570 to 0.40693, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 43s - loss: 0.5290 - acc: 0.7942 - val_loss: 0.4069 - val_acc: 0.8036\n",
      "Epoch 5/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.5072 - acc: 0.8062Epoch 00004: val_loss improved from 0.40693 to 0.40079, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 45s - loss: 0.5072 - acc: 0.8062 - val_loss: 0.4008 - val_acc: 0.8070\n",
      "Epoch 6/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4881 - acc: 0.8136Epoch 00005: val_loss improved from 0.40079 to 0.39974, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 49s - loss: 0.4881 - acc: 0.8136 - val_loss: 0.3997 - val_acc: 0.8077\n",
      "Epoch 7/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.4734 - acc: 0.8206Epoch 00006: val_loss did not improve\n",
      "323433/323433 [==============================] - 48s - loss: 0.4734 - acc: 0.8206 - val_loss: 0.4041 - val_acc: 0.8056\n",
      "Epoch 8/35\n",
      "323200/323433 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8275Epoch 00007: val_loss improved from 0.39974 to 0.38489, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_currie32_cnn.h5\n",
      "323433/323433 [==============================] - 49s - loss: 0.4591 - acc: 0.8275 - val_loss: 0.3849 - val_acc: 0.8177\n",
      "Epoch 9/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8334Epoch 00008: val_loss did not improve\n",
      "323433/323433 [==============================] - 49s - loss: 0.4468 - acc: 0.8334 - val_loss: 0.4042 - val_acc: 0.8048\n",
      "Epoch 10/35\n",
      "322944/323433 [============================>.] - ETA: 0s - loss: 0.4355 - acc: 0.8383Epoch 00009: val_loss did not improve\n",
      "323433/323433 [==============================] - 47s - loss: 0.4354 - acc: 0.8383 - val_loss: 0.3893 - val_acc: 0.8164\n",
      "Epoch 11/35\n",
      "323328/323433 [============================>.] - ETA: 0s - loss: 0.4239 - acc: 0.8420Epoch 00010: val_loss did not improve\n",
      "323433/323433 [==============================] - 45s - loss: 0.4238 - acc: 0.8420 - val_loss: 0.3888 - val_acc: 0.8178\n",
      "Epoch 12/35\n",
      "323072/323433 [============================>.] - ETA: 0s - loss: 0.4158 - acc: 0.8462Epoch 00011: val_loss did not improve\n",
      "323433/323433 [==============================] - 46s - loss: 0.4158 - acc: 0.8462 - val_loss: 0.3894 - val_acc: 0.8153\n",
      "Epoch 00011: early stopping\n",
      "2344960/2345796 [============================>.] - ETA: 0sCPU times: user 1h 28min 7s, sys: 5min 24s, total: 1h 33min 31s\n",
      "Wall time: 1h 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = X_train_q1[ix_train]\n",
    "    X_fold_train_q2 = X_train_q2[ix_train]\n",
    "\n",
    "    X_fold_val_q1 = X_train_q1[ix_val]\n",
    "    X_fold_val_q2 = X_train_q2[ix_val]\n",
    "\n",
    "    y_fold_train = y_train[ix_train]\n",
    "    y_fold_val = y_train[ix_val]\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2, X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2, X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "        class_weight=keras_get_class_weights(y_fold_val),\n",
    "\n",
    "        batch_size=128,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_pred_oofp = model.predict(\n",
    "        [X_train_q1[ix_val], X_train_q2[ix_val], X_train_q1[ix_val], X_train_q2[ix_val]],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    y_test_oofp[:, fold_num] = model.predict(\n",
    "        [X_test_q1, X_test_q2, X_test_q1, X_test_q2],\n",
    "        batch_size=1024,\n",
    "        verbose=1\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    # Remember them.\n",
    "    y_train_oofp[ix_val] = y_pred_oofp\n",
    "    \n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_currie32_cnn',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp_mean = np.mean(y_test_oofp, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp_mean, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
