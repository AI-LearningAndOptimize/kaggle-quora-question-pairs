{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'oofp_lystdo_bi_lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 101442 30\n"
     ]
    }
   ],
   "source": [
    "print(EMBEDDING_DIM, VOCAB_LENGTH, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models & Compute Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    params = {\n",
    "        'dense_dropout_rate': 0.07512852175097123,\n",
    "        'lstm_dropout_rate': 0.3320541002991107,\n",
    "        'num_dense': 130,\n",
    "        'num_lstm': 333\n",
    "    }\n",
    "    \n",
    "    embedding_layer = Embedding(\n",
    "        VOCAB_LENGTH,\n",
    "        EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False,\n",
    "    )\n",
    "    lstm_layer = Bidirectional(LSTM(\n",
    "        params['num_lstm'],\n",
    "        dropout=params['lstm_dropout_rate'],\n",
    "        recurrent_dropout=params['lstm_dropout_rate'],\n",
    "    ))\n",
    "\n",
    "    sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "    x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "    sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "    y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "    merged = concatenate([x1, y1])\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    merged = Dense(params['num_dense'], activation='relu')(merged)\n",
    "    merged = Dropout(params['dense_dropout_rate'])(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[sequence_1_input, sequence_2_input],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-' + feature_list_id + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = np.zeros_like(y_train, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting fold 1 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.7528Epoch 00000: val_loss improved from inf to 0.42928, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 266s - loss: 0.4940 - acc: 0.7528 - val_loss: 0.4293 - val_acc: 0.7923\n",
      "Epoch 2/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8031Epoch 00001: val_loss improved from 0.42928 to 0.39031, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 269s - loss: 0.4117 - acc: 0.8031 - val_loss: 0.3903 - val_acc: 0.8167\n",
      "Epoch 3/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3763 - acc: 0.8235Epoch 00002: val_loss improved from 0.39031 to 0.36961, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 268s - loss: 0.3763 - acc: 0.8235 - val_loss: 0.3696 - val_acc: 0.8287\n",
      "Epoch 4/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.8374Epoch 00003: val_loss improved from 0.36961 to 0.36114, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 267s - loss: 0.3513 - acc: 0.8374 - val_loss: 0.3611 - val_acc: 0.8335\n",
      "Epoch 5/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3327 - acc: 0.8477Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 267s - loss: 0.3327 - acc: 0.8477 - val_loss: 0.3641 - val_acc: 0.8321\n",
      "Epoch 6/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3190 - acc: 0.8551Epoch 00005: val_loss improved from 0.36114 to 0.35444, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 269s - loss: 0.3190 - acc: 0.8551 - val_loss: 0.3544 - val_acc: 0.8407\n",
      "Epoch 7/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.8617Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 268s - loss: 0.3062 - acc: 0.8617 - val_loss: 0.3686 - val_acc: 0.8346\n",
      "Epoch 8/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.8662Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 266s - loss: 0.2973 - acc: 0.8662 - val_loss: 0.3592 - val_acc: 0.8403\n",
      "Epoch 9/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.8705Epoch 00008: val_loss did not improve\n",
      "646862/646862 [==============================] - 266s - loss: 0.2890 - acc: 0.8705 - val_loss: 0.3738 - val_acc: 0.8351\n",
      "Epoch 10/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.8739Epoch 00009: val_loss did not improve\n",
      "646862/646862 [==============================] - 268s - loss: 0.2822 - acc: 0.8739 - val_loss: 0.3601 - val_acc: 0.8395\n",
      "Epoch 00009: early stopping\n",
      "80859/80859 [==============================] - 8s     \n",
      "80859/80859 [==============================] - 8s     \n",
      "\n",
      "Fitting fold 2 of 5\n",
      "\n",
      "Train on 646862 samples, validate on 161718 samples\n",
      "Epoch 1/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.4927 - acc: 0.7530Epoch 00000: val_loss improved from inf to 0.42870, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 272s - loss: 0.4927 - acc: 0.7530 - val_loss: 0.4287 - val_acc: 0.7923\n",
      "Epoch 2/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8026Epoch 00001: val_loss improved from 0.42870 to 0.40499, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 267s - loss: 0.4117 - acc: 0.8026 - val_loss: 0.4050 - val_acc: 0.8075\n",
      "Epoch 3/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8227Epoch 00002: val_loss improved from 0.40499 to 0.39043, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 320s - loss: 0.3771 - acc: 0.8227 - val_loss: 0.3904 - val_acc: 0.8189\n",
      "Epoch 4/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8374Epoch 00003: val_loss improved from 0.39043 to 0.36041, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646862/646862 [==============================] - 329s - loss: 0.3516 - acc: 0.8374 - val_loss: 0.3604 - val_acc: 0.8350\n",
      "Epoch 5/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3330 - acc: 0.8476Epoch 00004: val_loss did not improve\n",
      "646862/646862 [==============================] - 329s - loss: 0.3330 - acc: 0.8475 - val_loss: 0.3659 - val_acc: 0.8326\n",
      "Epoch 6/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3181 - acc: 0.8555Epoch 00005: val_loss did not improve\n",
      "646862/646862 [==============================] - 326s - loss: 0.3181 - acc: 0.8555 - val_loss: 0.3625 - val_acc: 0.8370\n",
      "Epoch 7/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.8611Epoch 00006: val_loss did not improve\n",
      "646862/646862 [==============================] - 330s - loss: 0.3072 - acc: 0.8611 - val_loss: 0.3634 - val_acc: 0.8392\n",
      "Epoch 8/35\n",
      "646656/646862 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.8662Epoch 00007: val_loss did not improve\n",
      "646862/646862 [==============================] - 288s - loss: 0.2975 - acc: 0.8662 - val_loss: 0.3635 - val_acc: 0.8407\n",
      "Epoch 00007: early stopping\n",
      "80859/80859 [==============================] - 8s     \n",
      "80859/80859 [==============================] - 8s     \n",
      "\n",
      "Fitting fold 3 of 5\n",
      "\n",
      "Train on 646864 samples, validate on 161716 samples\n",
      "Epoch 1/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.4957 - acc: 0.7510Epoch 00000: val_loss improved from inf to 0.42528, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646864/646864 [==============================] - 268s - loss: 0.4957 - acc: 0.7510 - val_loss: 0.4253 - val_acc: 0.7966\n",
      "Epoch 2/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8019Epoch 00001: val_loss improved from 0.42528 to 0.39286, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646864/646864 [==============================] - 267s - loss: 0.4147 - acc: 0.8019 - val_loss: 0.3929 - val_acc: 0.8157\n",
      "Epoch 3/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.3781 - acc: 0.8224Epoch 00002: val_loss improved from 0.39286 to 0.38163, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646864/646864 [==============================] - 266s - loss: 0.3781 - acc: 0.8224 - val_loss: 0.3816 - val_acc: 0.8216\n",
      "Epoch 4/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8364Epoch 00003: val_loss improved from 0.38163 to 0.36719, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646864/646864 [==============================] - 268s - loss: 0.3533 - acc: 0.8364 - val_loss: 0.3672 - val_acc: 0.8321\n",
      "Epoch 5/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.8467Epoch 00004: val_loss did not improve\n",
      "646864/646864 [==============================] - 267s - loss: 0.3343 - acc: 0.8467 - val_loss: 0.3805 - val_acc: 0.8263\n",
      "Epoch 6/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.3201 - acc: 0.8546Epoch 00005: val_loss improved from 0.36719 to 0.35677, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646864/646864 [==============================] - 269s - loss: 0.3201 - acc: 0.8546 - val_loss: 0.3568 - val_acc: 0.8403\n",
      "Epoch 7/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.3077 - acc: 0.8613Epoch 00006: val_loss did not improve\n",
      "646864/646864 [==============================] - 267s - loss: 0.3077 - acc: 0.8613 - val_loss: 0.3650 - val_acc: 0.8357\n",
      "Epoch 8/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.8662Epoch 00007: val_loss did not improve\n",
      "646864/646864 [==============================] - 269s - loss: 0.2975 - acc: 0.8662 - val_loss: 0.3636 - val_acc: 0.8372\n",
      "Epoch 9/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.2905 - acc: 0.8701Epoch 00008: val_loss did not improve\n",
      "646864/646864 [==============================] - 269s - loss: 0.2905 - acc: 0.8701 - val_loss: 0.3673 - val_acc: 0.8404\n",
      "Epoch 10/35\n",
      "646656/646864 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.8742Epoch 00009: val_loss did not improve\n",
      "646864/646864 [==============================] - 271s - loss: 0.2828 - acc: 0.8742 - val_loss: 0.3684 - val_acc: 0.8403\n",
      "Epoch 00009: early stopping\n",
      "80858/80858 [==============================] - 8s     \n",
      "80858/80858 [==============================] - 8s     \n",
      "\n",
      "Fitting fold 4 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.7522Epoch 00000: val_loss improved from inf to 0.43439, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 269s - loss: 0.4944 - acc: 0.7522 - val_loss: 0.4344 - val_acc: 0.7898\n",
      "Epoch 2/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.4131 - acc: 0.8033Epoch 00001: val_loss improved from 0.43439 to 0.39732, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 269s - loss: 0.4131 - acc: 0.8033 - val_loss: 0.3973 - val_acc: 0.8118\n",
      "Epoch 3/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3777 - acc: 0.8232Epoch 00002: val_loss improved from 0.39732 to 0.37303, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 268s - loss: 0.3777 - acc: 0.8232 - val_loss: 0.3730 - val_acc: 0.8269\n",
      "Epoch 4/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8367Epoch 00003: val_loss improved from 0.37303 to 0.36481, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 268s - loss: 0.3528 - acc: 0.8367 - val_loss: 0.3648 - val_acc: 0.8319\n",
      "Epoch 5/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3340 - acc: 0.8474Epoch 00004: val_loss did not improve\n",
      "646866/646866 [==============================] - 268s - loss: 0.3340 - acc: 0.8474 - val_loss: 0.3715 - val_acc: 0.8304\n",
      "Epoch 6/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.8548Epoch 00005: val_loss improved from 0.36481 to 0.36413, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 270s - loss: 0.3198 - acc: 0.8548 - val_loss: 0.3641 - val_acc: 0.8387\n",
      "Epoch 7/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3077 - acc: 0.8609Epoch 00006: val_loss improved from 0.36413 to 0.36140, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 270s - loss: 0.3077 - acc: 0.8609 - val_loss: 0.3614 - val_acc: 0.8390\n",
      "Epoch 8/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.8656Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 269s - loss: 0.2984 - acc: 0.8656 - val_loss: 0.3641 - val_acc: 0.8404\n",
      "Epoch 9/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.8687Epoch 00008: val_loss improved from 0.36140 to 0.36047, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 268s - loss: 0.2934 - acc: 0.8687 - val_loss: 0.3605 - val_acc: 0.8390\n",
      "Epoch 10/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.8697Epoch 00009: val_loss improved from 0.36047 to 0.35641, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 265s - loss: 0.2917 - acc: 0.8697 - val_loss: 0.3564 - val_acc: 0.8431\n",
      "Epoch 11/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2840 - acc: 0.8734Epoch 00010: val_loss did not improve\n",
      "646866/646866 [==============================] - 267s - loss: 0.2840 - acc: 0.8734 - val_loss: 0.3594 - val_acc: 0.8433\n",
      "Epoch 12/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2797 - acc: 0.8761Epoch 00011: val_loss did not improve\n",
      "646866/646866 [==============================] - 266s - loss: 0.2797 - acc: 0.8761 - val_loss: 0.3615 - val_acc: 0.8427\n",
      "Epoch 13/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.8781Epoch 00012: val_loss did not improve\n",
      "646866/646866 [==============================] - 265s - loss: 0.2756 - acc: 0.8781 - val_loss: 0.3620 - val_acc: 0.8438\n",
      "Epoch 14/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.8803Epoch 00013: val_loss did not improve\n",
      "646866/646866 [==============================] - 265s - loss: 0.2717 - acc: 0.8803 - val_loss: 0.3593 - val_acc: 0.8465\n",
      "Epoch 00013: early stopping\n",
      "80857/80857 [==============================] - 8s     \n",
      "80857/80857 [==============================] - 8s     \n",
      "\n",
      "Fitting fold 5 of 5\n",
      "\n",
      "Train on 646866 samples, validate on 161714 samples\n",
      "Epoch 1/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.4947 - acc: 0.7516Epoch 00000: val_loss improved from inf to 0.43269, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 267s - loss: 0.4947 - acc: 0.7516 - val_loss: 0.4327 - val_acc: 0.7910\n",
      "Epoch 2/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8019Epoch 00001: val_loss improved from 0.43269 to 0.38790, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 265s - loss: 0.4132 - acc: 0.8019 - val_loss: 0.3879 - val_acc: 0.8180\n",
      "Epoch 3/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8223Epoch 00002: val_loss improved from 0.38790 to 0.37591, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 264s - loss: 0.3784 - acc: 0.8223 - val_loss: 0.3759 - val_acc: 0.8251\n",
      "Epoch 4/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.8362Epoch 00003: val_loss improved from 0.37591 to 0.36495, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 266s - loss: 0.3536 - acc: 0.8362 - val_loss: 0.3649 - val_acc: 0.8332\n",
      "Epoch 5/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.8460Epoch 00004: val_loss improved from 0.36495 to 0.35982, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 265s - loss: 0.3351 - acc: 0.8459 - val_loss: 0.3598 - val_acc: 0.8382\n",
      "Epoch 6/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.8539Epoch 00005: val_loss did not improve\n",
      "646866/646866 [==============================] - 267s - loss: 0.3198 - acc: 0.8539 - val_loss: 0.3631 - val_acc: 0.8395\n",
      "Epoch 7/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.8606Epoch 00006: val_loss improved from 0.35982 to 0.35491, saving model to /home/yuriyguts/Projects/kaggle-quora-question-pairs/data/aux/fold-checkpoint-oofp_lystdo_bi_lstm.h5\n",
      "646866/646866 [==============================] - 267s - loss: 0.3078 - acc: 0.8606 - val_loss: 0.3549 - val_acc: 0.8452\n",
      "Epoch 8/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.8659Epoch 00007: val_loss did not improve\n",
      "646866/646866 [==============================] - 266s - loss: 0.2978 - acc: 0.8659 - val_loss: 0.3629 - val_acc: 0.8397\n",
      "Epoch 9/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.8698Epoch 00008: val_loss did not improve\n",
      "646866/646866 [==============================] - 265s - loss: 0.2896 - acc: 0.8698 - val_loss: 0.3599 - val_acc: 0.8456\n",
      "Epoch 10/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2833 - acc: 0.8735Epoch 00009: val_loss did not improve\n",
      "646866/646866 [==============================] - 266s - loss: 0.2833 - acc: 0.8735 - val_loss: 0.3578 - val_acc: 0.8457\n",
      "Epoch 11/35\n",
      "646656/646866 [============================>.] - ETA: 0s - loss: 0.2773 - acc: 0.8764Epoch 00010: val_loss did not improve\n",
      "646866/646866 [==============================] - 266s - loss: 0.2773 - acc: 0.8764 - val_loss: 0.3614 - val_acc: 0.8453\n",
      "Epoch 00010: early stopping\n",
      "80857/80857 [==============================] - 8s     \n",
      "80857/80857 [==============================] - 8s     \n",
      "CPU times: user 4h 37min 43s, sys: 30min 29s, total: 5h 8min 12s\n",
      "Wall time: 4h 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "    X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "    X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "\n",
    "    X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "    X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "\n",
    "    y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "    y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "    \n",
    "    print()\n",
    "    print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "    print()\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        [X_fold_train_q1, X_fold_train_q2], y_fold_train,\n",
    "        validation_data=([X_fold_val_q1, X_fold_val_q2], y_fold_val),\n",
    "#         class_weight=keras_get_class_weights(y_fold_val),\n",
    "\n",
    "        batch_size=384,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.001,\n",
    "                patience=3,\n",
    "                verbose=1,\n",
    "                mode='auto',\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                model_checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=2,\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "        \n",
    "    # Create out-of-fold prediction.\n",
    "    model.load_weights(model_checkpoint_path)\n",
    "    \n",
    "    y_pred_oofp = model.predict([X_train_q1[ix_val], X_train_q2[ix_val]], batch_size=2048, verbose=1).reshape(-1)\n",
    "    y_pred_oofp += model.predict([X_train_q2[ix_val], X_train_q1[ix_val]], batch_size=2048, verbose=1).reshape(-1)\n",
    "    y_pred_oofp /= 2\n",
    "       \n",
    "    # Remember them.\n",
    "    y_train_oofp[ix_val] = y_pred_oofp\n",
    "    \n",
    "    K.clear_session()\n",
    "    del X_fold_train_q1\n",
    "    del X_fold_train_q2\n",
    "    del X_fold_val_q1\n",
    "    del X_fold_val_q2\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'oofp_lystdo_bi_lstm',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_lines(feature_names, features_data_folder + f'X_train_{feature_list_id}.names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_oofp = y_train_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_train_oofp, features_data_folder + f'X_train_{feature_list_id}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_weights(model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345796/2345796 [==============================] - 236s   \n",
      "2345796/2345796 [==============================] - 237s   \n"
     ]
    }
   ],
   "source": [
    "# It would be better to fit the model on the whole training set\n",
    "# but the validation set for early stopping would be an issue.\n",
    "y_test_oofp = model.predict([X_test_q1, X_test_q2], batch_size=2048, verbose=1).reshape(-1)\n",
    "y_test_oofp += model.predict([X_test_q2, X_test_q1], batch_size=2048, verbose=1).reshape(-1)\n",
    "y_test_oofp /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_oofp = y_test_oofp.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(y_test_oofp, features_data_folder + f'X_test_{feature_list_id}.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
