{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_use_gpus(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sigopt import Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint_path = aux_data_folder + 'fold-checkpoint-sigopt-keras-cnn.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_OPTIMIZATION_ITERATIONS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIGOPT_EXPERIMENT_ID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIGOPT_TOKEN = 'YOUR_TOKEN_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load(aux_data_folder + 'embedding_weights_fasttext_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_q1 = load(features_data_folder + 'X_train_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_train_q2 = load(features_data_folder + 'X_train_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_q1 = load(features_data_folder + 'X_test_nn_fasttext_q1_filtered_no_stopwords.pickle')\n",
    "X_test_q2 = load(features_data_folder + 'X_test_nn_fasttext_q2_filtered_no_stopwords.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "magic_feature_lists = [\n",
    "    'magic_jturkewitz',\n",
    "    'magic_stas_svd_150',\n",
    "    'magic_stas_avito',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic, X_test_magic, _ = load_feature_lists(magic_feature_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_magic = X_train_magic.values\n",
    "X_test_magic = X_test_magic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack([X_train_magic, X_test_magic]))\n",
    "X_train_magic = scaler.transform(X_train_magic)\n",
    "X_test_magic = scaler.transform(X_test_magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = load(features_data_folder + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = embedding_matrix.shape[-1]\n",
    "VOCAB_LENGTH = embedding_matrix.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = X_train_q1.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=NUM_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = Connection(client_token=SIGOPT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SIGOPT_EXPERIMENT_ID:\n",
    "    experiment = conn.experiments(id=SIGOPT_EXPERIMENT_ID).fetch()\n",
    "\n",
    "else:\n",
    "    experiment = conn.experiments().create(\n",
    "        name='CNN over FastText',\n",
    "        parameters=[\n",
    "            dict(name='num_dense_1', type='int', bounds=(dict(min=8, max=500))),\n",
    "            dict(name='num_dense_2', type='int', bounds=(dict(min=8, max=500))),\n",
    "            dict(name='num_dense_3', type='int', bounds=(dict(min=8, max=500))),\n",
    "            dict(name='dropout_rate', type='double', bounds=(dict(min=0.0, max=0.75))),\n",
    "        ],\n",
    "    )\n",
    "    print(\"Created experiment: https://sigopt.com/experiment/\" + experiment.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    init_weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
    "    init_bias = 'zeros'\n",
    "\n",
    "    def create_embedding_block():\n",
    "        input_seq = Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype='int32')\n",
    "\n",
    "        embedding_seq = Embedding(\n",
    "            VOCAB_LENGTH,\n",
    "            EMBEDDING_DIM,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=MAX_SEQUENCE_LENGTH,\n",
    "            trainable=False,\n",
    "        )(input_seq)\n",
    "\n",
    "        output_seq = embedding_seq\n",
    "        return input_seq, output_seq    \n",
    "\n",
    "    def create_model_question_conv_branch(input_seq, params):\n",
    "        conv_1 = Conv1D(\n",
    "            params['num_conv_filters'],\n",
    "            kernel_size=params['conv_kernel_size'],\n",
    "            padding='same',\n",
    "        )(input_seq)\n",
    "\n",
    "        bn_1 = BatchNormalization()(conv_1)\n",
    "        relu_1 = Activation('relu')(bn_1)\n",
    "        dropout_1 = Dropout(params['conv_dropout_rate'])(relu_1)\n",
    "\n",
    "        conv_2 = Conv1D(\n",
    "            params['num_conv_filters'],\n",
    "            kernel_size=params['conv_kernel_size'],\n",
    "            padding='same',\n",
    "        )(dropout_1)\n",
    "\n",
    "        bn_2 = BatchNormalization()(conv_2)\n",
    "        relu_2 = Activation('relu')(bn_2)\n",
    "        dropout_2 = Dropout(params['conv_dropout_rate'])(relu_2)\n",
    "\n",
    "        flatten = Flatten()(dropout_2)\n",
    "        output = flatten\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def create_model_question_timedist_max_branch(input_seq, params):\n",
    "        timedist = TimeDistributed(Dense(EMBEDDING_DIM))(input_seq)\n",
    "        bn = BatchNormalization()(timedist)\n",
    "        relu = Activation('relu')(bn)\n",
    "        dropout = Dropout(params['timedist_dropout_rate'])(relu)\n",
    "\n",
    "        lambda_max = Lambda(\n",
    "            lambda x: K.max(x, axis=1),\n",
    "            output_shape=(EMBEDDING_DIM, )\n",
    "        )(dropout)\n",
    "\n",
    "        output = lambda_max\n",
    "        return output\n",
    "\n",
    "    def create_dense_block(input_layer, num_units, dropout_rate):\n",
    "        dense = Dense(\n",
    "            num_units,\n",
    "            kernel_initializer=init_weights,\n",
    "            bias_initializer=init_bias,\n",
    "        )(input_layer)\n",
    "        bn = BatchNormalization()(dense)\n",
    "        relu = Activation('relu')(bn)\n",
    "        dropout = Dropout(dropout_rate)(relu)\n",
    "        output = dropout\n",
    "\n",
    "        return output\n",
    "\n",
    "    input_q1, emb_q1 = create_embedding_block()\n",
    "    input_q2, emb_q2 = create_embedding_block()\n",
    "    \n",
    "    # Feature extractors.\n",
    "    conv_q1_output = create_model_question_conv_branch(emb_q1, params)\n",
    "    conv_q2_output = create_model_question_conv_branch(emb_q2, params)\n",
    "    \n",
    "    timedist_q1_output = create_model_question_timedist_max_branch(emb_q1, params)\n",
    "    timedist_q2_output = create_model_question_timedist_max_branch(emb_q2, params)\n",
    "    \n",
    "    # Mid-level transforms.\n",
    "    conv_merged = concatenate([conv_q1_output, conv_q2_output])\n",
    "    conv_dense_1 = create_dense_block(conv_merged, params['num_dense_1'], params['dense_dropout_rate'])\n",
    "    conv_dense_2 = create_dense_block(conv_dense_1, params['num_dense_2'], params['dense_dropout_rate'])\n",
    "\n",
    "    td_merged = concatenate([timedist_q1_output, timedist_q2_output])\n",
    "    td_dense_1 = create_dense_block(td_merged, params['num_dense_1'], params['dense_dropout_rate'])\n",
    "    td_dense_2 = create_dense_block(td_dense_1, params['num_dense_2'], params['dense_dropout_rate'])\n",
    "\n",
    "    # Magic features.\n",
    "    magic_input = Input(shape=(X_train_magic.shape[-1], ))\n",
    "    \n",
    "    # Main dense block.\n",
    "    merged_main = concatenate([conv_dense_2, td_dense_2, magic_input])\n",
    "    dense_main_1 = create_dense_block(merged_main, params['num_dense_1'], params['dense_dropout_rate'])\n",
    "    dense_main_2 = create_dense_block(dense_main_1, params['num_dense_2'], params['dense_dropout_rate'])\n",
    "    dense_main_3 = create_dense_block(dense_main_2, params['num_dense_3'], params['dense_dropout_rate'])\n",
    "    \n",
    "    output = Dense(\n",
    "        1,\n",
    "        kernel_initializer=init_weights,\n",
    "        bias_initializer=init_bias,\n",
    "        activation='sigmoid',\n",
    "    )(dense_main_3)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_q1, input_q2, magic_input],\n",
    "        outputs=output,\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='nadam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(candidate_params):\n",
    "    \n",
    "    model_params = {\n",
    "        'num_conv_filters': 32,\n",
    "        'num_dense_1': candidate_params['num_dense_1'],\n",
    "        'num_dense_2': candidate_params['num_dense_2'],\n",
    "        'num_dense_3': candidate_params['num_dense_3'],\n",
    "        'conv_kernel_size': 3,\n",
    "        'conv_dropout_rate': candidate_params['dropout_rate'],\n",
    "        'timedist_dropout_rate': candidate_params['dropout_rate'],\n",
    "        'dense_dropout_rate': candidate_params['dropout_rate'],\n",
    "    }\n",
    "    \n",
    "    cv_scores = []\n",
    "\n",
    "    for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "        X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "        X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "        X_fold_train_magic = np.vstack([X_train_magic[ix_train], X_train_magic[ix_train]])\n",
    "\n",
    "        X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "        X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "        X_fold_val_magic = np.vstack([X_train_magic[ix_val], X_train_magic[ix_val]])\n",
    "\n",
    "        y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "        y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "\n",
    "        print()\n",
    "        print(f'Fitting fold {fold_num + 1} of {kfold.n_splits}')\n",
    "        print()\n",
    "\n",
    "        model = create_model(model_params)\n",
    "        history = model.fit(\n",
    "            [X_fold_train_q1, X_fold_train_q2, X_fold_train_magic], y_fold_train,\n",
    "            validation_data=([X_fold_val_q1, X_fold_val_q2, X_fold_val_magic], y_fold_val),\n",
    "\n",
    "            batch_size=64,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            verbose=1,\n",
    "\n",
    "            callbacks=[\n",
    "                EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    min_delta=0.001,\n",
    "                    patience=3,\n",
    "                    verbose=1,\n",
    "                    mode='auto',\n",
    "                ),\n",
    "                ModelCheckpoint(\n",
    "                    model_checkpoint_path,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True,\n",
    "                    verbose=2,\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        best_val_loss = min(history.history[\"val_loss\"])\n",
    "        cv_scores.append(best_val_loss)\n",
    "        \n",
    "        # Clear GPU memory.\n",
    "        K.clear_session()\n",
    "        del X_fold_train_q1\n",
    "        del X_fold_train_q2\n",
    "        del X_fold_train_magic\n",
    "        del X_fold_val_q1\n",
    "        del X_fold_val_q2\n",
    "        del X_fold_val_magic\n",
    "        del model\n",
    "        del history\n",
    "        gc.collect()\n",
    "        \n",
    "        # PATCH: Limit to 1 fold for quicker parameter search.\n",
    "        break\n",
    "    \n",
    "    return -np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(NUM_OPTIMIZATION_ITERATIONS):\n",
    "    print(f'Iteration {i}')\n",
    "    suggestion = conn.experiments(experiment.id).suggestions().create()\n",
    "    \n",
    "    print('Suggestion: ')\n",
    "    pprint.pprint(suggestion.assignments)\n",
    "    \n",
    "    score = evaluate_model(suggestion.assignments)\n",
    "    print(f'Score: {score:.6f}')\n",
    "    print()\n",
    "    \n",
    "    conn.experiments(experiment.id).observations().create(\n",
    "        suggestion=suggestion.id,\n",
    "        value=score,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
