{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine, euclidean, jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list_id = 'nlp_tags'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_questions_train = pd.read_csv(data_folder + 'train.csv').fillna('')\n",
    "df_questions_test = pd.read_csv(data_folder + 'test.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_tokens_train = load_json(preproc_data_folder + 'question_tokens_spellchecked_train.json')\n",
    "question_tokens_test = load_json(preproc_data_folder + 'question_tokens_spellchecked_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [' '.join(pair['question1']), ' '.join(pair['question2'])]\n",
    "        for pair in question_tokens_train + question_tokens_test\n",
    "    ],\n",
    "    columns=['question1', 'question2'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', parser=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tags_whitelist = ['ADJ', 'ADV', 'NOUN', 'PROPN', 'NUM', 'VERB']\n",
    "ner_tags_whitelist = ['GPE', 'LOC', 'ORG', 'NORP', 'PERSON', 'PRODUCT', 'DATE', 'TIME', 'QUANTITY', 'CARDINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_raw_features = len(pos_tags_whitelist) + len(ner_tags_whitelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = np.zeros((len(df), num_raw_features))\n",
    "X2 = np.zeros((len(df), num_raw_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape, X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect POS and NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, doc in enumerate(nlp.pipe(df['question1'].values, n_threads=os.cpu_count())):\n",
    "    pos_counter = Counter(token.pos_ for token in doc)\n",
    "    ner_counter = Counter(ent.label_ for ent in doc.ents)\n",
    "    X1[i, :] = np.array(\n",
    "        [pos_counter[pos_tag] for pos_tag in pos_tags_whitelist] +\n",
    "        [ner_counter[ner_tag] for ner_tag in ner_tags_whitelist]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, doc in enumerate(nlp.pipe(df['question2'].values, n_threads=os.cpu_count())):\n",
    "    pos_counter = Counter(token.pos_ for token in doc)\n",
    "    ner_counter = Counter(ent.label_ for ent in doc.ents)\n",
    "    X2[i, :] = np.array(\n",
    "        [pos_counter[pos_tag] for pos_tag in pos_tags_whitelist] +\n",
    "        [ner_counter[ner_tag] for ner_tag in ner_tags_whitelist]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tag feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pos_1 = pd.DataFrame(\n",
    "    X1[:, 0:len(pos_tags_whitelist)],\n",
    "    columns=['pos_q1_' + pos_tag.lower() for pos_tag in pos_tags_whitelist]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pos_2 = pd.DataFrame(\n",
    "    X2[:, 0:len(pos_tags_whitelist)],\n",
    "    columns=['pos_q2_' + pos_tag.lower() for pos_tag in pos_tags_whitelist]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ner_1 = pd.DataFrame(\n",
    "    X1[:, -len(ner_tags_whitelist):],\n",
    "    columns=['ner_q1_' + ner_tag.lower() for ner_tag in ner_tags_whitelist]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ner_2 = pd.DataFrame(\n",
    "    X2[:, -len(ner_tags_whitelist):],\n",
    "    columns=['ner_q2_' + ner_tag.lower() for ner_tag in ner_tags_whitelist]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_distance_features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dist = np.zeros((len(df), num_distance_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in progressbar(range(len(df))):\n",
    "    X_dist[i, :] = np.array([\n",
    "        # POS distances.\n",
    "        cosine(X1[i, 0:len(pos_tags_whitelist)], X2[i, 0:len(pos_tags_whitelist)]),\n",
    "        euclidean(X1[i, 0:len(pos_tags_whitelist)], X2[i, 0:len(pos_tags_whitelist)]),\n",
    "        \n",
    "        # NER distances.\n",
    "        euclidean(X1[i, -len(ner_tags_whitelist):], X2[i, -len(ner_tags_whitelist):]),\n",
    "        np.abs(np.sum(X1[i, -len(ner_tags_whitelist):]) - np.sum(X2[i, -len(ner_tags_whitelist):])),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dist = pd.DataFrame(\n",
    "    X_dist,\n",
    "    columns=[\n",
    "        'pos_tag_cosine',\n",
    "        'pos_tag_euclidean',\n",
    "        'ner_tag_euclidean',\n",
    "        'ner_tag_count_diff',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build master feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_master = pd.concat(\n",
    "    [df_pos_1, df_ner_1, df_pos_2, df_ner_2, df_dist],\n",
    "    axis=1,\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_master.columns = list(df_pos_1.columns) + \\\n",
    "    list(df_ner_1.columns) + \\\n",
    "    list(df_pos_2.columns) + \\\n",
    "    list(df_ner_2.columns) + \\\n",
    "    list(df_dist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = list(df_master.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_feature_names(feature_names, feature_list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_master[:len(question_tokens_train)]\n",
    "df_test = df_master[len(question_tokens_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_feature_list(df_train.values, 'train', feature_list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_feature_list(df_test.values, 'test', feature_list_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
